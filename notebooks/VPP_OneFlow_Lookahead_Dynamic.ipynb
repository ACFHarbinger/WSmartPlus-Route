{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d981061-3d44-4982-bd1b-69085a57c3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Day 1 ===\n",
      "Initial trigger - bins predicted to overflow (S+2*avg >= Ei): [1173, 1655, 6092, 11571]\n",
      "Computed next collection day nc = 10 (based on overflow_today_bins)\n",
      "MUST-GO set (planned_bins MG) between t and nc: [197, 787, 892, 1171, 1172, 1173, 1410, 1459, 1606, 1621, 1655, 3224, 3315, 5752, 5931, 5933, 5938, 6046, 6092, 6225, 6240, 6904, 6911, 7245, 7445, 7733, 10799, 11213, 11571, 11781, 11789, 11790, 11800, 11811, 11824, 11860, 11873, 11983, 11986, 11989, 12036, 12344, 13138, 13579, 13633, 16825, 17812, 18141]\n",
      "Set parameter TimeLimit to value 300\n",
      "Set parameter MIPGap to value 0.001\n",
      "Gurobi Optimizer version 12.0.2 build v12.0.2rc0 (win64 - Windows 11+.0 (26200.2))\n",
      "\n",
      "CPU model: 12th Gen Intel(R) Core(TM) i5-1235U, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 10 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Non-default parameters:\n",
      "TimeLimit  300\n",
      "MIPGap  0.001\n",
      "\n",
      "Optimize a model with 11601 rows, 22576 columns and 76958 nonzeros\n",
      "Model fingerprint: 0x27962904\n",
      "Variable types: 11236 continuous, 11340 integer (11340 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 4e+03]\n",
      "  Objective range  [6e-02, 7e+01]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 5e+01]\n",
      "Presolve removed 1403 rows and 2626 columns\n",
      "Presolve time: 0.49s\n",
      "Presolved: 10198 rows, 19950 columns, 59355 nonzeros\n",
      "Variable types: 9900 continuous, 10050 integer (10049 binary)\n",
      "Found heuristic solution: objective -14120.35540\n",
      "Found heuristic solution: objective -13993.72640\n",
      "Found heuristic solution: objective -13987.77640\n",
      "\n",
      "Root simplex log...\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "   18946    1.3119988e+03   6.252744e+02   0.000000e+00      5s\n",
      "   26991    1.3110983e+03   0.000000e+00   0.000000e+00      7s\n",
      "\n",
      "Root relaxation: objective 1.311098e+03, 26991 iterations, 6.50 seconds (4.63 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 1311.09831    0  169 -13987.776 1311.09831   109%     -    8s\n",
      "H    0     0                    -13983.76640 1311.09831   109%     -    8s\n",
      "H    0     0                    -9332.522400 1311.09831   114%     -    8s\n",
      "H    0     0                     152.0597675 1311.09831   762%     -    9s\n",
      "H    0     0                     315.2367675 1311.09831   316%     -    9s\n",
      "H    0     0                     315.7517675 1295.96338   310%     -   14s\n",
      "H    0     0                     458.8887675 1295.96338   182%     -   14s\n",
      "H    0     0                     529.9197675 1295.96338   145%     -   14s\n",
      "H    0     0                     530.0817675 1295.96338   144%     -   14s\n",
      "H    0     0                     811.4367677 1295.96338  59.7%     -   14s\n",
      "H    0     0                     812.3497675 1295.96338  59.5%     -   14s\n",
      "H    0     0                     812.4521025 1295.96338  59.5%     -   14s\n",
      "H    0     0                     967.0087675 1295.96338  34.0%     -   14s\n",
      "H    0     0                     974.5767675 1295.96338  33.0%     -   14s\n",
      "H    0     0                     975.4967675 1295.96338  32.9%     -   14s\n",
      "H    0     0                     978.2067675 1295.96338  32.5%     -   14s\n",
      "H    0     0                     978.4297675 1295.96338  32.5%     -   14s\n",
      "H    0     0                    1008.4327675 1295.96338  28.5%     -   14s\n",
      "H    0     0                    1008.7847675 1295.96338  28.5%     -   14s\n",
      "H    0     0                    1008.8487675 1295.96338  28.5%     -   14s\n",
      "     0     0 1295.96338    0  182 1008.84877 1295.96338  28.5%     -   14s\n",
      "H    0     0                    1009.1987675 1295.94517  28.4%     -   16s\n",
      "H    0     0                    1240.6657675 1295.94517  4.46%     -   17s\n",
      "H    0     0                    1240.6667675 1295.94517  4.46%     -   17s\n",
      "     0     0 1279.15531    0  186 1240.66677 1279.15531  3.10%     -   17s\n",
      "     0     0 1279.15531    0  187 1240.66677 1279.15531  3.10%     -   17s\n",
      "     0     0 1273.86462    0  161 1240.66677 1273.86462  2.68%     -   24s\n",
      "     0     0 1273.55012    0  186 1240.66677 1273.55012  2.65%     -   27s\n",
      "     0     0 1273.55012    0  186 1240.66677 1273.55012  2.65%     -   27s\n",
      "H    0     0                    1249.2797675 1272.35588  1.85%     -   30s\n",
      "     0     0 1272.35588    0  160 1249.27977 1272.35588  1.85%     -   30s\n",
      "H    0     0                    1250.3457675 1272.33518  1.76%     -   31s\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "LOOK-AHEAD INTEGRATION + DYNAMIC VRPP TRACE + VISUALIZATION\n",
    "Héctor Bonilla - Full integration with Risk-based Lookahead (corrected MUST-GO logic)\n",
    "Requirements: pandas, gurobipy, matplotlib, openpyxl\n",
    "Adjust file paths before running.\n",
    "\"\"\"\n",
    "\n",
    "# --------------------------\n",
    "# Import libraries\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --------------------------\n",
    "# FILE PATHS (adjust to your environment)\n",
    "file_parameters = r'C:\\Users\\hecto\\OneDrive - Universidade de Lisboa\\PhDtese\\TestVRPP-Determinsit_104bins\\parameters.xlsx'\n",
    "file_distances  = r'C:\\Users\\hecto\\OneDrive - Universidade de Lisboa\\PhDtese\\TestVRPP-Determinsit_104bins\\distance_104bins.xlsx'\n",
    "\n",
    "# Output Excel files for KPIs, flows, dynamic traces, overflow risk, and lookahead traces\n",
    "output_excel_kpi    = r'C:\\Users\\hecto\\OneDrive - Universidade de Lisboa\\PhDtese\\TestVRPP-104bins_KPI_DYNAMIC_LOOKAHEAD_CORRECTED.xlsx'\n",
    "output_excel_flows  = r'C:\\Users\\hecto\\OneDrive - Universidade de Lisboa\\PhDtese\\TestVRPP-104bins_Flows_LOOKAHEAD_CORRECTED.xlsx'\n",
    "output_excel_dynamic = output_excel_kpi.replace(\"_KPI_\",\"_DYNAMIC_\")\n",
    "output_excel_risk = output_excel_kpi.replace(\"_KPI_\",\"_OVERFLOW_RISK_TRACE_\")\n",
    "output_excel_lookahead = output_excel_kpi.replace(\"_KPI_\",\"_LOOKAHEAD_TRACE_\")\n",
    "\n",
    "# --------------------------\n",
    "# PARAMETERS (adjust to model settings)\n",
    "C = 1.0               # Cost per unit distance\n",
    "R = 0.5837            # Revenue per kg collected\n",
    "Omega = 0.1           # Vehicle fixed cost per route\n",
    "Q = 3500.0            # Vehicle flow capacity per arc (kg)\n",
    "delta = 0             # Tolerance in \"hit\" constraint\n",
    "T_days = 10           # Total simulation days\n",
    "T = list(range(1, T_days+1))\n",
    "H_max = 30             # Maximum look-ahead horizon in days\n",
    "B = 19                # Parameter for conversion from percentage to kg\n",
    "vol = 2.5             # Volume factor\n",
    "\n",
    "# --------------------------\n",
    "# READ INPUTS FROM EXCEL\n",
    "# df_params: initial fill (Si), capacity (Ei), mean accumulation per day\n",
    "df_params = pd.read_excel(file_parameters, sheet_name=\"Si_Ei\", engine=\"openpyxl\")\n",
    "IDs_model = df_params[\"ID\"].astype(int).tolist()  # List of bin IDs\n",
    "S_base = {int(r['ID']): float(r['Si']) for _, r in df_params.iterrows()}  # Initial fill in kg\n",
    "E_dict = {int(r['ID']): float(r['Ei']) for _, r in df_params.iterrows()}  # Overflow threshold (capacity)\n",
    "avg_ai = {int(r['ID']): float(r['Mean']) for _, r in df_params.iterrows()}  # Mean daily accumulation in kg/day\n",
    "\n",
    "# df_ait: daily accumulation per bin as percentage, convert to kg\n",
    "df_ait = pd.read_excel(file_parameters, sheet_name=\"%ai_t\", engine=\"openpyxl\")\n",
    "ait_kg_dict = {}\n",
    "for _, row in df_ait.iterrows():\n",
    "    i = int(row['ID'])\n",
    "    for t in T:\n",
    "        col = f'Day {t}'\n",
    "        # convert percentage to kg: (percent/100) * B * vol\n",
    "        if col in df_ait.columns and not pd.isna(row[col]):\n",
    "            ait_kg_dict[(i,t)] = float(row[col]) / 100.0 * B * vol\n",
    "        else:\n",
    "            ait_kg_dict[(i,t)] = 0.0  # if no data, assume 0 accumulation\n",
    "\n",
    "# --------------------------\n",
    "# DISTANCE MATRIX\n",
    "df_dist = pd.read_excel(file_distances, engine=\"openpyxl\", index_col=0)\n",
    "df_dist.index = df_dist.index.astype(int)\n",
    "df_dist.columns = df_dist.columns.astype(int)\n",
    "\n",
    "nodes_real = IDs_model                # Real bin nodes\n",
    "n_bins = len(nodes_real)              # Number of bins\n",
    "fictitious_node = n_bins + 1          # Fictitious node to handle VRP end\n",
    "nodes = [0] + nodes_real + [fictitious_node]  # All nodes: 0=depot, fictitious_node=sink\n",
    "\n",
    "# Build distance dictionary (include mapping for fictitious node)\n",
    "distances = {}\n",
    "for i in nodes:\n",
    "    for j in nodes:\n",
    "        ii = 0 if i == fictitious_node else i\n",
    "        jj = 0 if j == fictitious_node else j\n",
    "        distances[(i,j)] = float(df_dist.loc[ii, jj])\n",
    "\n",
    "# --------------------------\n",
    "# HELPER FUNCTIONS\n",
    "def will_cause_overflow_nextday(S_current_i, avg_ai_i, E_i):\n",
    "    \"\"\"\n",
    "    Predict whether a bin will overflow tomorrow based on current fill and average accumulation.\n",
    "    If S_current + 2*avg_ai >= Ei -> risk of overflow, route should be planned today.\n",
    "    \"\"\"\n",
    "    return (S_current_i + 2.0 * avg_ai_i) >= E_i\n",
    "\n",
    "def compute_nc_for_overflow_bin(i, t, avg_ai, E_dict, T_max):\n",
    "    \"\"\"\n",
    "    Compute next collection day (nc) for bin i.\n",
    "    Start from t+1, sum daily avg_ai until predicted fill exceeds Ei.\n",
    "    If no overflow within horizon, return T_max+1.\n",
    "    \"\"\"\n",
    "    S_temp = 0.0\n",
    "    for tt in range(t+1, T_max+1):\n",
    "        S_temp += avg_ai.get(i, 0.0)\n",
    "        if S_temp >= E_dict[i]:\n",
    "            return tt\n",
    "    return T_max + 1\n",
    "\n",
    "def will_overflow_between_t_and_nc(i, t, nc, S_current, avg_ai, E_dict):\n",
    "    \"\"\"\n",
    "    Check if bin i will overflow at any day in [t, nc], using avg_ai projections.\n",
    "    \"\"\"\n",
    "    S_temp = S_current[i]\n",
    "    for tt in range(t, nc+1):\n",
    "        if tt > t:\n",
    "            S_temp += avg_ai.get(i, 0.0)\n",
    "        if S_temp >= E_dict[i]:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# --------------------------\n",
    "# INITIAL STATE\n",
    "S_current = {i: S_base[i] for i in nodes_real}  # current fill (kg) at start\n",
    "\n",
    "# OUTPUT TABLES\n",
    "dynamic_rows = []        # per-bin daily dynamics\n",
    "kpi_rows = []            # daily KPIs\n",
    "flow_rows = []           # arcs and collection variables\n",
    "overflow_risk_rows = []  # trace of S_current + 2*avg_ai\n",
    "lookahead_rows = []      # lookahead predicted fills per bin\n",
    "mg_trace_rows = []       # MUST-GO membership trace\n",
    "\n",
    "# --------------------------\n",
    "# MAIN SIMULATION LOOP\n",
    "for t in T:\n",
    "    print(f\"\\n=== Day {t} ===\")\n",
    "    t_start_time = time.time()\n",
    "\n",
    "    # Compute Wit_before: fill before collection plus today's accumulation\n",
    "    Wit_before_dict = {i: S_current[i] + ait_kg_dict.get((i,t), 0.0) for i in nodes_real}\n",
    "\n",
    "    # Step A: determine whether a route is needed today (overflow trigger)\n",
    "    overflow_today_bins = []\n",
    "    route_needed_today = False\n",
    "    for i in nodes_real:\n",
    "        if will_cause_overflow_nextday(S_current[i], avg_ai.get(i, 0.0), E_dict[i]):\n",
    "            overflow_today_bins.append(i)\n",
    "            route_needed_today = True\n",
    "\n",
    "    print(\"Initial trigger - bins predicted to overflow (S+2*avg >= Ei):\", overflow_today_bins)\n",
    "\n",
    "    # Record overflow risk for each bin (trace table)\n",
    "    for i in nodes_real:\n",
    "        risk_val = S_current[i] + 2.0 * avg_ai.get(i,0.0)\n",
    "        overflow_risk_rows.append({\n",
    "            \"Day\": t,\n",
    "            \"ID\": i,\n",
    "            \"S_current\": S_current[i],\n",
    "            \"2x_avg_ai\": 2.0 * avg_ai.get(i,0.0),\n",
    "            \"S_current+2avg\": risk_val,\n",
    "            \"Ei\": E_dict[i],\n",
    "            \"Margin_to_Ei\": E_dict[i] - risk_val,\n",
    "            \"RiskStatus\": \"RISK\" if risk_val >= E_dict[i] else \"SAFE\"\n",
    "        })\n",
    "\n",
    "    # If no route needed today, accumulate and continue\n",
    "    if not route_needed_today:\n",
    "        print(\"No route needed today (no triggered overflow). Accumulating a_it for all bins.\")\n",
    "        for i in nodes_real:\n",
    "            S_before = S_current[i]\n",
    "            a_it = ait_kg_dict.get((i, t), 0.0)\n",
    "            Wit_before = S_before + a_it\n",
    "            collected_planned = 0\n",
    "            collected_actual = 0\n",
    "            Wit_collected = 0.0\n",
    "            Profit_before = R * Wit_before if collected_planned == 1 else 0.0\n",
    "            Profit_after = 0.0\n",
    "            S_after = Wit_before\n",
    "            dynamic_rows.append({\n",
    "                \"Day\": t,\n",
    "                \"ID\": i,\n",
    "                \"S_before\": S_before,\n",
    "                \"a_it\": a_it,\n",
    "                \"Wit_before\": Wit_before,\n",
    "                \"Collected_planned\": collected_planned,\n",
    "                \"Collected_actual\": collected_actual,\n",
    "                \"Wit_collected\": Wit_collected,\n",
    "                \"Wit_after\": S_after,\n",
    "                \"Profit_before\": Profit_before,\n",
    "                \"Profit_after\": Profit_after,\n",
    "                \"RiskStatus\": \"SAFE\" if Wit_before < E_dict[i] else \"RISK\"\n",
    "            })\n",
    "            S_current[i] = S_after\n",
    "        # Append KPI row with zero collections\n",
    "        kpi_rows.append({\n",
    "            \"Day\": t,\n",
    "            \"KgCollected\": 0.0,\n",
    "            \"KgOverflow\": 0.0,\n",
    "            \"NumBinsOverflow_All\": 0,\n",
    "            \"IDsBinsOverflow_All\": [],\n",
    "            \"Distance\": 0.0,\n",
    "            \"Profit\": 0.0,\n",
    "            \"VehicleCost\": 0.0,\n",
    "            \"FO\": 0.0,\n",
    "            \"NumVehicles\": 0,\n",
    "            \"BinsVisited\": 0,\n",
    "            \"IDsBinsVisited\": [],\n",
    "            \"BinsNotVisited\": len(nodes_real),\n",
    "            \"IDsBinsNotVisited\": nodes_real,\n",
    "            \"Routes\": [],\n",
    "            \"SolveTime_s\": 0.0\n",
    "        })\n",
    "        continue\n",
    "\n",
    "    # Step B: compute nc (next collection day) based on overflow bins\n",
    "    T_max = min(max(T), t + H_max)  # cap horizon\n",
    "    candidate_nc_days = []\n",
    "    for i in overflow_today_bins:\n",
    "        nc_i = compute_nc_for_overflow_bin(i, t, avg_ai, E_dict, T_max)\n",
    "        if nc_i <= T_max:\n",
    "            candidate_nc_days.append(nc_i)\n",
    "    nc = min(candidate_nc_days) if candidate_nc_days else t\n",
    "    print(f\"Computed next collection day nc = {nc} (based on overflow_today_bins)\")\n",
    "\n",
    "    # Step C: define MUST-GO set MG = bins expected to overflow between t and nc\n",
    "    planned_bins = []\n",
    "    for i in nodes_real:\n",
    "        if will_overflow_between_t_and_nc(i, t, nc, S_current, avg_ai, E_dict):\n",
    "            planned_bins.append(i)\n",
    "    planned_bins = sorted(set(planned_bins))\n",
    "    collected_planned_dict = {i: 1 if i in planned_bins else 0 for i in nodes_real}\n",
    "    print(\"MUST-GO set (planned_bins MG) between t and nc:\", planned_bins)\n",
    "\n",
    "    # Save lookahead trace for visualization\n",
    "    for i in nodes_real:\n",
    "        S_temp = S_current[i]\n",
    "        for tt in range(t, nc+1):\n",
    "            if tt > t:\n",
    "                S_temp += avg_ai.get(i, 0.0)\n",
    "            lookahead_rows.append({\n",
    "                \"Day\": t,\n",
    "                \"ID\": i,\n",
    "                \"HorizonDay\": tt,\n",
    "                \"PredictedFill\": S_temp,\n",
    "                \"Ei\": E_dict[i],\n",
    "                \"DecisionLookahead\": 1 if i in planned_bins else 0,\n",
    "                \"S_current+2avg_ai\": S_current[i] + 2.0*avg_ai.get(i,0.0),\n",
    "                \"nc\": nc\n",
    "            })\n",
    "        mg_trace_rows.append({\n",
    "            \"Day\": t,\n",
    "            \"ID\": i,\n",
    "            \"In_MG\": 1 if i in planned_bins else 0,\n",
    "            \"nc\": nc,\n",
    "            \"S_current\": S_current[i]\n",
    "        })\n",
    "\n",
    "    # --------------------------\n",
    "    # BUILD VRP MODEL (Gurobi)\n",
    "    model = gp.Model(f\"VRP_Lookahead_Day_{t}\")\n",
    "    x = model.addVars(nodes, nodes, vtype=GRB.BINARY, name=\"x\")      # Arc usage\n",
    "    g = model.addVars(nodes_real, vtype=GRB.BINARY, name=\"g\")        # Whether bin visited\n",
    "    f = model.addVars(nodes, nodes, vtype=GRB.CONTINUOUS, lb=0.0, name=\"f\")  # Flow in kg\n",
    "\n",
    "    # Objective: Revenue from collected kg minus distance cost minus vehicle fixed cost\n",
    "    model.setObjective(\n",
    "        R * gp.quicksum(Wit_before_dict[i] * g[i] for i in nodes_real)\n",
    "        - C * gp.quicksum(x[i, j] * distances[(i, j)] for i in nodes for j in nodes if i != j)\n",
    "        - Omega * gp.quicksum(x[0, j] for j in nodes_real),\n",
    "        GRB.MAXIMIZE\n",
    "    )\n",
    "\n",
    "    # 1) If Wit_before==0, cannot collect\n",
    "    model.addConstrs((g[i] == 0 for i in nodes_real if Wit_before_dict.get(i, 0.0) == 0.0), name=\"no_collect_empty\")\n",
    "    # 2) Enforce MUST-GO bins\n",
    "    for i in planned_bins:\n",
    "        model.addConstr(g[i] == 1)\n",
    "    # 3) Linking arcs: sum incoming arcs == g[j] for each bin\n",
    "    model.addConstrs(\n",
    "        (gp.quicksum(x[i, j] for i in nodes if i != fictitious_node and i != j) == g[j]\n",
    "         for j in nodes_real),\n",
    "        name=\"linking_in\"\n",
    "    )\n",
    "    # 4) g bounds <=1\n",
    "    model.addConstrs((g[i] <= 1 for i in nodes_real), name=\"g_ub1\")\n",
    "    # 5) Hit constraint: serve at least planned MG bins\n",
    "    model.addConstr(\n",
    "        gp.quicksum(g[i] for i in planned_bins) >= len(planned_bins) - n_bins * delta,\n",
    "        name=\"hit_constraint\"\n",
    "    )\n",
    "    # 6) Depot balance: leaving depot == returning\n",
    "    model.addConstr(\n",
    "        gp.quicksum(x[0, j] for j in nodes if j != 0) - gp.quicksum(x[i, 0] for i in nodes if i != fictitious_node) == 0,\n",
    "        name=\"depot_balance\"\n",
    "    )\n",
    "    # 7) Node balance for intermediate nodes\n",
    "    model.addConstrs(\n",
    "        (gp.quicksum(x[i, h] for i in nodes if i != fictitious_node) - gp.quicksum(x[h, j] for j in nodes if j != 0) == 0\n",
    "         for h in nodes_real),\n",
    "        name=\"node_balance\"\n",
    "    )\n",
    "    # 8) Flow capacity linking: f <= Q*x\n",
    "    model.addConstrs((f[i, j] <= Q * x[i, j] for i in nodes for j in nodes if i != j), name=\"flow_capacity\")\n",
    "    # 9) Flow balance: collected mass\n",
    "    model.addConstrs(\n",
    "        (gp.quicksum(f[i, j] for j in nodes if j != 0) - gp.quicksum(f[j, i] for j in nodes if j != fictitious_node)\n",
    "         == Wit_before_dict[i] * g[i] for i in nodes_real),\n",
    "        name=\"flow_balance_mass\"\n",
    "    )\n",
    "\n",
    "    # Solver parameters\n",
    "    model.Params.TimeLimit = 300\n",
    "    model.Params.MIPGap = 1e-3\n",
    "    model.optimize()\n",
    "\n",
    "    # --------------------------\n",
    "    # UPDATE DYNAMICS PER BIN\n",
    "    print(\"\\nDay summary (per bin):\")\n",
    "    total_collected_kg = 0.0\n",
    "    for i in nodes_real:\n",
    "        S_before = S_current[i]\n",
    "        a_it = ait_kg_dict.get((i, t), 0.0)\n",
    "        Wit_before = Wit_before_dict[i]\n",
    "        collected_planned = collected_planned_dict[i]\n",
    "        collected_actual = 1 if (hasattr(g[i], 'X') and g[i].X > 0.5) else 0\n",
    "        Wit_collected = Wit_before if collected_actual == 1 else 0.0\n",
    "        Profit_before = R * Wit_before if collected_planned == 1 else 0.0\n",
    "        Profit_after = R * Wit_collected\n",
    "        total_collected_kg += Wit_collected\n",
    "        S_after = 0.0 if collected_actual == 1 else (S_before + a_it)\n",
    "\n",
    "        dynamic_rows.append({\n",
    "            \"Day\": t,\n",
    "            \"ID\": i,\n",
    "            \"S_before\": S_before,\n",
    "            \"a_it\": a_it,\n",
    "            \"Wit_before\": Wit_before,\n",
    "            \"Collected_planned\": collected_planned,\n",
    "            \"Collected_actual\": collected_actual,\n",
    "            \"Wit_collected\": Wit_collected,\n",
    "            \"Wit_after\": S_after,\n",
    "            \"Profit_before\": Profit_before,\n",
    "            \"Profit_after\": Profit_after,\n",
    "            \"In_MG\": 1 if i in planned_bins else 0,\n",
    "            \"nc\": nc\n",
    "        })\n",
    "\n",
    "        print(f\"Bin {i} | S_before={S_before:.2f} | a_it={a_it:.2f} | Wit_before={Wit_before:.2f} | \"\n",
    "              f\"Planned={collected_planned} | Actual={collected_actual} | Wit_collected={Wit_collected:.2f} | \"\n",
    "              f\"Wit_after={S_after:.2f} | Profit_before={Profit_before:.2f} | Profit_after={Profit_after:.2f}\")\n",
    "\n",
    "        # update state\n",
    "        S_current[i] = S_after\n",
    "\n",
    "# --------------------------\n",
    "# EXPORT RESULTS\n",
    "pd.DataFrame(dynamic_rows).to_excel(output_excel_dynamic, index=False)\n",
    "pd.DataFrame(kpi_rows).to_excel(output_excel_kpi, index=False)\n",
    "pd.DataFrame(flow_rows).to_excel(output_excel_flows, index=False)\n",
    "pd.DataFrame(overflow_risk_rows).to_excel(output_excel_risk, index=False)\n",
    "pd.DataFrame(lookahead_rows).to_excel(output_excel_lookahead, index=False)\n",
    "\n",
    "print(\"\\nSimulation completed. All dynamic, KPI, flow, overflow risk, and lookahead tables exported.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f757d83d-67f8-4068-8e36-06b26c134fee",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Day'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 56\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m days:\n\u001b[0;32m     55\u001b[0m     df_day_kpi \u001b[38;5;241m=\u001b[39m df_kpi[df_kpi[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDay\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m t]\n\u001b[1;32m---> 56\u001b[0m     df_day_flows \u001b[38;5;241m=\u001b[39m df_flows[df_flows[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDay\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m t]\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;66;03m# --------------------------\u001b[39;00m\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;66;03m# Nodos visitados y no visitados\u001b[39;00m\n\u001b[0;32m     60\u001b[0m     bins_visited \u001b[38;5;241m=\u001b[39m df_day_kpi[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIDsBinsVisited\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3893\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3891\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3892\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3893\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   3894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3895\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\range.py:418\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    416\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[1;32m--> 418\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n\u001b[0;32m    420\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Day'"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "DYNAMIC VRPP VISUALIZATION WITH FULL KPI TOOLTIP\n",
    "Héctor Bonilla - Interactive Dashboard with Look-Ahead, Overflow, MG, and KPIs\n",
    "Requirements: pandas, plotly, openpyxl\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# --------------------------\n",
    "# FILE PATHS\n",
    "file_coordinates = r'C:\\Users\\hecto\\OneDrive - Universidade de Lisboa\\PhDtese\\TestVRPP-Determinsit_104bins\\coordinates104.xlsx'\n",
    "file_kpi = output_excel_kpi      # exportado previamente por la simulación\n",
    "file_flows = output_excel_flows  # exportado previamente por la simulación\n",
    "\n",
    "# --------------------------\n",
    "# READ DATA\n",
    "# Leer coordenadas directamente desde el archivo\n",
    "df_coords = pd.read_excel(file_coordinates, engine=\"openpyxl\")\n",
    "\n",
    "# Crear diccionarios de coordenadas usando ID como clave\n",
    "# X = Lat, Y = Lon (puedes cambiar si tu sistema de coordenadas es diferente)\n",
    "x_coords = {int(r['ID']): float(r['Lat']) for _, r in df_coords.iterrows()}\n",
    "y_coords = {int(r['ID']): float(r['Lon']) for _, r in df_coords.iterrows()}\n",
    "\n",
    "# --------------------------\n",
    "# Depot\n",
    "# Asumiendo que ID = 0 es el depósito, usamos sus coordenadas directamente\n",
    "x_coords[0] = df_coords.loc[df_coords['ID'] == 0, 'Lon'].values[0]\n",
    "y_coords[0] = df_coords.loc[df_coords['ID'] == 0, 'Lat'].values[0]\n",
    "\n",
    "# Nodo ficticio para algoritmos de flujo (si aplica)\n",
    "fictitious_node_id = max(x_coords.keys()) + 1\n",
    "x_coords[fictitious_node_id] = x_coords[0]\n",
    "y_coords[fictitious_node_id] = y_coords[0]\n",
    "\n",
    "# --------------------------\n",
    "# Leer KPI y flujos\n",
    "df_kpi = pd.read_excel(file_kpi, engine=\"openpyxl\")\n",
    "df_flows = pd.read_excel(file_flows, engine=\"openpyxl\")\n",
    "\n",
    "# --------------------------\n",
    "# NODOS REALES (sin depot ni ficticio)\n",
    "nodes_real = [i for i in x_coords.keys() if i not in [0, fictitious_node_id]]\n",
    "\n",
    "# --------------------------\n",
    "# FIGURA INTERACTIVA\n",
    "fig = go.Figure()\n",
    "days = sorted(df_kpi['Day'].unique())\n",
    "\n",
    "# --------------------------\n",
    "# Loop por día para generar traces interactivos\n",
    "for t in days:\n",
    "    df_day_kpi = df_kpi[df_kpi['Day'] == t]\n",
    "    df_day_flows = df_flows[df_flows['Day'] == t]\n",
    "\n",
    "    # --------------------------\n",
    "    # Nodos visitados y no visitados\n",
    "    bins_visited = df_day_kpi['IDsBinsVisited'].values[0]\n",
    "    bins_not_visited = df_day_kpi['IDsBinsNotVisited'].values[0]\n",
    "    if isinstance(bins_visited, str): bins_visited = eval(bins_visited)\n",
    "    if isinstance(bins_not_visited, str): bins_not_visited = eval(bins_not_visited)\n",
    "\n",
    "    # --------------------------\n",
    "    # Extraer KPIs de cada bin\n",
    "    # Suponemos que df_day_kpi tiene columnas como:\n",
    "    # 'S_current', 'Collected', 'Overflow', 'Profit', 'MG_member', 'Lookahead_fill'\n",
    "    bin_kpis = {}\n",
    "    for _, row in df_day_kpi.iterrows():\n",
    "        for i in nodes_real:\n",
    "            bin_kpis[i] = {\n",
    "                'S_current': row.get(f'S_current_{i}', 0),\n",
    "                'Collected': row.get(f'Collected_{i}', 0),\n",
    "                'Overflow': row.get(f'Overflow_{i}', 0),\n",
    "                'Profit': row.get(f'Profit_{i}', 0),\n",
    "                'MG_member': row.get(f'MG_member_{i}', 0),\n",
    "                'Lookahead_fill': row.get(f'Lookahead_fill_{i}', 0)\n",
    "            }\n",
    "\n",
    "    # --------------------------\n",
    "    # TRACE NODOS VISITADOS con tooltip completo\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=[x_coords[i] for i in bins_visited],\n",
    "        y=[y_coords[i] for i in bins_visited],\n",
    "        mode='markers',\n",
    "        marker=dict(color='green', size=10, symbol='circle'),\n",
    "        name='Visited',\n",
    "        text=[(\n",
    "            f\"ID: {i}<br>\"\n",
    "            f\"Fill: {bin_kpis[i]['S_current']:.1f} kg<br>\"\n",
    "            f\"Collected: {bin_kpis[i]['Collected']:.1f} kg<br>\"\n",
    "            f\"Overflow: {bin_kpis[i]['Overflow']:.1f} kg<br>\"\n",
    "            f\"Profit: {bin_kpis[i]['Profit']:.2f}<br>\"\n",
    "            f\"MG member: {bin_kpis[i]['MG_member']}<br>\"\n",
    "            f\"Predicted Fill: {bin_kpis[i]['Lookahead_fill']:.1f} kg\"\n",
    "        ) for i in bins_visited],\n",
    "        hoverinfo='text',\n",
    "        visible=(t==days[0])\n",
    "    ))\n",
    "\n",
    "    # TRACE NODOS NO VISITADOS\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=[x_coords[i] for i in bins_not_visited],\n",
    "        y=[y_coords[i] for i in bins_not_visited],\n",
    "        mode='markers',\n",
    "        marker=dict(color='red', size=10, symbol='x'),\n",
    "        name='Not Visited',\n",
    "        text=[(\n",
    "            f\"ID: {i}<br>\"\n",
    "            f\"Fill: {bin_kpis[i]['S_current']:.1f} kg<br>\"\n",
    "            f\"Collected: {bin_kpis[i]['Collected']:.1f} kg<br>\"\n",
    "            f\"Overflow: {bin_kpis[i]['Overflow']:.1f} kg<br>\"\n",
    "            f\"Profit: {bin_kpis[i]['Profit']:.2f}<br>\"\n",
    "            f\"MG member: {bin_kpis[i]['MG_member']}<br>\"\n",
    "            f\"Predicted Fill: {bin_kpis[i]['Lookahead_fill']:.1f} kg\"\n",
    "        ) for i in bins_not_visited],\n",
    "        hoverinfo='text',\n",
    "        visible=(t==days[0])\n",
    "    ))\n",
    "\n",
    "    # DEPOT\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=[x_coords[0]],\n",
    "        y=[y_coords[0]],\n",
    "        mode='markers',\n",
    "        marker=dict(color='blue', size=12, symbol='square'),\n",
    "        name='Depot',\n",
    "        text=['Depot'],\n",
    "        hoverinfo='text',\n",
    "        visible=(t==days[0])\n",
    "    ))\n",
    "\n",
    "    # --------------------------\n",
    "    # RUTAS (arcos activos)\n",
    "    arcs = df_day_flows[df_day_flows['Var']=='x']\n",
    "    for _, row in arcs.iterrows():\n",
    "        i, j = int(row['i']), int(row['j'])\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=[x_coords[i], x_coords[j]],\n",
    "            y=[y_coords[i], y_coords[j]],\n",
    "            mode='lines',\n",
    "            line=dict(width=2, color='orange'),\n",
    "            name='Route',\n",
    "            visible=(t==days[0]),\n",
    "            hoverinfo='none'\n",
    "        ))\n",
    "\n",
    "# --------------------------\n",
    "# SLIDER POR DÍA\n",
    "steps = []\n",
    "for i, t in enumerate(days):\n",
    "    step = dict(\n",
    "        method='update',\n",
    "        args=[{'visible':[False]*len(fig.data)},\n",
    "              {'title': f\"Day {t} Routes and Bins\"}],\n",
    "        label=f\"Day {t}\"\n",
    "    )\n",
    "    n_traces_per_day = len(fig.data) // len(days)\n",
    "    for j in range(n_traces_per_day):\n",
    "        step['args'][0]['visible'][i*n_traces_per_day + j] = True\n",
    "    steps.append(step)\n",
    "\n",
    "sliders = [dict(\n",
    "    active=0,\n",
    "    currentvalue={\"prefix\": \"Day: \"},\n",
    "    pad={\"t\": 50},\n",
    "    steps=steps\n",
    ")]\n",
    "\n",
    "# --------------------------\n",
    "# LAYOUT FINAL\n",
    "fig.update_layout(\n",
    "    sliders=sliders,\n",
    "    title=\"Dynamic VRPP Visualization - Full KPI Dashboard\",\n",
    "    xaxis_title=\"Longitude\",\n",
    "    yaxis_title=\"Latitude\",\n",
    "    showlegend=True,\n",
    "    height=700\n",
    ")\n",
    "\n",
    "# --------------------------\n",
    "# MOSTRAR FIGURA\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc87e3c3-0eb8-4658-bc4c-7f1d5d155b1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
