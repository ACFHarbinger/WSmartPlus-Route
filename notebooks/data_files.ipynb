{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "159ed5de",
   "metadata": {},
   "source": [
    "# WSmart+ Route Data Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd972776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already added home_dir to system path: /home/pkhunter/Repositories/WSmart-Route\n"
     ]
    }
   ],
   "source": [
    "from notebook_setup import setup_google_colab, setup_home_directory\n",
    "\n",
    "NOTEBOOK_NAME = \"data_files\"\n",
    "home_dir = setup_home_directory(NOTEBOOK_NAME)\n",
    "IN_COLAB, gdrive, gfiles = setup_google_colab(NOTEBOOK_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57dbcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from logic.src.pipeline.simulator.wsmart_bin_analysis import OldGridBase\n",
    "from logic.src.utils.io_utils import chunk_zip_content, reassemble_files\n",
    "\n",
    "MAX_DISPLAY_ROWS = 500\n",
    "np.set_printoptions(suppress=True)\n",
    "pd.set_option(\"display.max_rows\", MAX_DISPLAY_ROWS)\n",
    "\n",
    "SHOW_TABLES = False\n",
    "if IN_COLAB:\n",
    "    gdrive.mount(\"/content/drive\")\n",
    "\n",
    "# Required to use matplotlib in Windows without breaking the Kernel\n",
    "if os.name == \"nt\":\n",
    "    os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"True\"\n",
    "\n",
    "seed = 42\n",
    "n_days = 30\n",
    "n_bins = 104\n",
    "n_samples = 1\n",
    "data_dist = \"emp\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5303f1",
   "metadata": {},
   "source": [
    "## Daily waste data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88c7d18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join(home_dir, \"data\", \"wsr_simulator\")\n",
    "file_path = os.path.join(data_dir, \"daily_waste\", \"enchimentos_abril_2024_cleaned.xlsx\")\n",
    "clean_df = (\n",
    "    pd.read_excel(file_path)\n",
    "    .rename(columns={\"Fill Level_Day 0\": \"Day 0\"})\n",
    "    .drop(columns=[\"Day 31\"])\n",
    ")\n",
    "if SHOW_TABLES:\n",
    "    display(clean_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2095c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join(home_dir, \"data\", \"wsr_simulator\")\n",
    "file_path = os.path.join(data_dir, \"daily_waste\", \"april_2024_summary.csv\")\n",
    "clean_df = pd.read_csv(file_path).rename(columns={\"Fill Level_Day 0\": \"Day 0\"})\n",
    "if SHOW_TABLES:\n",
    "    display(clean_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f022b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_waste_path = os.path.join(\n",
    "    home_dir,\n",
    "    \"daily_waste\",\n",
    "    f\"{area}{n_bins}_{data_dist}_wsr{n_days}_N{n_samples}_seed{seed}.pkl\",\n",
    ")\n",
    "if not os.path.exists(daily_waste_path):\n",
    "    clean_df.to_pickle(daily_waste_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7498dad0",
   "metadata": {},
   "source": [
    "## Coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f0eca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_old_wsba_coords(bins_coords):\n",
    "    bins_coords = bins_coords.rename(columns={\"Latitude\": \"Lat\", \"Longitude\": \"Lng\"})\n",
    "    bins_coords = bins_coords[[\"ID\", \"Lat\", \"Lng\"]]\n",
    "    return bins_coords.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca006ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "area = \"Rio Maior\"\n",
    "grid = OldGridBase(data_dir, area)\n",
    "_, info = grid.load_data()\n",
    "waste_types = [\"Mistura de embalagens\", \"Embalagens de papel e cart√£o\"]\n",
    "plastic_bins = info[info[\"Tipo de Residuos\"] == waste_types[0]]\n",
    "plastic_df = process_old_wsba_coords(plastic_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd99f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df_coords = plastic_df[plastic_df[\"ID\"].isin(clean_df[\"ID\"])]\n",
    "clean_df_coords = clean_df_coords.sort_values(\"ID\").reset_index(drop=True)\n",
    "clean_coords_file = os.path.join(\n",
    "    data_dir, \"coordinates\", \"coordenadas_abril_2024_cleaned.xlsx\"\n",
    ")\n",
    "if not os.path.exists(clean_coords_file):\n",
    "    clean_df_coords.to_excel(clean_coords_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4d1a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_file = os.path.join(\n",
    "    data_dir, \"bins_selection\", f\"graphs_{n_bins}V_1N_plastic.json\"\n",
    ")\n",
    "with open(selection_file) as fp:\n",
    "    indices = json.load(fp)\n",
    "\n",
    "clean_arr = clean_df.drop(columns=[\"ID\", \"Mean\", \"StD\"]).to_numpy()\n",
    "clean_arr = np.swapaxes(clean_arr[indices], 1, 2)\n",
    "daily_waste_file = os.path.join(\n",
    "    data_dir, \"daily_waste\", f\"riomaior{n_bins}_emp_wsr{n_days}_N1_seed{seed}.pkl\"\n",
    ")\n",
    "with open(daily_waste_file, \"wb\") as fp:\n",
    "    pickle.dump(clean_arr, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d318736b",
   "metadata": {},
   "source": [
    "## Distance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "17c88c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm_path = os.path.join(\n",
    "    data_dir, \"distance_matrix\", \"gmaps_distmat_plastic[riomaior].csv\"\n",
    ")\n",
    "dist_mat = np.loadtxt(dm_path, delimiter=\",\")\n",
    "dm_ids = pd.concat([pd.Series([0]), clean_df_coords[\"ID\"]], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d9fef663",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = dist_mat[0].astype(int)\n",
    "data_rows = dist_mat[1:]\n",
    "df = pd.DataFrame(data=data_rows, columns=col_names)\n",
    "df[-1] = df[-1].astype(int)\n",
    "df_matrix = df.set_index(-1)\n",
    "df_matrix = df_matrix.loc[dm_ids, dm_ids]\n",
    "df_matrix.to_csv(\n",
    "    os.path.join(data_dir, \"distance_matrix\", \"gmaps_distmat_plastic104[riomaior].csv\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "166dc792",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "261.9850000000001"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_arr = np.loadtxt(\n",
    "    os.path.join(data_dir, \"distance_matrix\", \"gmaps_distmat_plastic104[riomaior].csv\"),\n",
    "    delimiter=\",\",\n",
    ")[1:, 1:]\n",
    "idx = [\n",
    "    0,\n",
    "    60,\n",
    "    34,\n",
    "    10,\n",
    "    64,\n",
    "    94,\n",
    "    78,\n",
    "    102,\n",
    "    44,\n",
    "    59,\n",
    "    82,\n",
    "    15,\n",
    "    5,\n",
    "    20,\n",
    "    77,\n",
    "    29,\n",
    "    32,\n",
    "    12,\n",
    "    79,\n",
    "    28,\n",
    "    27,\n",
    "    51,\n",
    "    7,\n",
    "    21,\n",
    "    67,\n",
    "    8,\n",
    "    19,\n",
    "    81,\n",
    "    70,\n",
    "    74,\n",
    "    71,\n",
    "    54,\n",
    "    24,\n",
    "    69,\n",
    "    36,\n",
    "    22,\n",
    "    23,\n",
    "    47,\n",
    "    38,\n",
    "    6,\n",
    "    85,\n",
    "    48,\n",
    "    100,\n",
    "    86,\n",
    "    18,\n",
    "    96,\n",
    "    55,\n",
    "    14,\n",
    "    33,\n",
    "    92,\n",
    "    13,\n",
    "    97,\n",
    "    61,\n",
    "    91,\n",
    "    26,\n",
    "    35,\n",
    "    39,\n",
    "    58,\n",
    "    75,\n",
    "    53,\n",
    "    2,\n",
    "    73,\n",
    "    43,\n",
    "    103,\n",
    "    11,\n",
    "    31,\n",
    "    62,\n",
    "    3,\n",
    "    95,\n",
    "    37,\n",
    "    101,\n",
    "    42,\n",
    "    17,\n",
    "    76,\n",
    "    66,\n",
    "    16,\n",
    "    41,\n",
    "    56,\n",
    "    4,\n",
    "    57,\n",
    "    1,\n",
    "    99,\n",
    "    25,\n",
    "    87,\n",
    "    104,\n",
    "    68,\n",
    "    72,\n",
    "    88,\n",
    "    9,\n",
    "    40,\n",
    "    65,\n",
    "    63,\n",
    "    30,\n",
    "    45,\n",
    "    93,\n",
    "    80,\n",
    "    98,\n",
    "    89,\n",
    "    49,\n",
    "    84,\n",
    "    83,\n",
    "    90,\n",
    "    50,\n",
    "    46,\n",
    "    52,\n",
    "    0,\n",
    "]\n",
    "row_idx = idx[:-1]\n",
    "col_idx = idx[1:]\n",
    "values = np_arr[row_idx, col_idx]\n",
    "dist = 0\n",
    "for id, _ in enumerate(idx):\n",
    "    if id == len(idx) - 1:\n",
    "        break\n",
    "    dist += np_arr[idx[id], idx[id + 1]]\n",
    "dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35ad12c",
   "metadata": {},
   "source": [
    "## Reassamble large files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1918dac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "GITHUB_MAX_MBSIZE = 95 * 1000**2\n",
    "waste_data_dir = os.path.join(data_dir, \"bins_waste\")\n",
    "zip_path = os.path.join(\n",
    "    waste_data_dir, \"wetransfer_dados-rio-maior_2025-03-19_1615.zip\"\n",
    ")\n",
    "if os.path.isfile(zip_path):\n",
    "    zip_mbsize = os.path.getsize(zip_path)\n",
    "    chunk_files = chunk_zip_content(zip_path, GITHUB_MAX_MBSIZE, waste_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f8a269f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files = reassemble_files(waste_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9f88fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "collections_path = os.path.join(\n",
    "    waste_data_dir, \"Enchimentos_com_Recolhas[RioMaior].csv\"\n",
    ")\n",
    "sensors_path = os.path.join(waste_data_dir, \"Enchimentos_de_Sensores[RioMaior].csv\")\n",
    "collections = pd.read_csv(collections_path, delimiter=\",\")\n",
    "sensors = pd.read_csv(sensors_path, delimiter=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c222aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "collections[\"Matricula do contentor\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a058d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors[\"Matricula do contentor\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb668c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ucoll = collections.drop_duplicates(keep=\"first\", subset=\"Matricula do contentor\")\n",
    "ucoll[\"description\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d143b9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "usensor = sensors.drop_duplicates(keep=\"first\", subset=\"Matricula do contentor\")\n",
    "usensor[\"description\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f72f9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "collections.to_csv(collections_path, index=False)\n",
    "if SHOW_TABLES:\n",
    "    display(collections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6290f290",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_row = 524904\n",
    "sensors1 = sensors.iloc[:split_row]\n",
    "sensors2 = sensors.iloc[split_row:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1697e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHOW_TABLES:\n",
    "    display(sensors1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f1159a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHOW_TABLES:\n",
    "    display(sensors2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
