{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "159ed5de",
   "metadata": {},
   "source": [
    "# WSmart+ Route Data Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd972776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup completed - added home_dir to system path: /home/pkhunter/Repositories/WSmart-Route\n"
     ]
    }
   ],
   "source": [
    "from notebook_setup import setup_home_directory, setup_google_colab\n",
    "\n",
    "\n",
    "NOTEBOOK_NAME = 'data_files'\n",
    "home_dir = setup_home_directory(NOTEBOOK_NAME)\n",
    "IN_COLAB, gdrive, gfiles = setup_google_colab(NOTEBOOK_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b57dbcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from src.pipeline.simulator.wsmart_bin_analysis import OldGridBase\n",
    "from src.utils.io_utils import chunk_zip_content, reassemble_files\n",
    "\n",
    "\n",
    "MAX_DISPLAY_ROWS = 500\n",
    "pd.set_option('display.max_rows', MAX_DISPLAY_ROWS)\n",
    "\n",
    "SHOW_TABLES = False\n",
    "if IN_COLAB: \n",
    "    gdrive.mount('/content/drive')\n",
    "\n",
    "# Required to use matplotlib in Windows without breaking the Kernel\n",
    "if os.name == 'nt':\n",
    "    os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba285333",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_old_wsba_coords(bins_coords):\n",
    "    bins_coords = bins_coords.rename(columns={'Latitude': 'Lat', 'Longitude': 'Lng'})\n",
    "    bins_coords = bins_coords[['ID', 'Lat', 'Lng']]\n",
    "    return bins_coords.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88c7d18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join(home_dir, \"data\", \"wsr_simulator\")\n",
    "file_path = os.path.join(data_dir, 'daily_waste', 'enchimentos_abril_2024_cleaned.xlsx')\n",
    "clean_df = pd.read_excel(file_path).rename(columns={'Fill Level_Day 0': 'Day 0'}).drop(columns=['Day 31'])\n",
    "if SHOW_TABLES: display(clean_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "601db946",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join(home_dir, \"data\", \"wsr_simulator\")\n",
    "file_path = os.path.join(data_dir, 'daily_waste', 'april_2024_summary.csv')\n",
    "clean_df = pd.read_csv(file_path).rename(columns={'Fill Level_Day 0': 'Day 0'}).drop(columns=['Day 31'])\n",
    "if SHOW_TABLES: display(clean_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ca006ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "area = \"Rio Maior\"\n",
    "grid = OldGridBase(data_dir, area)\n",
    "_, info = grid.load_data()\n",
    "waste_types = ['Mistura de embalagens', 'Embalagens de papel e cart√£o']\n",
    "plastic_bins = info[info['Tipo de Residuos'] == waste_types[0]]\n",
    "plastic_df = process_old_wsba_coords(plastic_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bd99f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df_coords = plastic_df[plastic_df['ID'].isin(clean_df['ID'])]\n",
    "clean_df_coords = clean_df_coords.sort_values('ID').reset_index(drop=True)\n",
    "clean_coords_file = os.path.join(data_dir, 'coordinates', 'coordenadas_abril_2024_cleaned.xlsx')\n",
    "if not os.path.exists(clean_coords_file): clean_df_coords.to_excel(clean_coords_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a4d1a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_file = os.path.join(data_dir, 'bins_selection', 'graphs_100V_1N_plastic.json')\n",
    "with open(selection_file) as fp:\n",
    "    indices = json.load(fp)\n",
    "\n",
    "clean_arr = clean_df.drop(columns=['ID', 'Mean', 'StD']).to_numpy()\n",
    "clean_arr = np.swapaxes(clean_arr[indices], 1, 2)\n",
    "daily_waste_file = os.path.join(data_dir, 'daily_waste', 'riomaior100_emp_wsr31_N1_seed42.pkl')\n",
    "with open(daily_waste_file, 'wb') as fp:\n",
    "    pickle.dump(clean_arr, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35ad12c",
   "metadata": {},
   "source": [
    "## Reassamble large files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1918dac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "GITHUB_MAX_MBSIZE = 95 * 1000**2\n",
    "waste_data_dir = os.path.join(data_dir, 'bins_waste')\n",
    "zip_path = os.path.join(waste_data_dir, \"wetransfer_dados-rio-maior_2025-03-19_1615.zip\")\n",
    "if os.path.isfile(zip_path):\n",
    "    zip_mbsize = os.path.getsize(zip_path)\n",
    "    chunk_files = chunk_zip_content(zip_path, GITHUB_MAX_MBSIZE, waste_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f8a269f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files = reassemble_files(waste_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9f88fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "collections_path = os.path.join(waste_data_dir, \"Enchimentos_com_Recolhas[RioMaior].csv\")\n",
    "sensors_path = os.path.join(waste_data_dir, \"Enchimentos_de_Sensores[RioMaior].csv\")\n",
    "collections = pd.read_csv(collections_path, delimiter=',')\n",
    "sensors = pd.read_csv(sensors_path, delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c222aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "collections['Matricula do contentor'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a058d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors['Matricula do contentor'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb668c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ucoll = collections.drop_duplicates(keep='first', subset='Matricula do contentor')\n",
    "ucoll['description'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d143b9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "usensor = sensors.drop_duplicates(keep='first', subset='Matricula do contentor')\n",
    "usensor['description'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f72f9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "collections.to_csv(collections_path, index=False)\n",
    "if SHOW_TABLES: display(collections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6290f290",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_row = 524904\n",
    "sensors1 = sensors.iloc[:split_row]\n",
    "sensors2 = sensors.iloc[split_row:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1697e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHOW_TABLES: display(sensors1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f1159a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHOW_TABLES: display(sensors2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wsmart-route",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
