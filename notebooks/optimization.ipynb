{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WSmart+ Route Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already added home_dir to system path: /home/pkhunter/Repositories/WSmart-Route\n"
     ]
    }
   ],
   "source": [
    "from notebook_setup import setup_google_colab, setup_home_directory\n",
    "\n",
    "NOTEBOOK_NAME = \"optimization\"\n",
    "home_dir = setup_home_directory(NOTEBOOK_NAME)\n",
    "IN_COLAB, gdrive, gfiles = setup_google_colab(NOTEBOOK_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    %pip install fast-tsp\n",
    "    %pip install gurobipy\n",
    "    %pip install shapely\n",
    "    %pip install matplotlib\n",
    "    %pip install tqdm\n",
    "    %pip install pandas\n",
    "    %pip install torch\n",
    "    %pip install cuda-cudart\n",
    "    %pip install cudatoolkit\n",
    "    %pip install jupyter\n",
    "    %pip install networkx\n",
    "    %pip install numpy\n",
    "    %pip install torch_geometric\n",
    "    %pip install ortools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pprint as pp\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "import traceback\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "%matplotlib inline\n",
    "from __future__ import print_function\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from logic.src.pipeline.simulator.bins import Bins\n",
    "from logic.src.pipeline.simulator.day import get_daily_results, set_daily_waste\n",
    "from logic.src.pipeline.simulator.loader import (\n",
    "    load_area_and_waste_type_params,\n",
    "    load_depot,\n",
    "    load_indices,\n",
    "    load_simulator_data,\n",
    ")\n",
    "from logic.src.pipeline.simulator.network import (\n",
    "    apply_edges,\n",
    "    compute_distance_matrix,\n",
    "    get_paths_between_states,\n",
    ")\n",
    "from logic.src.pipeline.simulator.processor import process_data, process_model_data\n",
    "from logic.src.pipeline.simulator.wsmart_bin_analysis import OldGridBase\n",
    "from logic.src.policies import (\n",
    "    create_points,\n",
    "    find_route,\n",
    "    find_solutions,\n",
    "    get_route_cost,\n",
    "    policy_gurobi_vrpp,\n",
    "    policy_hexaly_vrpp,\n",
    "    policy_last_minute,\n",
    "    policy_last_minute_and_path,\n",
    "    policy_lookahead,\n",
    "    policy_lookahead_sans,\n",
    "    policy_lookahead_vrpp,\n",
    "    policy_regular,\n",
    ")\n",
    "from logic.src.utils.definitions import DAY_METRICS, SIM_METRICS, TQDM_COLOURS\n",
    "from logic.src.utils.functions import load_model\n",
    "from logic.src.utils.log_utils import log_plot, log_to_json, log_to_pickle\n",
    "from logic.src.utils.plot_utils import plot_attention_maps_wrapper\n",
    "from logic.src.utils.setup_utils import setup_hrl_manager\n",
    "from tqdm import tqdm\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "FIXED_POINT_NOTATION = True  # False to use scientific notation instead\n",
    "FLOAT_DIGITS_PRECISION = 15\n",
    "np.set_printoptions(precision=FLOAT_DIGITS_PRECISION)\n",
    "np.set_printoptions(suppress=FIXED_POINT_NOTATION)\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "if IN_COLAB:\n",
    "    gdrive.mount(\"/content/drive\")\n",
    "\n",
    "# Required to use matplotlib in Windows without breaking the Kernel\n",
    "if os.name == \"nt\":\n",
    "    os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"True\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimental Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ndays = 30\n",
    "number_of_bins = 100\n",
    "n_bins = number_of_bins + 1  # with depot\n",
    "NC = n_bins\n",
    "binsids = np.arange(0, NC - 1).tolist()\n",
    "\n",
    "area = \"Rio Maior\"\n",
    "waste_type = \"plastic\"\n",
    "data_distribution = \"gamma\"  # \"emp\"\n",
    "area = re.sub(\n",
    "    r\"[^a-zA-Z]\", \"\", area.lower()\n",
    ")  # area.translate(str.maketrans('', '', '-_ ')).lower()\n",
    "\n",
    "model_id = 0\n",
    "gamma_option = 0\n",
    "model_names = [\"amgat\", \"amgat_hrl\"]  # [\"amgat\", \"amgac\", \"amtgc\"]\n",
    "inner_dir = f\"gamma{gamma_option + 1}\" if data_distribution == \"gamma\" else \"emp\"\n",
    "\n",
    "data_dir = os.path.join(home_dir, \"data\", \"wsr_simulator\")\n",
    "output_dir = os.path.join(\n",
    "    home_dir, \"assets\", \"output\", f\"{Ndays}_days\", f\"{area}_{number_of_bins}\"\n",
    ")\n",
    "try:\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "except Exception:\n",
    "    traceback.print_exc(file=sys.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [*] Loading model from /home/pkhunter/Repositories/WSmart-Route/assets/model_weights/cwcvrp100_riomaior_plastic/gamma1/amgat/epoch-30.pt\n",
      "{'accumulation_steps': 1,\n",
      " 'activation': 'gelu',\n",
      " 'af_nparams': 3,\n",
      " 'af_param': 1.0,\n",
      " 'af_replacement': None,\n",
      " 'af_threshold': None,\n",
      " 'af_urange': [0.125, 0.3333333333333333],\n",
      " 'aggregation': 'sum',\n",
      " 'aggregation_graph': 'mean',\n",
      " 'area': 'riomaior',\n",
      " 'baseline': None,\n",
      " 'batch_size': 256,\n",
      " 'bl_alpha': 0.05,\n",
      " 'bl_warmup_epochs': 0,\n",
      " 'checkpoint_encoder': False,\n",
      " 'checkpoint_epochs': 1,\n",
      " 'checkpoints_dir': 'model_weights',\n",
      " 'data_distribution': 'gamma1',\n",
      " 'device': 'cuda:0',\n",
      " 'distance_method': 'gmaps',\n",
      " 'dm_filepath': 'data/wsr_simulator/distance_matrix/gmaps_distmat_plastic[riomaior].csv',\n",
      " 'dropout': 0.1,\n",
      " 'edge_method': 'knn',\n",
      " 'edge_threshold': 1.0,\n",
      " 'efficiency_weight': 0.8,\n",
      " 'embedding_dim': 128,\n",
      " 'enable_scaler': False,\n",
      " 'encoder': 'gat',\n",
      " 'epoch_size': 1280,\n",
      " 'epoch_start': 0,\n",
      " 'epsilon_alpha': 1e-05,\n",
      " 'eval_batch_size': 0,\n",
      " 'eval_focus_size': 0,\n",
      " 'eval_only': False,\n",
      " 'eval_time_days': 1,\n",
      " 'exp_beta': 0.8,\n",
      " 'final_dir': 'assets/model_weights/cwcvrp100_riomaior_plastic/gamma1/amgat',\n",
      " 'focus_graph': 'graphs_100V_1N_plastic.json',\n",
      " 'focus_size': 1280,\n",
      " 'gnorm_groups': 4,\n",
      " 'graph_size': 100,\n",
      " 'hidden_dim': 512,\n",
      " 'learn_affine': True,\n",
      " 'load_path': None,\n",
      " 'log_dir': 'logs',\n",
      " 'log_step': 5,\n",
      " 'lr_critic_value': 0.0001,\n",
      " 'lr_decay': 1.0,\n",
      " 'lr_min_decay': 1e-08,\n",
      " 'lr_min_value': 0.0,\n",
      " 'lr_model': 0.0001,\n",
      " 'lr_post_processing': 0.001,\n",
      " 'lr_scheduler': 'lambda',\n",
      " 'lrnorm_k': None,\n",
      " 'lrs_cooldown': 0,\n",
      " 'lrs_dfactor': 0.1,\n",
      " 'lrs_milestones': [7, 14, 21, 28],\n",
      " 'lrs_mode': 'min',\n",
      " 'lrs_patience': 10,\n",
      " 'lrs_restart_steps': 7,\n",
      " 'lrs_rfactor': 2,\n",
      " 'lrs_step_size': 1,\n",
      " 'lrs_thresh': 0.0001,\n",
      " 'lrs_thresh_mode': 'rel',\n",
      " 'lrs_total_steps': 5,\n",
      " 'mask_graph': False,\n",
      " 'mask_inner': True,\n",
      " 'mask_logits': True,\n",
      " 'max_grad_norm': 1.0,\n",
      " 'model': 'am',\n",
      " 'momentum_beta': 0.1,\n",
      " 'n_decode_layers': None,\n",
      " 'n_encode_layers': 3,\n",
      " 'n_encode_sublayers': None,\n",
      " 'n_epochs': 31,\n",
      " 'n_heads': 8,\n",
      " 'n_predict_layers': None,\n",
      " 'no_cuda': False,\n",
      " 'no_progress_bar': False,\n",
      " 'no_tensorboard': False,\n",
      " 'normalization': 'instance',\n",
      " 'optimizer': 'rmsprop',\n",
      " 'output_dir': 'assets/model_weights',\n",
      " 'overflow_weight': 0.2,\n",
      " 'pomo_size': 0,\n",
      " 'post_processing_epochs': 0,\n",
      " 'problem': 'cwcvrp',\n",
      " 'resume': None,\n",
      " 'run_name': 'amgat_gamma1_20251220T153939',\n",
      " 'save_dir': 'model_weights/cwcvrp_100/amgat_gamma1_20251220T153939',\n",
      " 'seed': 42,\n",
      " 'shrink_size': None,\n",
      " 'tanh_clipping': 10.0,\n",
      " 'temporal_horizon': 0,\n",
      " 'track_stats': False,\n",
      " 'train_dataset': 'data/datasets/wcvrp/wcvrp100_gamma1_time31_seed42.pkl',\n",
      " 'train_time': True,\n",
      " 'val_dataset': None,\n",
      " 'val_size': 0,\n",
      " 'vertex_method': 'mmn',\n",
      " 'w_length': 1.0,\n",
      " 'w_lost': None,\n",
      " 'w_overflows': 1.0,\n",
      " 'w_penalty': None,\n",
      " 'w_prize': None,\n",
      " 'w_waste': 1.0,\n",
      " 'wandb_mode': 'disabled',\n",
      " 'waste_filepath': None,\n",
      " 'waste_type': 'plastic'}\n",
      "Device set to cuda:0\n",
      "  [*] Loading model from /home/pkhunter/Repositories/WSmart-Route/assets/model_weights/cwcvrp100_riomaior_plastic/gamma1/amgat_hrl/epoch-30.pt\n",
      "{'accumulation_steps': 1,\n",
      " 'activation': 'gelu',\n",
      " 'af_nparams': 3,\n",
      " 'af_param': 1.0,\n",
      " 'af_replacement': None,\n",
      " 'af_threshold': None,\n",
      " 'af_urange': [0.125, 0.3333333333333333],\n",
      " 'aggregation': 'sum',\n",
      " 'aggregation_graph': 'mean',\n",
      " 'area': 'riomaior',\n",
      " 'baseline': None,\n",
      " 'batch_size': 256,\n",
      " 'bl_alpha': 0.05,\n",
      " 'bl_warmup_epochs': 0,\n",
      " 'cb_context_features': ['waste', 'overflow', 'length', 'visited_ratio', 'day'],\n",
      " 'cb_epsilon_decay': 0.995,\n",
      " 'cb_exploration_method': 'ucb',\n",
      " 'cb_features_aggregation': 'avg',\n",
      " 'cb_min_epsilon': 0.01,\n",
      " 'cb_num_configs': 10,\n",
      " 'checkpoint_encoder': False,\n",
      " 'checkpoint_epochs': 1,\n",
      " 'checkpoints_dir': 'model_weights',\n",
      " 'data_distribution': 'gamma1',\n",
      " 'device': 'cuda:0',\n",
      " 'distance_method': 'gmaps',\n",
      " 'dm_filepath': 'data/wsr_simulator/distance_matrix/gmaps_distmat_plastic[riomaior].csv',\n",
      " 'dropout': 0.1,\n",
      " 'edge_method': 'knn',\n",
      " 'edge_threshold': 1.0,\n",
      " 'efficiency_weight': 0.8,\n",
      " 'embedding_dim': 128,\n",
      " 'enable_scaler': False,\n",
      " 'encoder': 'gat',\n",
      " 'epoch_size': 1280,\n",
      " 'epoch_start': 0,\n",
      " 'epsilon_alpha': 1e-05,\n",
      " 'eval_batch_size': 0,\n",
      " 'eval_focus_size': 0,\n",
      " 'eval_only': False,\n",
      " 'eval_time_days': 1,\n",
      " 'exp_beta': 0.8,\n",
      " 'final_dir': 'assets/model_weights/cwcvrp100_riomaior_plastic/gamma1/amgat_hrl',\n",
      " 'focus_graph': 'graphs_100V_1N_plastic.json',\n",
      " 'focus_size': 1280,\n",
      " 'gat_hidden': 128,\n",
      " 'gate_prob_threshold': 0.7,\n",
      " 'gnorm_groups': 4,\n",
      " 'graph_size': 100,\n",
      " 'hidden_dim': 512,\n",
      " 'hrl_clip_eps': 0.2,\n",
      " 'hrl_epochs': 4,\n",
      " 'hrl_method': 'gating_mechanism',\n",
      " 'learn_affine': True,\n",
      " 'load_path': None,\n",
      " 'log_dir': 'logs',\n",
      " 'log_step': 5,\n",
      " 'lr_critic_value': 0.0001,\n",
      " 'lr_decay': 1.0,\n",
      " 'lr_min_decay': 1e-08,\n",
      " 'lr_min_value': 0.0,\n",
      " 'lr_model': 0.0001,\n",
      " 'lr_post_processing': 0.001,\n",
      " 'lr_scheduler': 'lambda',\n",
      " 'lrnorm_k': None,\n",
      " 'lrs_cooldown': 0,\n",
      " 'lrs_dfactor': 0.1,\n",
      " 'lrs_milestones': [7, 14, 21, 28],\n",
      " 'lrs_mode': 'min',\n",
      " 'lrs_patience': 10,\n",
      " 'lrs_restart_steps': 7,\n",
      " 'lrs_rfactor': 2,\n",
      " 'lrs_step_size': 1,\n",
      " 'lrs_thresh': 0.0001,\n",
      " 'lrs_thresh_mode': 'rel',\n",
      " 'lrs_total_steps': 5,\n",
      " 'lstm_hidden': 64,\n",
      " 'mask_graph': False,\n",
      " 'mask_inner': True,\n",
      " 'mask_logits': True,\n",
      " 'max_grad_norm': 1.0,\n",
      " 'model': 'am',\n",
      " 'momentum_beta': 0.1,\n",
      " 'morl_adaptation_rate': 0.1,\n",
      " 'morl_objectives': ['waste_efficiency', 'overflow_rate'],\n",
      " 'mrl_batch_size': 256,\n",
      " 'mrl_embedding_dim': 128,\n",
      " 'mrl_exploration_factor': 2.0,\n",
      " 'mrl_history': 7,\n",
      " 'mrl_lr': 0.0001,\n",
      " 'mrl_method': 'hrl',\n",
      " 'mrl_range': [0.01, 5.0],\n",
      " 'mrl_step': 7,\n",
      " 'n_decode_layers': None,\n",
      " 'n_encode_layers': 3,\n",
      " 'n_encode_sublayers': None,\n",
      " 'n_epochs': 31,\n",
      " 'n_heads': 8,\n",
      " 'n_predict_layers': None,\n",
      " 'no_cuda': False,\n",
      " 'no_progress_bar': False,\n",
      " 'no_tensorboard': False,\n",
      " 'normalization': 'instance',\n",
      " 'optimizer': 'rmsprop',\n",
      " 'output_dir': 'assets/model_weights',\n",
      " 'overflow_weight': 0.2,\n",
      " 'pomo_size': 0,\n",
      " 'post_processing_epochs': 0,\n",
      " 'problem': 'cwcvrp',\n",
      " 'resume': None,\n",
      " 'run_name': 'amgat_gamma1_20251220T153809',\n",
      " 'rwa_model': 'rnn',\n",
      " 'rwa_optimizer': 'rmsprop',\n",
      " 'rwa_update_step': 100,\n",
      " 'save_dir': 'model_weights/cwcvrp_100/amgat_gamma1_20251220T153809',\n",
      " 'seed': 42,\n",
      " 'shrink_size': None,\n",
      " 'tanh_clipping': 10.0,\n",
      " 'tdl_lr_decay': 1.0,\n",
      " 'temporal_horizon': 0,\n",
      " 'track_stats': False,\n",
      " 'train_dataset': 'data/datasets/wcvrp/wcvrp100_gamma1_time31_seed42.pkl',\n",
      " 'train_time': True,\n",
      " 'val_dataset': None,\n",
      " 'val_size': 0,\n",
      " 'vertex_method': 'mmn',\n",
      " 'w_length': 1.0,\n",
      " 'w_lost': None,\n",
      " 'w_overflows': 1.0,\n",
      " 'w_penalty': None,\n",
      " 'w_prize': None,\n",
      " 'w_waste': 1.0,\n",
      " 'wandb_mode': 'disabled',\n",
      " 'waste_filepath': None,\n",
      " 'waste_type': 'plastic'}\n",
      "Device set to cuda:0\n",
      "/home/pkhunter/Repositories/WSmart-Route/assets/model_weights/cwcvrp100_riomaior_plastic/gamma1/amgat_hrl\n",
      "Loaded HRL Manager...\n"
     ]
    }
   ],
   "source": [
    "models = {}\n",
    "configs = {}\n",
    "problem = \"cwcvrp\"\n",
    "decode_type = \"greedy\"\n",
    "softmax_temperature = 1\n",
    "for model_name in model_names:\n",
    "    model_path = os.path.join(\n",
    "        home_dir,\n",
    "        \"assets\",\n",
    "        \"model_weights\",\n",
    "        f\"{problem}{number_of_bins}_{area}_{waste_type}\",\n",
    "        inner_dir,\n",
    "        model_name,\n",
    "    )\n",
    "    try:\n",
    "        model, config = load_model(model_path)\n",
    "        pp.pprint(config)\n",
    "\n",
    "        device = torch.device(\n",
    "            \"cpu\"\n",
    "            if not torch.cuda.is_available()\n",
    "            else f\"cuda:{torch.cuda.device_count() - 1}\"\n",
    "        )\n",
    "        print(\"Device set to\", device)\n",
    "\n",
    "        hrl_manager = setup_hrl_manager({\"model_path\": model_path}, device, config)\n",
    "        if hrl_manager is not None:\n",
    "            print(\"Loaded HRL Manager...\")\n",
    "\n",
    "        models[model_name] = model\n",
    "        configs[model_name] = config\n",
    "        models[model_name].to(device)\n",
    "        models[model_name].eval()\n",
    "        models[model_name].set_decode_type(decode_type, temp=softmax_temperature)\n",
    "    except Exception:\n",
    "        print(f\"Failed to load {model_name} model from {model_path}\")\n",
    "        traceback.print_exc(file=sys.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_minute_cfs = []\n",
    "last_minute_variants = \"both\"  # 'only'|'path'|'both'\n",
    "\n",
    "regular_levels = []\n",
    "\n",
    "look_ahead_configs = []\n",
    "look_ahead_configurations = {\n",
    "    \"a\": [500, 75, 0.7, 0, 0.095, 0, 0],\n",
    "    \"b\": [2000, 75, 0.7, 0, 0.095, 0, 0],\n",
    "}\n",
    "look_ahead_variants = []  # 'base', 'vrpp', 'sans'\n",
    "\n",
    "gp_params = []\n",
    "if gp_params or \"vrpp\" in look_ahead_variants:\n",
    "    gp_env_params = {\"OutputFlag\": 0}\n",
    "    gp_env = gp.Env(params=gp_env_params)\n",
    "\n",
    "hex_params = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['amgat_gamma1', 'amgat_hrl_gamma1']\n"
     ]
    }
   ],
   "source": [
    "policies = []\n",
    "if len(model_names) > 0:\n",
    "    for model_name in model_names:\n",
    "        policy = \"{}{}_{}\".format(\n",
    "            model_name, f\"{model_id}\" if model_id >= 1 else \"\", inner_dir\n",
    "        )\n",
    "        policies.append(policy)\n",
    "\n",
    "if last_minute_cfs:\n",
    "    for lmcf in last_minute_cfs:\n",
    "        if last_minute_variants in [\"only\", \"both\"]:\n",
    "            policy = (\n",
    "                f\"policy_last_minute{lmcf}_gamma{gamma_option + 1}\"\n",
    "                if inner_dir[:-1] == \"gamma\"\n",
    "                else f\"policy_last_minute{lmcf}_emp\"\n",
    "            )\n",
    "            policies.append(policy)\n",
    "        if last_minute_variants in [\"path\", \"both\"]:\n",
    "            policy = (\n",
    "                f\"policy_last_minute_and_path{lmcf}_gamma{gamma_option + 1}\"\n",
    "                if inner_dir[:-1] == \"gamma\"\n",
    "                else f\"policy_last_minute_and_path{lmcf}_emp\"\n",
    "            )\n",
    "            policies.append(policy)\n",
    "\n",
    "if regular_levels:\n",
    "    for lvl in regular_levels:\n",
    "        policy = (\n",
    "            f\"policy_regular{lvl}_gamma{gamma_option + 1}\"\n",
    "            if inner_dir[:-1] == \"gamma\"\n",
    "            else f\"policy_regular{lvl}_emp\"\n",
    "        )\n",
    "        policies.append(policy)\n",
    "\n",
    "for lac in look_ahead_configs:\n",
    "    for lav in look_ahead_variants:\n",
    "        if lav == \"base\":\n",
    "            policy = (\n",
    "                f\"policy_look_ahead_{lac}_gamma{gamma_option + 1}\"\n",
    "                if inner_dir[:-1] == \"gamma\"\n",
    "                else f\"policy_look_ahead_{lac}_emp\"\n",
    "            )\n",
    "        else:\n",
    "            policy = (\n",
    "                f\"policy_look_ahead_{lac}_{lav}_gamma{gamma_option + 1}\"\n",
    "                if inner_dir[:-1] == \"gamma\"\n",
    "                else f\"policy_look_ahead_{lac}_{lav}_emp\"\n",
    "            )\n",
    "        policies.append(policy)\n",
    "\n",
    "if gp_params:\n",
    "    for gpp in gp_params:\n",
    "        policy = (\n",
    "            f\"gurobi_vrpp{gpp}_gamma{gamma_option + 1}\"\n",
    "            if inner_dir[:-1] == \"gamma\"\n",
    "            else f\"gurobi_vrpp{gpp}_emp\"\n",
    "        )\n",
    "        policies.append(policy)\n",
    "\n",
    "if hex_params:\n",
    "    for hexp in hex_params:\n",
    "        policy = (\n",
    "            f\"hexaly_vrpp{hexp}_gamma{gamma_option + 1}\"\n",
    "            if inner_dir[:-1] == \"gamma\"\n",
    "            else f\"hexaly_vrpp{hexp}_emp\"\n",
    "        )\n",
    "        policies.append(policy)\n",
    "\n",
    "# policies = policies[1:] #+ policies[:1]\n",
    "print(policies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area riomaior (173 full) for 100 bins\n",
      "Lat: [39.25353454, 39.4429361111111]\n",
      "Lng: [-8.984290944, -8.79266007]\n"
     ]
    }
   ],
   "source": [
    "depot = load_depot(data_dir, area)\n",
    "data, bins_coordinates = load_simulator_data(data_dir, number_of_bins, area, waste_type)\n",
    "assert data.shape == bins_coordinates.shape\n",
    "\n",
    "print(f\"Area {area} ({bins_coordinates.shape[0]} full) for {number_of_bins} bins\")\n",
    "print(f\"Lat: [{bins_coordinates['Lat'].min()}, {bins_coordinates['Lat'].max()}]\")\n",
    "print(f\"Lng: [{bins_coordinates['Lng'].min()}, {bins_coordinates['Lng'].max()}]\")\n",
    "\n",
    "edge_thresh = 1.0\n",
    "edge_method = \"knn\"\n",
    "norm_method = \"mmn\"\n",
    "dist_mat_method = \"gmaps\"\n",
    "if area == \"riomaior\":\n",
    "    grid = OldGridBase(data_dir, area)\n",
    "else:\n",
    "    grid = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "depot_tmp = depot.copy()\n",
    "depot_location = \"og\"\n",
    "if depot_location == \"mean\":\n",
    "    depot_tmp[\"Lat\"] = bins_coordinates[\"Lat\"].mean()\n",
    "    depot_tmp[\"Lng\"] = bins_coordinates[\"Lng\"].mean()\n",
    "else:\n",
    "    assert depot_location == \"og\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Experiments on Simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nsamples = 10\n",
    "start_id = 0\n",
    "assert start_id < Nsamples\n",
    "\n",
    "log_filepath = os.path.join(output_dir, f\"log_mean_{Nsamples}N.json\")\n",
    "if Nsamples > 1:\n",
    "    logstd_filepath = os.path.join(output_dir, f\"log_std_{Nsamples}N.json\")\n",
    "    logfull_filepath = os.path.join(output_dir, f\"log_full_{Nsamples}N.json\")\n",
    "\n",
    "data_size = bins_coordinates.shape[0]\n",
    "dm_filepath = os.path.join(\n",
    "    data_dir, \"distance_matrix\", f\"gmaps_distmat_{waste_type}[{area}].csv\"\n",
    ")\n",
    "daily_log_path = os.path.join(output_dir, f\"daily_{inner_dir}_{Nsamples}N.json\")\n",
    "if data_size > number_of_bins:\n",
    "    idx_filename = f\"graphs_{number_of_bins}V_1N_{waste_type}.json\"\n",
    "    indices_ls = load_indices(idx_filename, Nsamples, number_of_bins, data_size)\n",
    "else:\n",
    "    indices_ls = [None] * Nsamples\n",
    "\n",
    "daily_waste_path = os.path.join(\n",
    "    data_dir,\n",
    "    \"daily_waste\",\n",
    "    \"{}{}_{}_wsr31_N10_seed{}.pkl\".format(area, number_of_bins, inner_dir, SEED),\n",
    ")\n",
    "if not os.path.exists(daily_waste_path):\n",
    "    load_waste = False\n",
    "    daily_waste_path = None\n",
    "    print(f\"Specified daily waste fill file {daily_waste_path} does not exist\")\n",
    "else:\n",
    "    load_waste = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "amgat_gamma1 #0: 100%|\u001b[31m██████████\u001b[0m| 30/30 [00:00<00:00, 157.92it/s]\n",
      "/tmp/ipykernel_340061/1819045513.py:171: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  np.sum(bins.lost), bins.travel, np.nan_to_num(np.sum(bins.collected)/bins.travel, 0),\n",
      "amgat_hrl_gamma1 #0: 100%|\u001b[34m██████████\u001b[0m| 30/30 [00:00<00:00, 168.99it/s]\n",
      "amgat_gamma1 #1: 100%|\u001b[31m██████████\u001b[0m| 30/30 [00:00<00:00, 166.00it/s]\n",
      "/tmp/ipykernel_340061/1819045513.py:171: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  np.sum(bins.lost), bins.travel, np.nan_to_num(np.sum(bins.collected)/bins.travel, 0),\n",
      "amgat_hrl_gamma1 #1: 100%|\u001b[34m██████████\u001b[0m| 30/30 [00:00<00:00, 172.29it/s]\n",
      "amgat_gamma1 #2: 100%|\u001b[31m██████████\u001b[0m| 30/30 [00:00<00:00, 123.32it/s]\n",
      "/tmp/ipykernel_340061/1819045513.py:171: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  np.sum(bins.lost), bins.travel, np.nan_to_num(np.sum(bins.collected)/bins.travel, 0),\n",
      "amgat_hrl_gamma1 #2: 100%|\u001b[34m██████████\u001b[0m| 30/30 [00:00<00:00, 175.77it/s]\n",
      "amgat_gamma1 #3: 100%|\u001b[31m██████████\u001b[0m| 30/30 [00:00<00:00, 171.08it/s]\n",
      "/tmp/ipykernel_340061/1819045513.py:171: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  np.sum(bins.lost), bins.travel, np.nan_to_num(np.sum(bins.collected)/bins.travel, 0),\n",
      "amgat_hrl_gamma1 #3: 100%|\u001b[34m██████████\u001b[0m| 30/30 [00:00<00:00, 168.20it/s]\n",
      "amgat_gamma1 #4: 100%|\u001b[31m██████████\u001b[0m| 30/30 [00:00<00:00, 174.32it/s]\n",
      "/tmp/ipykernel_340061/1819045513.py:171: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  np.sum(bins.lost), bins.travel, np.nan_to_num(np.sum(bins.collected)/bins.travel, 0),\n",
      "amgat_hrl_gamma1 #4: 100%|\u001b[34m██████████\u001b[0m| 30/30 [00:00<00:00, 171.13it/s]\n",
      "amgat_gamma1 #5: 100%|\u001b[31m██████████\u001b[0m| 30/30 [00:00<00:00, 172.60it/s]\n",
      "/tmp/ipykernel_340061/1819045513.py:171: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  np.sum(bins.lost), bins.travel, np.nan_to_num(np.sum(bins.collected)/bins.travel, 0),\n",
      "amgat_hrl_gamma1 #5: 100%|\u001b[34m██████████\u001b[0m| 30/30 [00:00<00:00, 163.31it/s]\n",
      "amgat_gamma1 #6: 100%|\u001b[31m██████████\u001b[0m| 30/30 [00:00<00:00, 156.60it/s]\n",
      "/tmp/ipykernel_340061/1819045513.py:171: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  np.sum(bins.lost), bins.travel, np.nan_to_num(np.sum(bins.collected)/bins.travel, 0),\n",
      "amgat_hrl_gamma1 #6: 100%|\u001b[34m██████████\u001b[0m| 30/30 [00:00<00:00, 159.47it/s]\n",
      "amgat_gamma1 #7: 100%|\u001b[31m██████████\u001b[0m| 30/30 [00:00<00:00, 163.29it/s]\n",
      "/tmp/ipykernel_340061/1819045513.py:171: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  np.sum(bins.lost), bins.travel, np.nan_to_num(np.sum(bins.collected)/bins.travel, 0),\n",
      "amgat_hrl_gamma1 #7: 100%|\u001b[34m██████████\u001b[0m| 30/30 [00:00<00:00, 120.66it/s]\n",
      "amgat_gamma1 #8: 100%|\u001b[31m██████████\u001b[0m| 30/30 [00:00<00:00, 153.55it/s]\n",
      "/tmp/ipykernel_340061/1819045513.py:171: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  np.sum(bins.lost), bins.travel, np.nan_to_num(np.sum(bins.collected)/bins.travel, 0),\n",
      "amgat_hrl_gamma1 #8: 100%|\u001b[34m██████████\u001b[0m| 30/30 [00:00<00:00, 143.70it/s]\n",
      "amgat_gamma1 #9: 100%|\u001b[31m██████████\u001b[0m| 30/30 [00:00<00:00, 160.78it/s]\n",
      "/tmp/ipykernel_340061/1819045513.py:171: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  np.sum(bins.lost), bins.travel, np.nan_to_num(np.sum(bins.collected)/bins.travel, 0),\n",
      "amgat_hrl_gamma1 #9: 100%|\u001b[34m██████████\u001b[0m| 30/30 [00:00<00:00, 161.24it/s]\n"
     ]
    }
   ],
   "source": [
    "log = []\n",
    "if Nsamples > 1:\n",
    "    tmp_log = {pol: [] for pol in policies}\n",
    "\n",
    "run_tsp = False\n",
    "regular_cache = True\n",
    "full_daily_log = {}\n",
    "attention_dict = {model_name: [] for model_name in model_names}\n",
    "for sample_id in range(start_id, Nsamples):\n",
    "    indices = indices_ls[sample_id]\n",
    "    new_data, coordinates = process_data(\n",
    "        data, bins_coordinates, depot_tmp, indices=indices\n",
    "    )\n",
    "    distance_matrix = compute_distance_matrix(\n",
    "        coordinates, dist_mat_method, focus_idx=indices, dm_filepath=dm_filepath\n",
    "    )\n",
    "    dist_matrix_edges, shortest_paths, adj_matrix = apply_edges(\n",
    "        distance_matrix, edge_thresh, edge_method\n",
    "    )\n",
    "    pathbetweenstates = get_paths_between_states(n_bins, shortest_paths)\n",
    "    distancesC = np.round(dist_matrix_edges * 10).astype(\"int32\")\n",
    "    if len(models) > 0:\n",
    "        distC_tensor = torch.from_numpy(distancesC).to(device)\n",
    "    tour_ls = []\n",
    "    cost_ls = []\n",
    "    for pol_id, pol in enumerate(policies):\n",
    "        desc = f\"{pol} #{sample_id}\"\n",
    "        policy = pol.rsplit(\"_\", 1)[0]\n",
    "        daily_log = {key: [] for key in DAY_METRICS}\n",
    "        if len(models) > 0:\n",
    "            model_strip_name = re.split(r\"[^a-zA-Z]\", pol, maxsplit=1)[0]\n",
    "            if model_strip_name in [\"amgat\", \"amgac\", \"amtgc\"]:\n",
    "                model = models[policy]\n",
    "                config = configs[policy]\n",
    "                model_data, graph, profit_vars = process_model_data(\n",
    "                    coordinates,\n",
    "                    distancesC,\n",
    "                    device,\n",
    "                    norm_method,\n",
    "                    config,\n",
    "                    edge_thresh,\n",
    "                    edge_method,\n",
    "                    area,\n",
    "                    waste_type,\n",
    "                    adj_matrix,\n",
    "                )\n",
    "        else:\n",
    "            model_data, graph = (None, None)\n",
    "\n",
    "        overflows = 0\n",
    "        cached = [] if regular_cache else None\n",
    "        current_collection_day = 0\n",
    "        bins = Bins(\n",
    "            NC - 1,\n",
    "            data_dir,\n",
    "            data_distribution,\n",
    "            grid,\n",
    "            waste_file=daily_waste_path,\n",
    "            waste_type=waste_type,\n",
    "            area=area,\n",
    "        )\n",
    "        bins.set_indices(indices)\n",
    "        if data_distribution == \"gamma\":\n",
    "            bins.setGammaDistribution(option=gamma_option)\n",
    "        if daily_waste_path is not None:\n",
    "            bins.set_sample_waste(sample_id)\n",
    "\n",
    "        colour = TQDM_COLOURS[pol_id % len(TQDM_COLOURS)]\n",
    "        tic = time.perf_counter()\n",
    "        for day in tqdm(range(1, Ndays + 1), desc=desc, colour=colour):\n",
    "            tour = []\n",
    "            if bins.is_stochastic():\n",
    "                new_overflows, fill, total_fill, sum_lost = bins.stochasticFilling()\n",
    "            else:\n",
    "                new_overflows, fill, total_fill, sum_lost = bins.loadFilling(day)\n",
    "            overflows += new_overflows\n",
    "            if \"policy_last_minute_and_path\" in policy:\n",
    "                last_minute_cf = int(policy.rsplit(\"_and_path\", 1)[1])\n",
    "                if last_minute_cf not in [50, 70, 90]:\n",
    "                    print(\n",
    "                        \"Valid cf values for policy_last_minute_and_path: [50, 70, 90]\"\n",
    "                    )\n",
    "                    raise ValueError(\n",
    "                        f\"Invalid cf value for policy_last_minute_and_path: {last_minute_cf}\"\n",
    "                    )\n",
    "                bins.setCollectionLvlandFreq(cf=last_minute_cf / 100)\n",
    "                tour = policy_last_minute_and_path(\n",
    "                    bins.c,\n",
    "                    distancesC,\n",
    "                    pathbetweenstates,\n",
    "                    bins.collectlevl,\n",
    "                    waste_type,\n",
    "                    area,\n",
    "                )\n",
    "                cost = get_route_cost(distance_matrix, tour) if tour else 0\n",
    "            elif \"policy_last_minute\" in policy:\n",
    "                last_minute_cf = int(policy.rsplit(\"_last_minute\", 1)[1])\n",
    "                if last_minute_cf not in [50, 70, 90]:\n",
    "                    print(\"Valid cf values for policy_last_minute: [50, 70, 90]\")\n",
    "                    raise ValueError(\n",
    "                        f\"Invalid cf value for policy_last_minute: {last_minute_cf}\"\n",
    "                    )\n",
    "                bins.setCollectionLvlandFreq(cf=last_minute_cf / 100)\n",
    "                tour = policy_last_minute(\n",
    "                    bins.c, distancesC, bins.collectlevl, waste_type, area\n",
    "                )\n",
    "                cost = get_route_cost(distance_matrix, tour) if tour else 0\n",
    "            elif \"policy_regular\" in policy:\n",
    "                regular_level = int(policy.rsplit(\"_regular\", 1)[1]) - 1\n",
    "                if regular_level not in [1, 2, 5]:\n",
    "                    print(\"Valid lvl values for policy_regular: [2, 3, 6]\")\n",
    "                    raise ValueError(\n",
    "                        f\"Invalid lvl value for policy_regular: {regular_level + 1}\"\n",
    "                    )\n",
    "                tour = policy_regular(\n",
    "                    bins.n,\n",
    "                    bins.c,\n",
    "                    distancesC,\n",
    "                    regular_level,\n",
    "                    day,\n",
    "                    cached,\n",
    "                    waste_type,\n",
    "                    area,\n",
    "                )\n",
    "                cost = get_route_cost(distance_matrix, tour) if tour else 0\n",
    "                if cached is not None and not cached and tour:\n",
    "                    cached = tour\n",
    "            elif policy[:2] == \"am\" or policy[:4] == \"ddam\" or \"transgcn\" in policy:\n",
    "                daily_data = set_daily_waste(model_data, bins.c, device, fill)\n",
    "                tour, cost, output_dict = model.compute_simulator_day(\n",
    "                    daily_data,\n",
    "                    graph,\n",
    "                    distC_tensor,\n",
    "                    profit_vars,\n",
    "                    run_tsp,\n",
    "                    hrl_manager=hrl_manager,\n",
    "                    waste_history=bins.get_fill_history(device=device),\n",
    "                )\n",
    "                attention_dict[policy].append(output_dict)\n",
    "            elif \"gurobi\" in policy:\n",
    "                gp_param = float(policy.rsplit(\"_vrpp\", 1)[1])\n",
    "                try:\n",
    "                    to_collect = policy_gurobi_vrpp(\n",
    "                        bins.c,\n",
    "                        dist_matrix_edges.tolist(),\n",
    "                        gp_env,\n",
    "                        gp_param,\n",
    "                        bins.means,\n",
    "                        bins.std,\n",
    "                        waste_type,\n",
    "                        area,\n",
    "                        time_limit=600,\n",
    "                    )\n",
    "                except:\n",
    "                    to_collect = policy_gurobi_vrpp(\n",
    "                        bins.c,\n",
    "                        dist_matrix_edges.tolist(),\n",
    "                        gp_env,\n",
    "                        gp_param,\n",
    "                        bins.means,\n",
    "                        bins.std,\n",
    "                        waste_type,\n",
    "                        area,\n",
    "                        time_limit=3600,\n",
    "                    )\n",
    "\n",
    "                if to_collect:\n",
    "                    tour = (\n",
    "                        find_route(distancesC, np.array(to_collect[0]))\n",
    "                        if run_tsp\n",
    "                        else to_collect[0]\n",
    "                    )\n",
    "                    cost = get_route_cost(dist_matrix_edges, tour)\n",
    "            elif \"hexaly\" in policy:\n",
    "                hex_param = float(policy.rsplit(\"_vrpp\", 1)[1])\n",
    "                try:\n",
    "                    routes = policy_hexaly_vrpp(\n",
    "                        bins.c,\n",
    "                        distance_matrix.tolist(),\n",
    "                        hex_param,\n",
    "                        bins.means,\n",
    "                        bins.std,\n",
    "                        waste_type,\n",
    "                        area,\n",
    "                        time_limit=600,\n",
    "                    )\n",
    "                except:\n",
    "                    routes = policy_hexaly_vrpp(\n",
    "                        bins.c,\n",
    "                        distance_matrix.tolist(),\n",
    "                        hex_param,\n",
    "                        bins.means,\n",
    "                        bins.std,\n",
    "                        waste_type,\n",
    "                        area,\n",
    "                        time_limit=3600,\n",
    "                    )\n",
    "\n",
    "                if routes:\n",
    "                    tour = (\n",
    "                        find_route(distancesC, np.array(routes[0]))\n",
    "                        if run_tsp\n",
    "                        else routes[0]\n",
    "                    )\n",
    "                    cost = get_route_cost(dist_matrix_edges, tour)\n",
    "            elif \"policy_look_ahead\" in policy:\n",
    "                look_ahead_config = policy[policy.find(\"ahead_\") + len(\"ahead_\")]\n",
    "                try:\n",
    "                    chosen_combination = look_ahead_configurations[look_ahead_config]\n",
    "                except KeyError:\n",
    "                    print(\"Possible policy_look_ahead configurations:\")\n",
    "                    for pos_pol, ploa_configs in look_ahead_configurations.items():\n",
    "                        print(f\"{pos_pol} configuration: {ploa_configs}\")\n",
    "                    raise ValueError(\n",
    "                        f\"Invalid policy_look_ahead configuration: {policy}\"\n",
    "                    )\n",
    "\n",
    "                binsids = np.arange(0, number_of_bins).tolist()\n",
    "                must_go_bins = policy_lookahead(\n",
    "                    binsids, bins.c, bins.means, current_collection_day\n",
    "                )\n",
    "                if len(must_go_bins) > 0:\n",
    "                    vehicle_capacity, R, B, C, E = load_area_and_waste_type_params(\n",
    "                        area, waste_type\n",
    "                    )\n",
    "                    values = {\n",
    "                        \"R\": R,\n",
    "                        \"C\": C,\n",
    "                        \"E\": E,\n",
    "                        \"B\": B,\n",
    "                        \"vehicle_capacity\": vehicle_capacity,\n",
    "                    }\n",
    "                    if \"vrpp\" in policy:\n",
    "                        values[\"time_limit\"] = 600\n",
    "                        fh = np.array(fill_history).transpose()\n",
    "                        routes, profit, _ = policy_lookahead_vrpp(\n",
    "                            fh,\n",
    "                            binsids,\n",
    "                            must_go_bins,\n",
    "                            distance_matrix,\n",
    "                            values,\n",
    "                            env=gp_env,\n",
    "                        )\n",
    "                        if routes:\n",
    "                            tour = (\n",
    "                                find_route(distancesC, np.array(routes))\n",
    "                                if run_tsp\n",
    "                                else routes\n",
    "                            )\n",
    "                            cost = get_route_cost(distance_matrix, tour)\n",
    "                    elif \"sans\" in policy:\n",
    "                        values[\"time_limit\"] = 60\n",
    "                        fh = np.array(fill_history).transpose()\n",
    "                        T_min = 0.01\n",
    "                        T_init = 75\n",
    "                        iterations_per_T = 50000\n",
    "                        alpha = 0.7\n",
    "                        params = (T_init, iterations_per_T, alpha, T_min)\n",
    "                        routes, profit, _ = policy_lookahead_sans(\n",
    "                            fh,\n",
    "                            coordinates,\n",
    "                            distance_matrix,\n",
    "                            params,\n",
    "                            must_go_bins,\n",
    "                            values,\n",
    "                            binsids,\n",
    "                        )\n",
    "                        if routes:\n",
    "                            tour = (\n",
    "                                find_route(distancesC, np.array(routes[0]))\n",
    "                                if run_tsp\n",
    "                                else routes[0]\n",
    "                            )\n",
    "                            cost = get_route_cost(distance_matrix, tour)\n",
    "                    else:\n",
    "                        values[\"shift_duration\"] = 390  # minutes\n",
    "                        values[\"perc_bins_can_overflow\"] = 0  # 0%\n",
    "                        points = create_points(new_data, coordinates)\n",
    "                        new_data.loc[1 : number_of_bins + 1, \"Stock\"] = (\n",
    "                            bins.c / 100\n",
    "                        ).astype(\"float32\")\n",
    "                        new_data.loc[1 : number_of_bins + 1, \"Accum_Rate\"] = (\n",
    "                            bins.means / 100\n",
    "                        ).astype(\"float32\")\n",
    "                        try:\n",
    "                            routes, profit, removed_bins = find_solutions(\n",
    "                                new_data,\n",
    "                                coordinates,\n",
    "                                distance_matrix,\n",
    "                                chosen_combination,\n",
    "                                must_go_bins,\n",
    "                                values,\n",
    "                                number_of_bins,\n",
    "                                points,\n",
    "                                time_limit=600,\n",
    "                            )\n",
    "                        except:\n",
    "                            routes, profit, removed_bins = find_solutions(\n",
    "                                new_data,\n",
    "                                coordinates,\n",
    "                                distance_matrix,\n",
    "                                chosen_combination,\n",
    "                                must_go_bins,\n",
    "                                values,\n",
    "                                number_of_bins,\n",
    "                                points,\n",
    "                                time_limit=3600,\n",
    "                            )\n",
    "\n",
    "                        if routes:\n",
    "                            tour = (\n",
    "                                find_route(distancesC, np.array(routes[0]))\n",
    "                                if run_tsp\n",
    "                                else routes[0]\n",
    "                            )\n",
    "                            cost = get_route_cost(distance_matrix, tour)\n",
    "                else:\n",
    "                    tour = [0, 0]\n",
    "                    cost = 0\n",
    "            else:\n",
    "                raise ValueError(\"Unknown policy:\", policy)\n",
    "            cost_ls.append(cost)\n",
    "            tour_ls.append(tour)\n",
    "            # $print(\"Tour (cost {}): {}\".format(cost, tour))\n",
    "            collected, total_collected, ncol, profit = bins.collect(tour, cost)\n",
    "            dlog = get_daily_results(\n",
    "                total_collected,\n",
    "                ncol,\n",
    "                cost,\n",
    "                tour,\n",
    "                day,\n",
    "                new_overflows,\n",
    "                sum_lost,\n",
    "                coordinates,\n",
    "                profit,\n",
    "            )\n",
    "            for key, val in dlog.items():\n",
    "                daily_log[key].append(val)\n",
    "        full_daily_log[\"{}#{}\".format(pol, sample_id)] = daily_log\n",
    "        lg = [\n",
    "            np.sum(bins.inoverflow),\n",
    "            np.sum(bins.collected),\n",
    "            np.sum(bins.ncollections),\n",
    "            np.sum(bins.lost),\n",
    "            bins.travel,\n",
    "            np.nan_to_num(np.sum(bins.collected) / bins.travel, 0),\n",
    "            np.sum(bins.inoverflow) - np.sum(bins.collected) + bins.travel,\n",
    "            bins.ndays,\n",
    "            time.perf_counter() - tic,\n",
    "        ]\n",
    "        if Nsamples > 1:\n",
    "            save_id = sample_id - start_id\n",
    "            tmp_log[pol].append(lg)\n",
    "            log_to_json(\n",
    "                logfull_filepath,\n",
    "                SIM_METRICS,\n",
    "                {pol: tmp_log[pol][save_id]},\n",
    "                sample_id=sample_id,\n",
    "            )\n",
    "            log_to_json(\n",
    "                daily_log_path, DAY_METRICS, {f\"{pol} #{sample_id}\": daily_log.values()}\n",
    "            )\n",
    "        else:\n",
    "            log.append(lg)\n",
    "            log_to_json(log_filepath, SIM_METRICS, {pol: log[-1]})\n",
    "            log_to_json(daily_log_path, DAY_METRICS, {pol: daily_log.values()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To-Do\n",
    "### Comecar escrever o paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"amgat_gamma1\": {\n",
      " \"overflows\": 2633.1,\n",
      " \"kg\": 0.0,\n",
      " \"ncol\": 0.0,\n",
      " \"kg_lost\": 32847.68109749626,\n",
      " \"km\": 0,\n",
      " \"kg/km\": 0.0,\n",
      " \"cost\": 2633.1,\n",
      " \"profit\": 0,\n",
      " \"days\": 0.19139860910363496\n",
      "}\n",
      "\"amgat_hrl_gamma1\": {\n",
      " \"overflows\": 2633.1,\n",
      " \"kg\": 0.0,\n",
      " \"ncol\": 0.0,\n",
      " \"kg_lost\": 32847.68109749626,\n",
      " \"km\": 0,\n",
      " \"kg/km\": 0.0,\n",
      " \"cost\": 2633.1,\n",
      " \"profit\": 0,\n",
      " \"days\": 0.19131775919813662\n",
      "}\n",
      "Standard deviation\n",
      "\"amgat_gamma1\": {\n",
      " \"overflows\": 6.297265720577111,\n",
      " \"kg\": 0.0,\n",
      " \"ncol\": 0.0,\n",
      " \"kg_lost\": 227.53151422551494,\n",
      " \"km\": 0.0,\n",
      " \"kg/km\": 0.0,\n",
      " \"cost\": 6.297265720577111,\n",
      " \"profit\": 0.0,\n",
      " \"days\": 0.020658330028860104\n",
      "}\n",
      "\"amgat_hrl_gamma1\": {\n",
      " \"overflows\": 6.297265720577111,\n",
      " \"kg\": 0.0,\n",
      " \"ncol\": 0.0,\n",
      " \"kg_lost\": 227.53151422551494,\n",
      " \"km\": 0.0,\n",
      " \"kg/km\": 0.0,\n",
      " \"cost\": 6.297265720577111,\n",
      " \"profit\": 0.0,\n",
      " \"days\": 0.023610940446398873\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import statistics\n",
    "\n",
    "if Nsamples > 1:\n",
    "    log_mean = []\n",
    "    log_std = []\n",
    "    for pol_log in tmp_log.values():\n",
    "        log_mean.append([*map(statistics.mean, zip(*pol_log))])\n",
    "        log_std.append([*map(statistics.stdev, zip(*pol_log))])\n",
    "\n",
    "    for lg, pol in zip(log_mean, policies):\n",
    "        print(f'\"{pol}\":', end=\" \")\n",
    "        print(json.dumps(dict(zip(SIM_METRICS, lg)), indent=True))\n",
    "\n",
    "    print(\"Standard deviation\")\n",
    "    for lg, pol in zip(log_std, policies):\n",
    "        print(f'\"{pol}\":', end=\" \")\n",
    "        print(json.dumps(dict(zip(SIM_METRICS, lg)), indent=True))\n",
    "else:\n",
    "    for lg, pol in zip(log, policies):\n",
    "        print(f'\"{pol}\":', end=\" \")\n",
    "        print(json.dumps(dict(zip(SIM_METRICS, lg)), indent=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_attn_viz = [0]  # list(range(0, Nsamples))\n",
    "\n",
    "for name in model_names:\n",
    "    for sample_idx in samples_attn_viz:\n",
    "        for layer_idx in range(configs[name][\"n_encode_layers\"]):\n",
    "            for head_idx in range(configs[name][\"n_heads\"]):\n",
    "                indices = indices_ls[sample_id]\n",
    "                labels = [\"Depot\"] + list(\n",
    "                    map(\n",
    "                        lambda id: \"Bin {}\".format(id),\n",
    "                        data.iloc[indices][\"ID\"].tolist(),\n",
    "                    )\n",
    "                )\n",
    "                attn_maps = plot_attention_maps_wrapper(\n",
    "                    home_dir,\n",
    "                    Ndays,\n",
    "                    number_of_bins,\n",
    "                    \"output\",\n",
    "                    area,\n",
    "                    attention_dict,\n",
    "                    name,\n",
    "                    log_plot,\n",
    "                    layer_idx,\n",
    "                    sample_idx,\n",
    "                    head_idx,\n",
    "                    x_labels=labels,\n",
    "                    y_labels=labels,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_viz = [\"cost\"]\n",
    "policies_daily_viz = policies[:-1]\n",
    "days_ls = [x for x in range(1, Ndays + 1)]\n",
    "\n",
    "plt.figure(dpi=200)\n",
    "for metric in metrics_viz:\n",
    "    plt.title(f\"Daily {metric} (Mean with Min/Max range over all simulation samples)\")\n",
    "    plt.xlabel(\"Day\")\n",
    "    plt.ylabel(f\"{metric.capitalize()}\")\n",
    "    for viz_pol in policies_daily_viz:\n",
    "        metric_pol_data = []\n",
    "        for sample_id in range(Nsamples):\n",
    "            metric_pol_data.append(full_daily_log[f\"{viz_pol}#{sample_id}\"][metric])\n",
    "\n",
    "        metric_arr = np.array(metric_pol_data)\n",
    "        means = np.mean(metric_arr, axis=0)\n",
    "        mins = np.min(metric_arr, axis=0)\n",
    "        maxs = np.max(metric_arr, axis=0)\n",
    "        plt.plot(days_ls, means, marker=\"o\", linestyle=\"-\", label=viz_pol)\n",
    "        plt.fill_between(days_ls, mins, maxs, alpha=0.2)\n",
    "\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dit = {}\n",
    "for pol, val in zip(policies, log_mean):\n",
    "    dit[pol] = val if isinstance(val, list) else val.tolist()\n",
    "\n",
    "log_filepath = os.path.join(output_dir, f\"log_mean_{Nsamples}N.json\")\n",
    "log_to_json(log_filepath, SIM_METRICS, dit)\n",
    "if IN_COLAB:\n",
    "    log_to_pickle(\n",
    "        os.path.join(output_dir, f\"log_mean_{Nsamples}N.pkl\"),\n",
    "        log_mean,\n",
    "        dw_func=gfiles.download,\n",
    "    )\n",
    "\n",
    "if Nsamples > 1:\n",
    "    std_dit = {}\n",
    "    for pol, val in zip(policies, log_std):\n",
    "        std_dit[pol] = val if isinstance(val, list) else val.tolist()\n",
    "\n",
    "    logstd_filepath = os.path.join(output_dir, f\"log_std_{Nsamples}N.json\")\n",
    "    log_to_json(logstd_filepath, SIM_METRICS, std_dit)\n",
    "    if IN_COLAB:\n",
    "        log_to_pickle(\n",
    "            os.path.join(output_dir, f\"log_std_{Nsamples}N.pkl\"),\n",
    "            log_std,\n",
    "            dw_func=gfiles.download,\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
