{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Tutorial 6: Multi-Day Simulation Testing\n",
                "\n",
                "**WSmart+ Route Tutorial Series**\n",
                "\n",
                "This tutorial covers multi-day waste collection simulation for comparing routing policies. You'll learn:\n",
                "\n",
                "1. **Bins**: waste accumulation and overflow dynamics\n",
                "2. **Simulation concepts**: daily fill-collect-log cycle\n",
                "3. **Routing policies**: regular, neural, and classical approaches\n",
                "4. **Running simulations** and collecting metrics\n",
                "5. **Analyzing results** with visualizations\n",
                "\n",
                "**Previous**: [05_evaluation_and_decoding.ipynb](05_evaluation_and_decoding.ipynb) | **Next**: [07_extending_the_codebase.ipynb](07_extending_the_codebase.ipynb)\n",
                "\n",
                "> **Note**: This tutorial uses synthetic data to demonstrate the simulation framework. Real-world simulations use empirical waste data from sensor-equipped bins."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import sys\n",
                "import warnings\n",
                "\n",
                "warnings.filterwarnings(\"ignore\")\n",
                "\n",
                "PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), \"..\", \"..\"))\n",
                "if PROJECT_ROOT not in sys.path:\n",
                "    sys.path.insert(0, PROJECT_ROOT)\n",
                "\n",
                "import matplotlib.pyplot as plt\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import torch\n",
                "\n",
                "torch.manual_seed(42)\n",
                "np.random.seed(42)\n",
                "print(f\"Project root: {PROJECT_ROOT}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 1. Understanding Waste Bins\n",
                "\n",
                "In real-world waste collection, bins fill up over time. Each day, citizens deposit waste, and the municipality must decide which bins to collect. The challenge: collect bins efficiently before they overflow, while minimizing travel costs.\n",
                "\n",
                "### Key Concepts\n",
                "\n",
                "| Concept | Description |\n",
                "|---------|-------------|\n",
                "| **Fill level** | Current waste level (0-100%) |\n",
                "| **Overflow** | When fill level exceeds 100% - waste is lost |\n",
                "| **Collection** | Emptying a bin (reset to 0%) |\n",
                "| **Revenue** | Income from collected waste (per kg) |\n",
                "| **Expenses** | Cost of travel (per km) |\n",
                "| **Profit** | Revenue - Expenses |"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Simulate bin filling over 10 days (simplified)\n",
                "n_bins = 10\n",
                "n_days = 15\n",
                "\n",
                "np.random.seed(42)\n",
                "\n",
                "# Generate daily fill rates from gamma distribution (realistic waste patterns)\n",
                "alpha, beta = 5.0, 10.0  # Shape and scale\n",
                "daily_fills = np.random.gamma(alpha, 1.0 / beta, size=(n_days, n_bins)) * 100  # Scale to percentage\n",
                "\n",
                "# Simulate without collection (to see overflow dynamics)\n",
                "fill_levels = np.zeros((n_days + 1, n_bins))\n",
                "overflows = np.zeros((n_days, n_bins))\n",
                "\n",
                "for day in range(n_days):\n",
                "    new_level = fill_levels[day] + daily_fills[day]\n",
                "    overflows[day] = np.maximum(new_level - 100, 0)\n",
                "    fill_levels[day + 1] = np.minimum(new_level, 100)\n",
                "\n",
                "print(\"Bin Dynamics (no collection):\")\n",
                "print(f\"  Bins: {n_bins}\")\n",
                "print(f\"  Days simulated: {n_days}\")\n",
                "print(f\"  Mean daily fill rate: {daily_fills.mean():.1f}%\")\n",
                "print(f\"  Total overflow events: {(overflows > 0).sum()}\")\n",
                "print(f\"  Total waste lost to overflow: {overflows.sum():.1f}% equivalent\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, axes = plt.subplots(2, 1, figsize=(12, 8), gridspec_kw={\"height_ratios\": [3, 1]})\n",
                "\n",
                "# Top: Fill levels over time\n",
                "ax = axes[0]\n",
                "for i in range(min(5, n_bins)):\n",
                "    ax.plot(range(n_days + 1), fill_levels[:, i], linewidth=1.5, label=f\"Bin {i+1}\")\n",
                "ax.axhline(y=100, color=\"red\", linestyle=\"--\", linewidth=1, alpha=0.7, label=\"Overflow threshold\")\n",
                "ax.set_xlabel(\"Day\")\n",
                "ax.set_ylabel(\"Fill Level (%)\")\n",
                "ax.set_title(\"Bin Fill Levels Over Time (No Collection)\")\n",
                "ax.legend(bbox_to_anchor=(1.05, 1), loc=\"upper left\", fontsize=9)\n",
                "ax.grid(True, alpha=0.3)\n",
                "\n",
                "# Bottom: Daily overflow events\n",
                "ax = axes[1]\n",
                "daily_overflow_count = (overflows > 0).sum(axis=1)\n",
                "ax.bar(range(n_days), daily_overflow_count, color=\"red\", alpha=0.6, edgecolor=\"darkred\")\n",
                "ax.set_xlabel(\"Day\")\n",
                "ax.set_ylabel(\"Bins Overflowing\")\n",
                "ax.set_title(\"Daily Overflow Events\")\n",
                "ax.grid(True, alpha=0.3)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 2. Collection Policies\n",
                "\n",
                "A **routing policy** decides which bins to collect each day and in what order. Different policies trade off between:\n",
                "- **Collection coverage**: How many bins to empty\n",
                "- **Travel efficiency**: How to minimize distance\n",
                "- **Overflow prevention**: Prioritizing nearly-full bins"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def simulate_policy(daily_fills, distance_matrix, policy_fn, n_days=None):\n",
                "    \"\"\"Run a multi-day simulation with a given collection policy.\n",
                "    \n",
                "    Args:\n",
                "        daily_fills: (n_days, n_bins) array of daily fill increments\n",
                "        distance_matrix: (n_bins+1, n_bins+1) distance matrix (index 0 = depot)\n",
                "        policy_fn: function(fill_levels, distance_matrix) -> list of bin indices to collect\n",
                "        n_days: number of days to simulate (defaults to all days in daily_fills)\n",
                "    \n",
                "    Returns:\n",
                "        Dictionary with simulation metrics\n",
                "    \"\"\"\n",
                "    if n_days is None:\n",
                "        n_days = len(daily_fills)\n",
                "    n_bins = daily_fills.shape[1]\n",
                "    \n",
                "    fill_levels = np.zeros(n_bins)\n",
                "    metrics = {\n",
                "        \"fill_history\": [],\n",
                "        \"collections\": [],\n",
                "        \"overflows\": [],\n",
                "        \"distance\": [],\n",
                "        \"waste_collected\": [],\n",
                "        \"waste_lost\": [],\n",
                "    }\n",
                "    \n",
                "    for day in range(n_days):\n",
                "        # Step 1: Fill bins\n",
                "        fill_levels += daily_fills[day]\n",
                "        \n",
                "        # Step 2: Record overflow BEFORE collection\n",
                "        overflow = np.maximum(fill_levels - 100, 0)\n",
                "        waste_lost = overflow.sum()\n",
                "        fill_levels = np.minimum(fill_levels, 100)\n",
                "        \n",
                "        # Step 3: Decide which bins to collect\n",
                "        tour = policy_fn(fill_levels.copy(), distance_matrix)\n",
                "        \n",
                "        # Step 4: Calculate tour distance\n",
                "        if len(tour) > 0:\n",
                "            route = [0] + list(tour) + [0]  # Start and end at depot\n",
                "            total_dist = sum(distance_matrix[route[i], route[i+1]] for i in range(len(route)-1))\n",
                "        else:\n",
                "            total_dist = 0.0\n",
                "        \n",
                "        # Step 5: Collect waste\n",
                "        waste_collected = fill_levels[tour].sum() if len(tour) > 0 else 0.0\n",
                "        if len(tour) > 0:\n",
                "            fill_levels[tour] = 0.0\n",
                "        \n",
                "        # Record metrics\n",
                "        metrics[\"fill_history\"].append(fill_levels.copy())\n",
                "        metrics[\"collections\"].append(len(tour))\n",
                "        metrics[\"overflows\"].append(int((overflow > 0).sum()))\n",
                "        metrics[\"distance\"].append(total_dist)\n",
                "        metrics[\"waste_collected\"].append(waste_collected)\n",
                "        metrics[\"waste_lost\"].append(waste_lost)\n",
                "    \n",
                "    return metrics\n",
                "\n",
                "\n",
                "# Generate a distance matrix (random symmetric)\n",
                "n_bins = 10\n",
                "np.random.seed(42)\n",
                "coords = np.random.rand(n_bins + 1, 2)  # +1 for depot at index 0\n",
                "dist_matrix = np.sqrt(((coords[:, None] - coords[None, :]) ** 2).sum(axis=-1))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def regular_policy(fill_levels, distance_matrix, interval=3):\n",
                "    \"\"\"Collect all bins every N days.\"\"\"\n",
                "    regular_policy._day_count = getattr(regular_policy, \"_day_count\", 0) + 1\n",
                "    if regular_policy._day_count % interval == 0:\n",
                "        return list(range(len(fill_levels)))\n",
                "    return []\n",
                "\n",
                "\n",
                "def threshold_policy(fill_levels, distance_matrix, threshold=70.0):\n",
                "    \"\"\"Collect bins that exceed a fill threshold.\"\"\"\n",
                "    return list(np.where(fill_levels >= threshold)[0])\n",
                "\n",
                "\n",
                "def greedy_nearest_policy(fill_levels, distance_matrix, threshold=50.0):\n",
                "    \"\"\"Collect high-fill bins using nearest-neighbor ordering.\"\"\"\n",
                "    candidates = np.where(fill_levels >= threshold)[0]\n",
                "    if len(candidates) == 0:\n",
                "        return []\n",
                "    \n",
                "    # Nearest-neighbor ordering from depot\n",
                "    tour = []\n",
                "    remaining = set(candidates.tolist())\n",
                "    current = 0  # Start at depot\n",
                "    \n",
                "    while remaining:\n",
                "        # Add 1 to index since distance_matrix includes depot at 0\n",
                "        distances = {b: distance_matrix[current, b + 1] for b in remaining}\n",
                "        nearest = min(distances, key=distances.get)\n",
                "        tour.append(nearest)\n",
                "        current = nearest + 1\n",
                "        remaining.remove(nearest)\n",
                "    \n",
                "    return tour\n",
                "\n",
                "\n",
                "def priority_policy(fill_levels, distance_matrix, max_collections=5):\n",
                "    \"\"\"Collect the most-full bins first, limited to max per day.\"\"\"\n",
                "    sorted_bins = np.argsort(fill_levels)[::-1]\n",
                "    # Only collect bins above 30% fill\n",
                "    candidates = [b for b in sorted_bins if fill_levels[b] > 30.0]\n",
                "    return candidates[:max_collections]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Reset regular policy counter\n",
                "regular_policy._day_count = 0\n",
                "\n",
                "# Generate more days of data\n",
                "np.random.seed(42)\n",
                "n_days = 20\n",
                "daily_fills = np.random.gamma(5.0, 1.0 / 10.0, size=(n_days, n_bins)) * 100\n",
                "\n",
                "policies = {\n",
                "    \"Regular (every 3 days)\": lambda fl, dm: regular_policy(fl, dm, interval=3),\n",
                "    \"Threshold (70%)\": lambda fl, dm: threshold_policy(fl, dm, threshold=70.0),\n",
                "    \"Greedy Nearest (50%)\": lambda fl, dm: greedy_nearest_policy(fl, dm, threshold=50.0),\n",
                "    \"Priority (top 5)\": lambda fl, dm: priority_policy(fl, dm, max_collections=5),\n",
                "}\n",
                "\n",
                "results = {}\n",
                "for name, policy_fn in policies.items():\n",
                "    # Reset state for regular policy\n",
                "    if \"Regular\" in name:\n",
                "        regular_policy._day_count = 0\n",
                "    results[name] = simulate_policy(daily_fills, dist_matrix, policy_fn, n_days)\n",
                "\n",
                "print(\"Simulation Complete!\")\n",
                "print(f\"{'Policy':<25} {'Total Collected':>15} {'Total Lost':>12} {'Total Dist':>12} {'Overflows':>10}\")\n",
                "print(\"-\" * 78)\n",
                "for name, m in results.items():\n",
                "    print(f\"{name:<25} {sum(m['waste_collected']):>15.1f} {sum(m['waste_lost']):>12.1f} \"\n",
                "          f\"{sum(m['distance']):>12.2f} {sum(m['overflows']):>10d}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
                "\n",
                "# 1. Cumulative waste collected\n",
                "ax = axes[0, 0]\n",
                "for name, m in results.items():\n",
                "    ax.plot(np.cumsum(m[\"waste_collected\"]), linewidth=2, label=name)\n",
                "ax.set_xlabel(\"Day\")\n",
                "ax.set_ylabel(\"Cumulative Waste Collected (%)\")\n",
                "ax.set_title(\"Waste Collection Over Time\")\n",
                "ax.legend(fontsize=8)\n",
                "ax.grid(True, alpha=0.3)\n",
                "\n",
                "# 2. Cumulative overflow\n",
                "ax = axes[0, 1]\n",
                "for name, m in results.items():\n",
                "    ax.plot(np.cumsum(m[\"overflows\"]), linewidth=2, label=name)\n",
                "ax.set_xlabel(\"Day\")\n",
                "ax.set_ylabel(\"Cumulative Overflow Events\")\n",
                "ax.set_title(\"Overflow Events Over Time\")\n",
                "ax.legend(fontsize=8)\n",
                "ax.grid(True, alpha=0.3)\n",
                "\n",
                "# 3. Daily distance traveled\n",
                "ax = axes[1, 0]\n",
                "for name, m in results.items():\n",
                "    ax.plot(m[\"distance\"], linewidth=1.5, alpha=0.8, label=name)\n",
                "ax.set_xlabel(\"Day\")\n",
                "ax.set_ylabel(\"Distance Traveled\")\n",
                "ax.set_title(\"Daily Travel Distance\")\n",
                "ax.legend(fontsize=8)\n",
                "ax.grid(True, alpha=0.3)\n",
                "\n",
                "# 4. Summary bar chart\n",
                "ax = axes[1, 1]\n",
                "policy_names = list(results.keys())\n",
                "total_collected = [sum(results[n][\"waste_collected\"]) for n in policy_names]\n",
                "total_lost = [sum(results[n][\"waste_lost\"]) for n in policy_names]\n",
                "\n",
                "x = np.arange(len(policy_names))\n",
                "width = 0.35\n",
                "ax.bar(x - width/2, total_collected, width, label=\"Collected\", color=\"steelblue\", alpha=0.8)\n",
                "ax.bar(x + width/2, total_lost, width, label=\"Lost (overflow)\", color=\"red\", alpha=0.6)\n",
                "ax.set_xticks(x)\n",
                "ax.set_xticklabels([n.split(\"(\")[0].strip() for n in policy_names], rotation=15, ha=\"right\")\n",
                "ax.set_ylabel(\"Total Waste (%)\")\n",
                "ax.set_title(\"Collection vs Overflow\")\n",
                "ax.legend()\n",
                "ax.grid(True, alpha=0.3, axis=\"y\")\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 3. WSmart+ Route Simulation Framework\n",
                "\n",
                "The WSmart+ Route simulator provides a comprehensive framework for multi-day simulation testing with:\n",
                "\n",
                "- **Bins class**: Manages bin state with stochastic/empirical filling\n",
                "- **Distance matrices**: Real-world road network distances\n",
                "- **Policy adapters**: Unified interface for all routing strategies\n",
                "- **Parallel execution**: Multi-process simulation across seeds\n",
                "\n",
                "### CLI Usage\n",
                "\n",
                "```bash\n",
                "# Run simulation with multiple policies\n",
                "python main.py test_sim --policies regular alns hgs --days 31 --size 50\n",
                "\n",
                "# With neural agent\n",
                "python main.py test_sim --policies neural regular --days 31 --model weights/best.pt\n",
                "```"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 4. Results Analysis\n",
                "\n",
                "Let's create a comprehensive analysis of the simulation results."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create summary DataFrame\n",
                "summary_data = []\n",
                "for name, m in results.items():\n",
                "    summary_data.append({\n",
                "        \"Policy\": name,\n",
                "        \"Total Collected (%)\": sum(m[\"waste_collected\"]),\n",
                "        \"Total Lost (%)\": sum(m[\"waste_lost\"]),\n",
                "        \"Total Distance\": sum(m[\"distance\"]),\n",
                "        \"Total Overflows\": sum(m[\"overflows\"]),\n",
                "        \"Avg Collections/Day\": np.mean(m[\"collections\"]),\n",
                "        \"Collection Efficiency\": (\n",
                "            sum(m[\"waste_collected\"]) / max(sum(m[\"distance\"]), 0.001)\n",
                "        ),\n",
                "    })\n",
                "\n",
                "df = pd.DataFrame(summary_data)\n",
                "df = df.set_index(\"Policy\")\n",
                "print(\"Simulation Summary:\")\n",
                "print(df.to_string())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Radar chart for multi-metric comparison\n",
                "metrics_for_radar = [\"Total Collected (%)\", \"Collection Efficiency\", \"Avg Collections/Day\"]\n",
                "\n",
                "# Invert metrics where lower is better\n",
                "inverted_metrics = {\"Total Lost (%)\", \"Total Distance\", \"Total Overflows\"}\n",
                "\n",
                "fig, ax = plt.subplots(figsize=(8, 8), subplot_kw=dict(polar=True))\n",
                "\n",
                "categories = [\"Collection\\nVolume\", \"Efficiency\\n(waste/km)\", \"Collection\\nFrequency\",\n",
                "              \"Low\\nOverflow\", \"Low\\nDistance\"]\n",
                "n_cats = len(categories)\n",
                "\n",
                "# Normalize each metric to [0, 1]\n",
                "radar_data = {}\n",
                "for name in df.index:\n",
                "    vals = [\n",
                "        df.loc[name, \"Total Collected (%)\"],\n",
                "        df.loc[name, \"Collection Efficiency\"],\n",
                "        df.loc[name, \"Avg Collections/Day\"],\n",
                "        1.0 / max(df.loc[name, \"Total Overflows\"] + 1, 1),  # Inverse: fewer overflows = better\n",
                "        1.0 / max(df.loc[name, \"Total Distance\"] + 0.1, 0.1),  # Inverse: less distance = better\n",
                "    ]\n",
                "    radar_data[name] = vals\n",
                "\n",
                "# Normalize across policies\n",
                "all_vals = np.array(list(radar_data.values()))\n",
                "mins = all_vals.min(axis=0)\n",
                "maxs = all_vals.max(axis=0)\n",
                "ranges = maxs - mins\n",
                "ranges[ranges == 0] = 1  # Avoid division by zero\n",
                "\n",
                "angles = np.linspace(0, 2 * np.pi, n_cats, endpoint=False).tolist()\n",
                "angles += angles[:1]\n",
                "\n",
                "colors = [\"steelblue\", \"coral\", \"seagreen\", \"purple\"]\n",
                "for idx, (name, vals) in enumerate(radar_data.items()):\n",
                "    normalized = (np.array(vals) - mins) / ranges\n",
                "    values = normalized.tolist()\n",
                "    values += values[:1]\n",
                "    \n",
                "    ax.plot(angles, values, \"o-\", linewidth=2, label=name.split(\"(\")[0].strip(),\n",
                "            color=colors[idx], markersize=6)\n",
                "    ax.fill(angles, values, alpha=0.1, color=colors[idx])\n",
                "\n",
                "ax.set_xticks(angles[:-1])\n",
                "ax.set_xticklabels(categories, fontsize=10)\n",
                "ax.set_ylim(0, 1.1)\n",
                "ax.legend(loc=\"upper right\", bbox_to_anchor=(1.3, 1.1), fontsize=9)\n",
                "ax.set_title(\"Multi-Metric Policy Comparison\", fontsize=13, pad=20)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Heatmap of fill levels over time for best policy\n",
                "best_policy = min(results.keys(), key=lambda k: sum(results[k][\"waste_lost\"]))\n",
                "fill_history = np.array(results[best_policy][\"fill_history\"])\n",
                "\n",
                "fig, ax = plt.subplots(figsize=(12, 5))\n",
                "im = ax.imshow(fill_history.T, aspect=\"auto\", cmap=\"YlOrRd\", vmin=0, vmax=100)\n",
                "ax.set_xlabel(\"Day\", fontsize=12)\n",
                "ax.set_ylabel(\"Bin Index\", fontsize=12)\n",
                "ax.set_title(f\"Fill Levels Over Time - {best_policy}\", fontsize=13)\n",
                "plt.colorbar(im, ax=ax, label=\"Fill Level (%)\", shrink=0.8)\n",
                "ax.set_yticks(range(n_bins))\n",
                "ax.set_yticklabels([f\"Bin {i+1}\" for i in range(n_bins)])\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 5. Key Insights\n",
                "\n",
                "### Policy Trade-offs\n",
                "\n",
                "- **Regular collection** is simple but wasteful (collects even empty bins) and misses high-fill bins between collection days\n",
                "- **Threshold-based** policies are reactive - they wait until bins are nearly full, risking overflow\n",
                "- **Nearest-neighbor greedy** policies balance fill level awareness with travel efficiency\n",
                "- **Priority-based** policies focus on the most urgent bins but may miss efficient routing\n",
                "\n",
                "### Why Neural Policies?\n",
                "\n",
                "Neural routing policies (trained in Tutorial 4) can learn to:\n",
                "- **Predict** which bins will overflow soon\n",
                "- **Optimize** routes for both collection urgency and travel efficiency\n",
                "- **Generalize** across different demand patterns and problem sizes\n",
                "- Make decisions in **milliseconds** (vs. seconds/minutes for classical solvers)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Summary\n",
                "\n",
                "In this tutorial, you learned:\n",
                "\n",
                "- **Bin dynamics**: Waste accumulates daily following stochastic patterns; overflows cause waste loss\n",
                "- **Collection policies** make daily decisions about which bins to collect and in what order\n",
                "- **Simulation framework** enables multi-day testing with various policies and metrics\n",
                "- **Key metrics**: waste collected, overflow events, travel distance, collection efficiency\n",
                "- **Trade-offs**: Every policy balances collection coverage, travel cost, and overflow prevention\n",
                "- **Neural policies** can learn to outperform hand-crafted heuristics through RL training\n",
                "\n",
                "### Full Tutorial Series\n",
                "\n",
                "1. **[Data Generation](01_data_generation.ipynb)** - Creating problem instances and datasets\n",
                "2. **[Environments](02_environments.ipynb)** - RL environment abstraction and state management\n",
                "3. **[Models & Policies](03_models_and_policies.ipynb)** - Neural and classical routing policies\n",
                "4. **[Training](04_training_with_lightning.ipynb)** - RL training with PyTorch Lightning\n",
                "5. **[Evaluation](05_evaluation_and_decoding.ipynb)** - Decoding strategies and metrics\n",
                "6. **[Simulation](06_simulation_testing.ipynb)** - Multi-day simulation testing (this tutorial)\n",
                "\n",
                "For production-scale experiments, use the CLI:\n",
                "```bash\n",
                "python main.py test_sim --policies regular neural alns hgs --days 31 --size 50\n",
                "```"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
