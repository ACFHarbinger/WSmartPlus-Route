{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WSmart+ Route Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup completed - added home_dir to system path: /home/pkhunter/Repositories/WSmart-Route\n"
     ]
    }
   ],
   "source": [
    "from notebook_setup import setup_home_directory, setup_google_colab\n",
    "\n",
    "\n",
    "NOTEBOOK_NAME = 'datasets'\n",
    "home_dir = setup_home_directory(NOTEBOOK_NAME)\n",
    "IN_COLAB, gdrive, gfiles = setup_google_colab(NOTEBOOK_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    %pip install osmnx\n",
    "    %pip install plotly\n",
    "    %pip install pandas\n",
    "    %pip install scipy\n",
    "    %pip install torch\n",
    "    %pip install torch_geometric\n",
    "    %pip install networkx\n",
    "    %pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import json\n",
    "import torch\n",
    "import osmnx as ox\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from itertools import islice\n",
    "from collections.abc import Iterable\n",
    "from torch.utils.data import DataLoader\n",
    "from scipy.stats import gamma\n",
    "from torch_geometric.utils import segregate_self_loops\n",
    "\n",
    "from logic.src.pipeline.simulator.wsmart_bin_analysis import OldGridBase, GridBase, Simulation\n",
    "from logic.src.utils.plot_utils import draw_graph\n",
    "from logic.src.utils.functions import load_problem\n",
    "from logic.src.utils.graph_utils import sort_by_pairs\n",
    "from logic.src.pipeline.simulator.processor import process_indices, haversine_distance\n",
    "from logic.src.pipeline.simulator.network import compute_distance_matrix\n",
    "from logic.src.pipeline.simulator.loader import load_depot, load_simulator_data\n",
    "\n",
    "\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "MAX_DISPLAY_ROWS = 500\n",
    "pd.set_option('display.max_rows', MAX_DISPLAY_ROWS)\n",
    "\n",
    "SHOW_MAPS = False\n",
    "SHOW_LISTS = False\n",
    "SHOW_TABLES = False\n",
    "if IN_COLAB: \n",
    "    gdrive.mount('/content/drive')\n",
    "\n",
    "# Required to use matplotlib in Windows without breaking the Kernel\n",
    "if os.name == 'nt':\n",
    "    os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_type(obj, obj_name=None):\n",
    "    def _flatten(S):\n",
    "        if S == []:\n",
    "            return S\n",
    "        if isinstance(S[0], Iterable):\n",
    "            return _flatten(S[0]) + _flatten(S[1:])\n",
    "        return S[:1] + _flatten(S[1:])\n",
    "\n",
    "    if not obj_name is None:\n",
    "        print(f\"Type of {obj_name} instance: {type(obj)}\")\n",
    "    else:\n",
    "        print(f\"Type: {type(obj)}\")\n",
    "\n",
    "    if isinstance(obj, Iterable):\n",
    "        if isinstance(obj, pd.DataFrame):\n",
    "            print(f\"Iterable dimensions: {obj.shape}\")\n",
    "            print(f\"Element type: {type(obj.iloc[0])}\")\n",
    "        else:\n",
    "            if not isinstance(obj, np.ndarray):\n",
    "                obj = np.array(obj)\n",
    "\n",
    "            print(f\"Iterable dimensions: {obj.shape}\")\n",
    "            print(f\"Element type: {type(obj.item(0))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>39.183851</td>\n",
       "      <td>-9.148065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID        Lat       Lng\n",
       "0   0  39.183851 -9.148065"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "area = \"Rio Maior\"\n",
    "data_dir = os.path.join(home_dir, \"data\", \"wsr_simulator\")\n",
    "depot = load_depot(data_dir, area)\n",
    "depot_c = depot[['ID', 'Lat', 'Lng']]\n",
    "depot_c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WSmart+ Route Simulator (WSRS) original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_maxmin_latlong(coords):\n",
    "    print('Coordinate limits for', len(coords), 'bins:')\n",
    "    print('- Lat min:', coords['Lat'].min())\n",
    "    print('- Lat max:', coords['Lat'].max())\n",
    "    print('- Lon min:', coords['Lng'].min())\n",
    "    print('- Lon max:', coords['Lng'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordinate limits for 225 bins:\n",
      "- Lat min: 39.1923394226\n",
      "- Lat max: 39.4742888888889\n",
      "- Lon min: -9.19131189008\n",
      "- Lon max: -8.79293435861\n"
     ]
    }
   ],
   "source": [
    "old_data225, old_coords225 = load_simulator_data(data_dir, number_of_bins=225, area=\"mixrmbac\")\n",
    "old_dist_matrix225 = compute_distance_matrix(pd.concat([depot_c, old_coords225]).reset_index(drop=True), method='ogd')\n",
    "show_maxmin_latlong(old_coords225)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHOW_MAPS:\n",
    "    coords225_to_print = old_coords225.copy()\n",
    "    coords225_to_print['Dist_Depot'] = old_dist_matrix225[:1, 1:][0]\n",
    "    fig = px.scatter_mapbox(\n",
    "        coords225_to_print, \n",
    "        lat=\"Lat\", \n",
    "        lon=\"Lng\", \n",
    "        hover_name=\"ID\", \n",
    "        hover_data=[\"ID\", \"Dist_Depot\"],\n",
    "        color=\"Dist_Depot\",\n",
    "        color_continuous_scale=[(0, 'cyan'), (1,'blue')],\n",
    "        #color_discrete_sequence=[\"blue\"],\n",
    "        size_max=10,\n",
    "        zoom=10,\n",
    "        height=650,\n",
    "        width=750\n",
    "    )\n",
    "\n",
    "    fig.add_trace(go.Scattermapbox(\n",
    "        lat=depot_c['Lat'],\n",
    "        lon=depot_c['Lng'],\n",
    "        mode=\"markers+text\",\n",
    "        marker=go.scattermapbox.Marker(size=10, color=\"black\"),\n",
    "        text=[\"Depot\"],\n",
    "        textposition=\"bottom center\",\n",
    "        name=\"Depot\",\n",
    "        showlegend=False\n",
    "    ))\n",
    "\n",
    "    fig.update_layout(mapbox_style=\"open-street-map\")\n",
    "    fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    # mode='all'|'all_public'|'drive_service'|'drive'|'bike'|'walk'\n",
    "    mode = 'drive_service'\n",
    "    ox.settings.use_cache = True\n",
    "    ox.settings.log_console = True\n",
    "    #bbox_limits = (np.min(bins_coords['Lat'])-0.5, np.max(bins_coords['Lng'])-0.2, np.max(bins_coords['Lng'])+0.2, np.min(bins_coords['Lat'])+0.5)\n",
    "    bbox_limits = (np.min(bins_coords['Lat']), np.max(bins_coords['Lng']), np.max(bins_coords['Lng']), np.min(bins_coords['Lat']))\n",
    "    graph = ox.graph_from_bbox(bbox_limits, network_type=mode)\n",
    "    ox.plot_graph(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    i = 0\n",
    "    matrix = [['BIN_ID_X', 'BIN_ID_Y', 'DISTANCE']]\n",
    "    for bin in islice(bins_coords.iterrows(), 0, len(list(bins_coords.ID))):\n",
    "        j = 0\n",
    "        for each_bin in bins_coords.iterrows():\n",
    "            start_coords = (float(bin[1][1]), float(bin[1][2]))\n",
    "            end_coords = (float(each_bin[1][1]), float(each_bin[1][2]))\n",
    "            orig_node = ox.nearest_nodes(graph, start_coords[0], start_coords[1])\n",
    "            dest_node = ox.nearest_nodes(graph, end_coords[0], end_coords[1])\n",
    "            print('orig:', orig_node)\n",
    "            print('dest:', dest_node)\n",
    "            shortest_route_distance = nx.shortest_path_length(graph, orig_node, dest_node, weight=\"length\", method=\"dijkstra\")\n",
    "            matrix.append([str(int(bin[1][0])) + \", \" + str(int(each_bin[1][0])) + \", \" + str(float(shortest_route_distance))])\n",
    "            print(matrix[-1])\n",
    "\n",
    "    print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WSRS full dataset and subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordinate limits for 20 bins:\n",
      "- Lat min: 39.2394966666667\n",
      "- Lat max: 39.313247722\n",
      "- Lon min: -9.14663990915\n",
      "- Lon max: -9.05968835622\n"
     ]
    }
   ],
   "source": [
    "old_data20, old_coords20 = load_simulator_data(data_dir, number_of_bins=20, area=\"mixrmbac\")\n",
    "old_dist_matrix20 = compute_distance_matrix(pd.concat([depot_c, old_coords20]).reset_index(drop=True), method='ogd')\n",
    "show_maxmin_latlong(old_coords20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordinate limits for 50 bins:\n",
      "- Lat min: 39.1933922824\n",
      "- Lat max: 39.3278877543\n",
      "- Lon min: -9.19131189008\n",
      "- Lon max: -8.84237843324\n"
     ]
    }
   ],
   "source": [
    "old_data50, old_coords50 = load_simulator_data(data_dir, number_of_bins=50, area=\"mixrmbac\")\n",
    "old_dist_matrix50 = compute_distance_matrix(pd.concat([depot_c, old_coords50]).reset_index(drop=True), method='ogd')\n",
    "show_maxmin_latlong(old_coords50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "s20 = pd.Series(np.sum(old_dist_matrix20[1:, 1:], axis=1)).sort_values()\n",
    "s50 = pd.Series(np.sum(old_dist_matrix50[1:, 1:], axis=1)).sort_values()\n",
    "s225 = pd.Series(np.sum(old_dist_matrix225[1:, 1:], axis=1)).sort_values()\n",
    "\n",
    "# Reindex series to the same index (use union of all indices)\n",
    "index_union = s20.index.union(s50.index).union(s225.index)\n",
    "\n",
    "# Reindex all series\n",
    "s20 = s20.reindex(index_union).sort_values()\n",
    "s50 = s50.reindex(index_union).sort_values()\n",
    "s225 = s225.reindex(index_union).sort_values()\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'ID20': s20.index, 'B20': s20.values,\n",
    "    'ID50': s50.index, 'B50': s50.values,\n",
    "    'ID225': s225.index, 'B225': s225.values\n",
    "})\n",
    "if SHOW_TABLES: display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WSmart+ Bin Analysis (WSBA) data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordinate limits for 317 bins:\n",
      "- Lat min: 39.25353454\n",
      "- Lat max: 39.4482722222222\n",
      "- Lon min: -8.98823888888889\n",
      "- Lon max: -8.79266007\n"
     ]
    }
   ],
   "source": [
    "data317, coords317 = load_simulator_data(data_dir, number_of_bins=317, area=area)\n",
    "dist_matrix317 = compute_distance_matrix(pd.concat([depot_c, coords317]).reset_index(drop=True), method='ogd')\n",
    "show_maxmin_latlong(coords317)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39.350903381111095\n",
      "-0.09736884111109845\n",
      "0.09736884111110555\n"
     ]
    }
   ],
   "source": [
    "center_parallel = (coords317['Lat'].min() + coords317['Lat'].max()) / 2\n",
    "print(center_parallel)\n",
    "print(coords317['Lat'].min() - center_parallel)\n",
    "print(coords317['Lat'].max() - center_parallel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHOW_MAPS:\n",
    "    coords317_to_print = coords317.copy()\n",
    "    coords317_to_print['Dist_Depot'] = dist_matrix317[:1, 1:][0]\n",
    "    fig = px.scatter_mapbox(\n",
    "        coords317_to_print, \n",
    "        lat=\"Lat\", \n",
    "        lon=\"Lng\", \n",
    "        hover_name=\"ID\", \n",
    "        hover_data=[\"ID\", \"Dist_Depot\"],\n",
    "        color=\"Dist_Depot\",\n",
    "        color_continuous_scale=[(0, 'cyan'), (1,'blue')],\n",
    "        #color_discrete_sequence=[\"blue\"],\n",
    "        size_max=10,\n",
    "        zoom=10,\n",
    "        height=450,\n",
    "        width=550\n",
    "    )\n",
    "\n",
    "    fig.add_trace(go.Scattermapbox(\n",
    "        lat=depot_c['Lat'],\n",
    "        lon=depot_c['Lng'],\n",
    "        mode=\"markers+text\",\n",
    "        marker=go.scattermapbox.Marker(size=10, color=\"black\"),\n",
    "        text=[\"Depot\"],\n",
    "        textposition=\"bottom center\",\n",
    "        name=\"Depot\",\n",
    "        showlegend=False\n",
    "    ))\n",
    "\n",
    "    fig.update_layout(mapbox_style=\"open-street-map\")\n",
    "    fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separate types of waste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_old_wsba_coords(bins_coords):\n",
    "    bins_coords = bins_coords.rename(columns={'Latitude': 'Lat', 'Longitude': 'Lng'})\n",
    "    bins_coords = bins_coords[['ID', 'Lat', 'Lng']]\n",
    "    return bins_coords.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of info instance: <class 'pandas.core.frame.DataFrame'>\n",
      "Iterable dimensions: (317, 11)\n",
      "Element type: <class 'pandas.core.series.Series'>\n",
      "Type of new_data instance: <class 'pandas.core.frame.DataFrame'>\n",
      "Iterable dimensions: (1025, 317)\n",
      "Element type: <class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "grid = OldGridBase(data_dir, area)\n",
    "new_data, info = grid.load_data()\n",
    "show_type(info, \"info\")\n",
    "show_type(new_data, \"new_data\")\n",
    "if SHOW_TABLES: display(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "waste_types = ['Mistura de embalagens', 'Embalagens de papel e cartão']\n",
    "plastic_bins = info[info['Tipo de Residuos'] == waste_types[0]]\n",
    "plastic_df = process_old_wsba_coords(plastic_bins)\n",
    "plastic_dist_matrix = compute_distance_matrix(pd.concat([depot_c, plastic_df]).reset_index(drop=True), method='ogd')\n",
    "plastic_df['Distance'] = np.sum(plastic_dist_matrix[1:, 1:], axis=1)\n",
    "if SHOW_TABLES: display(plastic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_plastic = plastic_df.merge(old_coords225, on=['Lat', 'Lng'], how='inner')\n",
    "merged_plastic = merged_plastic.drop('ID_y', axis=1).rename(columns={'ID_x': 'ID'})\n",
    "merged_idx = plastic_df[plastic_df['ID'].isin(merged_plastic['ID'])].index.tolist()\n",
    "merged_plastic.insert(0, 'index', merged_idx)\n",
    "merged_plastic = merged_plastic.sort_values('Distance')\n",
    "if SHOW_TABLES: display(merged_plastic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Intermediate graphs selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 10, 11, 13, 14, 15, 21, 24, 30, 32, 33, 46, 63, 64, 74, 76, 154, 155, 157, 169]\n"
     ]
    }
   ],
   "source": [
    "first20_plastic = merged_plastic['index'].head(20).tolist()\n",
    "first20_plastic.sort()\n",
    "if SHOW_LISTS: print(first20_plastic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 3, 4, 5, 7, 9, 11, 13, 14, 15, 17, 20, 21, 24, 27, 30, 32, 33, 37, 38, 45, 46, 57, 63, 64, 66, 67, 70, 73, 74, 75, 76, 128, 141, 146, 149, 150, 151, 152, 153, 154, 156, 157, 158, 160, 163, 166, 169, 172]\n"
     ]
    }
   ],
   "source": [
    "last50_plastic = merged_plastic['index'].tail(50).tolist()\n",
    "last50_plastic.sort()\n",
    "if SHOW_LISTS: print(last50_plastic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckeys = ['Lat', 'Lng']\n",
    "mkeys = merged_plastic[ckeys].apply(tuple, axis=1)\n",
    "pkeys = plastic_df[ckeys].apply(tuple, axis=1)\n",
    "wsba_only_df = plastic_df[~pkeys.isin(mkeys)].sort_values('Distance')\n",
    "wsba_only_idx = plastic_df[plastic_df['ID'].isin(wsba_only_df['ID'])].index.tolist()\n",
    "wsba_only_df.insert(0, 'index', wsba_only_idx)\n",
    "wsba_only_df = wsba_only_df.sort_values('Distance')\n",
    "if SHOW_TABLES: display(wsba_only_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_plastic_df = plastic_df.reset_index().sort_values('Distance')\n",
    "if SHOW_TABLES: display(sorted_plastic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172]\n"
     ]
    }
   ],
   "source": [
    "last170_only_wsba = sorted_plastic_df['index'].tail(170).tolist()\n",
    "last170_only_wsba.sort()\n",
    "if SHOW_LISTS: print(last170_only_wsba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3, 4, 5, 7, 8, 10, 11, 12, 13, 14, 15, 16, 18, 19, 21, 22, 24, 25, 29, 30, 32, 33, 36, 37, 39, 40, 41, 42, 43, 46, 47, 54, 56, 58, 60, 61, 62, 63, 64, 68, 69, 71, 72, 74, 75, 76, 77, 78, 82, 85, 87, 92, 93, 94, 95, 97, 98, 99, 102, 104, 105, 107, 110, 111, 112, 113, 114, 115, 117, 118, 120, 122, 124, 125, 130, 135, 136, 137, 138, 139, 140, 141, 142, 145, 146, 147, 151, 153, 154, 155, 156, 157, 158, 159, 163, 164, 167, 169, 172]\n"
     ]
    }
   ],
   "source": [
    "first100_only_wsba = sorted_plastic_df['index'].head(100).tolist()\n",
    "first100_only_wsba.sort()\n",
    "if SHOW_LISTS: print(first100_only_wsba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Full data pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHOW_TABLES: display(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-12 00:00:00\n",
      "2023-10-23 00:00:00\n"
     ]
    }
   ],
   "source": [
    "new_index = new_data.index\n",
    "print(new_index[0])\n",
    "print(new_index[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_transpose = new_data.copy().transpose()\n",
    "new_data_transpose[\"Stock\"] = np.zeros((len(new_data_transpose)))\n",
    "new_data_transpose['Accum_Rate'] = new_data_transpose.mean(axis=1)\n",
    "new_data_transpose = new_data_transpose[['Stock', 'Accum_Rate']].reset_index(drop=False).rename(columns={'index': 'ID'})\n",
    "new_data_transpose['ID'] = pd.to_numeric(new_data_transpose['ID'])\n",
    "if SHOW_TABLES: display(new_data_transpose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_new_data = pd.merge(new_data_transpose, info, on='ID')\n",
    "full_new_data = full_new_data[['ID', 'Stock', 'Accum_Rate', 'Latitude', 'Longitude']].rename(columns={'Latitude': 'Lat', 'Longitude': 'Lng'})\n",
    "wsba_dist_depot = []\n",
    "for lat, long in zip(full_new_data['Lat'], full_new_data['Lng']):\n",
    "    tmp_dist = haversine_distance(depot['Lat'], depot['Lng'], lat, long)\n",
    "    wsba_dist_depot.append(tmp_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#full_new_data['Edge_Weight']= [sum(row) for row in compute_distance_matrix(full_new_data, wsba_size)]\n",
    "full_new_data['Dist_Depot'] = wsba_dist_depot\n",
    "if SHOW_TABLES: display(full_new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "unprocessed_data, _ = grid.load_data(processed=False)\n",
    "if SHOW_TABLES: display(unprocessed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ndays = 3\n",
    "srate_ls = []\n",
    "for _ in range(Ndays):\n",
    "    srate_ls.append(grid.sample())\n",
    "\n",
    "show_type(srate_ls)\n",
    "if SHOW_LISTS: print(srate_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trate_ls = []\n",
    "start_date = pd.to_datetime(\"2022-03-01\")\n",
    "end_date = pd.to_datetime(start_date) + pd.DateOffset(days=Ndays-1)\n",
    "for date in pd.date_range(start=start_date, end=end_date):\n",
    "    trate_ls.append(grid.get_values_by_date(date, sample = True))\n",
    "    \n",
    "show_type(trate_ls)\n",
    "if SHOW_LISTS: print(trate_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_rate = grid.get_std_rate()\n",
    "show_type(std_rate)\n",
    "print(std_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_rate = grid.get_mean_rate()\n",
    "show_type(mean_rate)\n",
    "print(mean_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_rate = grid.get_var_rate()\n",
    "show_type(var_rate)\n",
    "print(var_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins_idx = [0, 1]\n",
    "print(f\"Number of bins: {len(info)}\")\n",
    "for id in bins_idx:\n",
    "    print(grid.get_info(id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sampling waste fill values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters for gamma distribution\n",
    "alpha_comb = [[5, 10], [2, 6], [1, 3]]  # Shape parameters\n",
    "theta_comb = [[5, 2], [6, 4], [8, 6]]  # Scale parameters\n",
    "\n",
    "x = np.linspace(0, 1000, 1000)  # Range of x values for plotting\n",
    "\n",
    "# Plot PDFs for each combination of parameters\n",
    "plt.figure(figsize=(10, 6))\n",
    "for id, (alpha_values, theta_values) in enumerate(zip(alpha_comb, theta_comb)):\n",
    "    for alpha in alpha_values:\n",
    "        for theta in theta_values:\n",
    "            # Calculate PDF for gamma distribution\n",
    "            pdf = gamma.pdf(x, a=alpha, scale=theta)\n",
    "            \n",
    "            # Plot the PDF\n",
    "            plt.plot(x, pdf, label=f'α={alpha}, θ={theta}')\n",
    "\n",
    "    plt.title(f'Probability Density Function of Gamma Distribution {id+1}')\n",
    "    plt.xlabel('Daily Waste Fill')\n",
    "    plt.ylabel('PDF')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.xlim(0, 120)\n",
    "\n",
    "    #plt.savefig('gamma_distributions_dist2.png', dpi=300)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "from pipeline.simulator.wsmart_bin_analysis import OldGridBase\n",
    "\n",
    "\n",
    "class Bins:\n",
    "    def __init__(self, n, data_dir, sample_method=\"gamma\", grid=None):\n",
    "        assert sample_method in [\"grid\", \"gamma\"]\n",
    "        self.n = n\n",
    "        self.c = np.zeros((n))\n",
    "        self.means = np.ones((n))*10\n",
    "        self.std = np.ones((n))*1\n",
    "        self.lost = np.zeros((n))\n",
    "        self.distribution = sample_method\n",
    "        self.dist_param1 = np.ones((n))*10\n",
    "        self.dist_param2 = np.ones((n))*10\n",
    "        self.inoverflow = np.zeros((n))\n",
    "        self.collected = np.zeros((n))\n",
    "        self.ncollections = np.zeros((n))\n",
    "        self.travel = 0\n",
    "        self.ndays = 0\n",
    "        self.collectdays = np.ones((n))*5\n",
    "        self.collectlevl = np.ones((n))*80\n",
    "        self.indices = list(range(n))\n",
    "        self.data_dir = data_dir\n",
    "        if grid is None:\n",
    "            self.grid = OldGridBase(data_dir)\n",
    "        else:\n",
    "            self.grid = grid\n",
    "\n",
    "    def _predictdaystooverflow(self, ui, vi, f, cl):\n",
    "        n = np.zeros(ui.shape[0])+31\n",
    "        for ii in np.arange(1,31,1):\n",
    "            k = ii*ui**2/vi\n",
    "            th = vi/ui\n",
    "            aux = np.zeros(ui.shape[0])+31\n",
    "            p = 1-stats.gamma.cdf(100-f, k, scale=th)\n",
    "            aux[np.nonzero(p>cl)[0]]=ii\n",
    "            n = np.minimum(n,aux)\n",
    "            if (p>cl).all():\n",
    "                return n\n",
    "            \n",
    "    def predictdaystooverflow(self, cl):\n",
    "        return self._predictdaystooverflow(self.means, self.std, self.c, cl)\n",
    "    \n",
    "    def set_indices(self, indices=None):\n",
    "        if not indices is None:\n",
    "            self.indices = indices\n",
    "\n",
    "    def collect(self, idsfull):\n",
    "        if not idsfull:\n",
    "            return 0\n",
    "\n",
    "        ids = set(idsfull)\n",
    "        ids.remove(0)\n",
    "        ids = np.array(list(ids))-1\n",
    "\n",
    "        self.collected[ids] += self.c[ids]\n",
    "        self.ncollections[ids] += 1\n",
    "        collected = np.sum(self.c[ids])\n",
    "        self.c[ids] = 0\n",
    "        return collected\n",
    "\n",
    "    def predictdaystooverflow(self, cl):\n",
    "        return self._predictdaystooverflow(self.means, self.std, self.c, cl)\n",
    "\n",
    "    def stochasticFilling(self):\n",
    "        if self.distribution == 'gamma':\n",
    "            todaysfilling = np.random.gamma(self.dist_param1, self.dist_param2, size=(self.n, ))\n",
    "        elif self.distribution == 'emp':\n",
    "            todaysfilling = np.take(self.grid.sample(), self.indices)\n",
    "\n",
    "        # Lost overflows\n",
    "        self.lost += np.maximum(self.c + todaysfilling - 100, 0)\n",
    "\n",
    "        # New depositions - do not change order otherwise\n",
    "        # xq + vals + vals for the overflow calculation\n",
    "        self.c = np.minimum(self.c + todaysfilling, 100)\n",
    "        self.c = np.maximum(self.c, 0)\n",
    "        self.inoverflow += (self.c==100)\n",
    "        return np.sum(self.inoverflow)\n",
    "\n",
    "    def deterministicFilling(self, date):\n",
    "        todaysfilling = self.grid.get_values_by_date(date, sample = True)\n",
    "        \n",
    "        # Lost overflows\n",
    "        self.lost += np.maximum(self.c + todaysfilling - 100, 0)\n",
    "\n",
    "        # New depositions - do not change order otherwise\n",
    "        # xq + vals + vals for the overflow calculation\n",
    "        self.c = np.minimum(self.c + todaysfilling, 100)\n",
    "        self.c = np.maximum(self.c, 0)\n",
    "        self.inoverflow += (self.c==100)\n",
    "        return np.sum(self.inoverflow)\n",
    "\n",
    "    def __setDistribution(self, param1, param2):\n",
    "        if len(param1)==1:\n",
    "            self.dist_param1 = np.ones((self.n))*param1\n",
    "            self.dist_param2 = np.ones((self.n))*param2\n",
    "        else:\n",
    "            self.dist_param1 = param1\n",
    "            self.dist_param2 = param2\n",
    "        self.setCollectionLvlandFreq()\n",
    "\n",
    "    def setGammaDistribution(self, option=0):\n",
    "        def __set_param(param):\n",
    "            param_len = len(param)\n",
    "            if self.n == param_len:\n",
    "                return param\n",
    "            \n",
    "            param = param * math.ceil(self.n / param_len)\n",
    "            if self.n % param_len != 0:\n",
    "                param = param[:param_len-self.n % param_len]\n",
    "            return param\n",
    "    \n",
    "        self.distribution = 'gamma'\n",
    "        if option == 0:\n",
    "            k = __set_param([5, 5, 5, 5, 5, 10, 10, 10, 10, 10])\n",
    "            th = __set_param([5, 2])\n",
    "        elif option == 1:\n",
    "            k = __set_param([2, 2, 2, 2, 2, 6, 6, 6, 6, 6])\n",
    "            th = __set_param([6, 4])\n",
    "        elif option == 2:\n",
    "            k = __set_param([1, 1, 1, 1, 1, 3, 3, 3, 3, 3])\n",
    "            th = __set_param([8, 6])\n",
    "        else:\n",
    "            assert option == 3\n",
    "            k = __set_param([5, 2])\n",
    "            th = __set_param([10])\n",
    "        self.__setDistribution(k, th)\n",
    "\n",
    "    def freqvisit2(self, ui, vi, cf):\n",
    "        # a = gamma.cdf(30, k, scale=th)\n",
    "        # c = gamma.ppf(a, k, scale=th)\n",
    "        # print(a,c)\n",
    "        for n in range(1,50):\n",
    "            k = n*ui**2/vi\n",
    "            th = vi/ui\n",
    "            if n==1:\n",
    "                ov = 100-stats.gamma.ppf(1-cf, k, scale=th)\n",
    "\n",
    "            v = stats.gamma.ppf(1-cf, k, scale=th)\n",
    "            if v>100:\n",
    "                return n, ov\n",
    "\n",
    "    def setCollectionLvlandFreq(self, cf = 0.9):\n",
    "        for ii in range(0,self.n):\n",
    "            f2,lv2 = self.freqvisit2(self.dist_param1[ii]*self.dist_param2[ii],self.dist_param1[ii]*self.dist_param2[ii]**2,cf)\n",
    "            self.collectdays[ii] = f2\n",
    "            self.collectlevl[ii] = lv2\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_nodes = pd.concat([tmp_depot, bins_coords]).sort_index().reset_index(drop=True).drop('index', axis=1)\n",
    "all_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_nodes_new = pd.concat([tmp_depot[['ID', 'Lat', 'Lng']], full_new_data[['ID', 'Lat', 'Lng']]]).sort_index().reset_index(drop=True).drop('index', axis=1)\n",
    "all_nodes_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_dict = {'Sum': [], 'Avg': [], 'Min': [], 'Max': []}\n",
    "for nodes, g_size in zip([all_nodes, all_nodes_new], [wsrs_size, wsba_size]):\n",
    "    distance_matrix = compute_distance_matrix(nodes, g_size+1)\n",
    "    tmp_sum = sum(sum(row) for row in distance_matrix)\n",
    "    dist_dict['Sum'].append(tmp_sum)\n",
    "    dist_dict['Avg'].append(tmp_sum/(g_size+1))\n",
    "    dist_dict['Min'].append(min([min(x) for x in distance_matrix]))\n",
    "    dist_dict['Max'].append(max([max(x) for x in distance_matrix]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_df = pd.DataFrame(index=[wsrs_size, wsba_size])\n",
    "dist_df.index.names = [\"#bin\"]\n",
    "for key in dist_dict.keys():\n",
    "    dist_df[key] = dist_dict[key]\n",
    "\n",
    "dist_df\n",
    "#styled_df = dist_df.style.set_properties(subset=pd.IndexSlice[:, :], **{'font-weight': 'bold'})\n",
    "#styled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_matrix = compute_distance_matrix(all_nodes, wsrs_size+1)\n",
    "thresholds = [np.percentile(distance_matrix, 50), np.percentile(distance_matrix, 75), np.percentile(distance_matrix, 90)]\n",
    "for thresh in thresholds:\n",
    "    adj_matrix = (distance_matrix <= thresh).astype(int)\n",
    "    print(f\"threshold {thresh}: {np.sum(adj_matrix)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_edge_idx(size, undirected=False):\n",
    "    num_edges = math.ceil(size * (size - 1) / 3 - 2 * (size - 1))\n",
    "    # Initialize an empty adjacency matrix\n",
    "    adj_matrix = np.zeros((size+1, size+1), dtype=int)\n",
    "\n",
    "    # Create a list of all possible edges\n",
    "    possible_edges = [(i, j) for i in range(1, size+1) for j in range(1, size+1) if i != j]\n",
    "\n",
    "    # For undirected graphs, avoid duplicate edges by ensuring (i, j) == (j, i)\n",
    "    if undirected:\n",
    "        possible_edges = [(i, j) for i, j in possible_edges if i < j]\n",
    "\n",
    "    # Randomly select <num_edges> edges from the possible edges and populate adj matrix\n",
    "    selected_edges = np.random.choice(len(possible_edges), num_edges, replace=False)\n",
    "    for edge_index in selected_edges:\n",
    "        i, j = possible_edges[edge_index]\n",
    "        adj_matrix[i, j] = 1\n",
    "        if undirected:\n",
    "            adj_matrix[j, i] = 1\n",
    "\n",
    "    # Add edges to and from the depot\n",
    "    adj_matrix[0] = np.ones(size+1, dtype=int)\n",
    "    adj_matrix[:, 0] = np.ones(size+1, dtype=int)\n",
    "    adj_matrix[0, 0] = 0\n",
    "    return torch.tensor(np.array(np.nonzero(adj_matrix)), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_tmp = generate_edge_idx(20)\n",
    "print(edge_tmp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_edge_idx(size, thresh_val):\n",
    "    threshold = np.percentile(distance_matrix, thresh_val)\n",
    "    adj_matrix = (distance_matrix <= threshold).astype(int)\n",
    "    adj_matrix[0] = np.ones(size+1, dtype=int)\n",
    "    adj_matrix[:, 0] = np.ones(size+1, dtype=int)\n",
    "    np.fill_diagonal(adj_matrix, 0)\n",
    "    return np.array(np.nonzero(adj_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(generate_edge_idx(wsrs_size, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#midx = pd.MultiIndex.from_tuples((bid, key) for bid in [wsrs_size, wsba_size] for key in dist_dict.keys())\n",
    "#midx\n",
    "#dist_df = pd.DataFrame(data=[x for x in [y[0] for y in dist_dict.values()] + [y[1] for y in dist_dict.values()]], index=midx)\n",
    "#dist_df.index.names = ['#bin']\n",
    "#dist_df.transpose()\n",
    "#dist_df.loc[-1] = [x for x in [y[0] for y in dist_dict] + [y[1] for y in dist_dict]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ndays = 31\n",
    "Nsamples = 1\n",
    "if wsrs_size in [20, 50, 225]:\n",
    "    distance_matrix = compute_distance_matrix(all_nodes, wsrs_size+1)\n",
    "    draw_graph(distance_matrix)\n",
    "elif wsrs_size < 225:\n",
    "    input_graphs_path = os.path.join(home_dir, \"assets\", \"output\", \"wsrs\", f\"{Ndays}_days\", f\"op_{wsrs_size}\", f\"graphs_{Nsamples}N.json\") \n",
    "    if os.path.isfile(input_graphs_path):\n",
    "        with open(input_graphs_path) as fp:\n",
    "            indices = json.load(fp)\n",
    "    else:\n",
    "        raise ValueError(\"Must provide a file with the indices of the bins used in the experiments.\")\n",
    "    \n",
    "    sample_id = 0\n",
    "    bins_coordinates_tmp = process_indices(all_nodes, indices[sample_id])\n",
    "    distance_matrix = compute_distance_matrix(bins_coordinates_tmp, wsrs_size+1)\n",
    "    draw_graph(distance_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate bin fillings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = Bins(wsrs_size, data_dir, \"gamma\", grid=None)\n",
    "Ndays = 5\n",
    "overflows = [0]\n",
    "bin_fillings = []\n",
    "bins.setGammaDistribution()\n",
    "for day in range(1, Ndays):\n",
    "    overflow, filling = bins.stochasticFilling() \n",
    "    overflows.append(overflows[day - 1] + overflow)\n",
    "    bin_fillings.append(filling)\n",
    "    print(f'Day {day} #overflows: {overflows[day]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wsrs_overflows = np.array(overflows)\n",
    "wsrs_fillings = np.array(bin_fillings)\n",
    "wsrs_maxmin = (np.min(wsrs_fillings), np.max(wsrs_fillings))\n",
    "print(f\"Min daily filling: {wsrs_maxmin[0]}\")\n",
    "print(f\"Max daily filling: {wsrs_maxmin[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = Bins(wsba_size, data_dir, \"grid\", grid)\n",
    "overflows = [0]\n",
    "bin_fillings = []\n",
    "for day in range(1, Ndays):\n",
    "    overflow, filling = bins.stochasticFilling() \n",
    "    overflows.append(overflows[day - 1] + overflow)\n",
    "    bin_fillings.append(filling)\n",
    "    print(f'Day {day} #overflows: {overflows[day]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wsba_overflows = np.array(overflows)\n",
    "wsba_fillings = np.array(bin_fillings)\n",
    "wsba_maxmin = (np.min(wsba_fillings), np.max(wsba_fillings))\n",
    "print(f\"Min daily filling: {wsba_maxmin[0]}\")\n",
    "print(f\"Max daily filling: {wsba_maxmin[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_days = np.arange(1, Ndays)\n",
    "mean_wsrs_fillings = np.mean(wsrs_fillings, axis=1)\n",
    "std_wsrs_fillings = np.std(wsrs_fillings, axis=1)\n",
    "mean_wsba_fillings = np.mean(wsba_fillings, axis=1)\n",
    "std_wsba_fillings = np.std(wsba_fillings, axis=1)\n",
    "\n",
    "print(mean_wsrs_fillings)\n",
    "print(std_wsrs_fillings)\n",
    "print(mean_wsba_fillings)\n",
    "print(std_wsba_fillings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.figsize=(20, 10)\n",
    "ax.set_xticks(x_days)\n",
    "ax.set_title(\"Mu and Sigma of the daily bins' fillings\")\n",
    "ax.yaxis.grid(True)\n",
    "wsrs_bar = ax.bar(x_days - 0.2, mean_wsrs_fillings, yerr=std_wsrs_fillings, width=0.4, label='Gamma', align='center', alpha=0.5, ecolor='black', capsize=10)\n",
    "wsba_bar = ax.bar(x_days + 0.2, mean_wsba_fillings, yerr=std_wsba_fillings, width=0.4, label='WSBA', align='center', alpha=0.5, ecolor='black', capsize=10)\n",
    "ax.set_xlabel('Day of the simulation')\n",
    "ax.set_ylabel('Bins fillings')\n",
    "ax.bar_label(wsrs_bar)\n",
    "ax.bar_label(wsba_bar)\n",
    "fig.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {f\"Day {day}\": day_fill for day, day_fill in zip(x_days, wsrs_fillings)}\n",
    "fig, ax = plt.subplots()\n",
    "fig.figsize=(20, 10)\n",
    "ax.set_xticks(x_days)\n",
    "ax.set_title(\"Daily filling for Gamma Distribution\")\n",
    "ax.yaxis.grid(True)\n",
    "wsba_bar = ax.boxplot(my_dict.values(), labels=my_dict.keys())\n",
    "ax.set_xlabel('Day of the simulation')\n",
    "ax.set_ylabel('Bins fillings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {f\"Day {day}\": day_fill for day, day_fill in zip(x_days, wsba_fillings)}\n",
    "fig, ax = plt.subplots()\n",
    "fig.figsize=(20, 10)\n",
    "ax.set_xticks(x_days)\n",
    "ax.set_title(\"Daily filling for WSmart+ Bin Analysis Grid\")\n",
    "ax.yaxis.grid(True)\n",
    "wsba_bar = ax.boxplot(my_dict.values(), labels=my_dict.keys())\n",
    "ax.set_xlabel('Day of the simulation')\n",
    "ax.set_ylabel('Bins fillings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overflows_ls = []\n",
    "x_days = np.arange(0, Ndays)\n",
    "graph_size_ls = [20, 50, 100, 150]\n",
    "for id, n_nodes in enumerate(graph_size_ls):\n",
    "    tmp_overflows = [0]\n",
    "    bins = Bins(n_nodes, data_dir, \"gamma\")\n",
    "    bins.setGammaDistribution()\n",
    "    print(f\"Graph size: {n_nodes}\")\n",
    "    for day in range(1, Ndays):\n",
    "        overflow, filling = bins.stochasticFilling() \n",
    "        tmp_overflows.append(tmp_overflows[day - 1] + overflow)\n",
    "        print(f' - day {day} #overflows: {tmp_overflows[day]}')\n",
    "    \n",
    "    overflows_ls.append(tmp_overflows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_days = np.arange(0, Ndays)\n",
    "graph_size_ls.append(225)\n",
    "overflows_ls.append(wsrs_overflows)\n",
    "for n_nodes, ofs_elem in zip(graph_size_ls, overflows_ls):\n",
    "    plt.plot(x_days, ofs_elem, label=f\"Gamma Distribution OP{n_nodes}\")\n",
    "\n",
    "plt.plot(x_days, wsba_overflows, label=\"WSmart+ Bin Analysis Grid\")\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('#overflows')\n",
    "plt.title('Cumulative #overflows')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = Bins(317, data_dir, \"grid\", grid)\n",
    "overflows = [0]\n",
    "bin_fillings = []\n",
    "for day in range(1, Ndays):\n",
    "    overflow, filling = bins.stochasticFilling(trim_fill=True) \n",
    "    overflows.append(overflows[day - 1] + overflow)\n",
    "    bin_fillings.append(filling)\n",
    "    print(f'Day {day} #overflows: {overflows[day]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_days = np.arange(1, Ndays)\n",
    "wsba_overflows2 = np.array(overflows)\n",
    "wsba_fillings2 = np.array(bin_fillings)\n",
    "wsrs_fillings2 = wsrs_fillings.copy()\n",
    "wsrs_fillings2[wsrs_fillings2 < 0] = 0\n",
    "\n",
    "mean_wsrs_fillings = np.mean(wsrs_fillings2, axis=1)\n",
    "std_wsrs_fillings = np.std(wsrs_fillings2, axis=1)\n",
    "mean_wsba_fillings = np.mean(wsba_fillings2, axis=1)\n",
    "std_wsba_fillings = np.std(wsba_fillings2, axis=1)\n",
    "\n",
    "print(mean_wsrs_fillings)\n",
    "print(std_wsrs_fillings)\n",
    "print(mean_wsba_fillings)\n",
    "print(std_wsba_fillings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wsba2_maxmin = (np.min(wsba_fillings2), np.max(wsba_fillings2))\n",
    "df = pd.DataFrame([[wsrs_maxmin[0], wsba_maxmin[0], wsba2_maxmin[0]], [wsrs_maxmin[1], wsba_maxmin[1], wsba2_maxmin[1]]], ['Minimum fill', 'Maximum fill'], ['Gamma', 'WSBA', 'WSBA (y < 0 = 0)'])\n",
    "df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.figsize=(20, 10)\n",
    "ax.set_xticks(x_days)\n",
    "ax.set_title(\"Mu and Sigma of the daily bins' fillings (y < 0 = 0)\")\n",
    "ax.yaxis.grid(True)\n",
    "wsrs_bar = ax.bar(x_days - 0.2, mean_wsrs_fillings, yerr=std_wsrs_fillings, width=0.4, label='Gamma', align='center', alpha=0.5, ecolor='black', capsize=10)\n",
    "wsba_bar = ax.bar(x_days + 0.2, mean_wsba_fillings, yerr=std_wsba_fillings, width=0.4, label='WSBA', align='center', alpha=0.5, ecolor='black', capsize=10)\n",
    "ax.set_xlabel('Day of the simulation')\n",
    "ax.set_ylabel('Bins fillings')\n",
    "ax.bar_label(wsrs_bar)\n",
    "ax.bar_label(wsba_bar)\n",
    "fig.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_days = np.arange(0, Ndays)\n",
    "plt.plot(x_days, wsrs_overflows, label=f\"Gamma Distribution OP225\")\n",
    "plt.plot(x_days, wsba_overflows, label=\"WSmart+ Bin Analysis Grid\")\n",
    "plt.plot(x_days, wsba_overflows2, label=\"WSmart+ Bin Analysis Grid (y < 0 = 0)\")\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('#overflows')\n",
    "plt.title('Cumulative #overflows')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Graph\n",
    "### Generate edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_size = wsrs_size\n",
    "num_edges = math.ceil(graph_size * (graph_size - 1) / 3 - 2 * (graph_size - 1))\n",
    "print(num_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_idx = generate_edge_idx(graph_size, num_edges)\n",
    "print(edge_idx.size())\n",
    "print(edge_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_idx = generate_edge_idx(graph_size, num_edges)\n",
    "print(edge_idx.size())\n",
    "print(edge_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(edge_idx.size())\n",
    "edge_idx = sort_by_pairs(graph_size, edge_idx)\n",
    "print(edge_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depot_idx = torch.cat((torch.zeros(graph_size, dtype=torch.long), torch.range(start=1, end=graph_size))).reshape(2, graph_size)\n",
    "print(depot_idx.size())\n",
    "print(depot_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_idx = torch.cat((depot_idx, edge_idx), dim=1)\n",
    "print(full_idx.size())\n",
    "print(full_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_idx = segregate_self_loops(full_idx)\n",
    "print(sorted_idx[-2].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Orienteering Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 10\n",
    "data_dist = 'unif'\n",
    "problem = load_problem('op')\n",
    "dataset = problem.make_dataset(size=graph_size, num_samples=n_samples, distribution=data_dist)\n",
    "dataloader = DataLoader(dataset, batch_size=dataset.__len__())\n",
    "_, batch = next(enumerate(dataloader))\n",
    "print(batch.keys())\n",
    "print(batch['loc'].size())\n",
    "print(batch['edge_idx'].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(batch['loc'].size())\n",
    "print(batch['depot'].size())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
