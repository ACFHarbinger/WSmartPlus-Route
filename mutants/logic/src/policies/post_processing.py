"""
Post-Processing module for routing solutions.

This module provides a modular framework for refining tours generated by
base routing policies. It follows the Registry/Factory pattern to support
various refinement strategies like Fast TSP, Vectorized 2-opt, Swap, etc.

Decouples tour construction from tour optimization.
"""

from abc import ABC, abstractmethod
from typing import Any, Callable, Dict, List, Optional, Type, Union

import numpy as np
import torch

from .single_vehicle import find_route


# --- IPostProcessor Interface ---
class IPostProcessor(ABC):
    """
    Interface for all routing post-processors.
    """

    @abstractmethod
    def process(self, tour: List[int], **kwargs: Any) -> List[int]:
        """
        Refine a given tour.

        Args:
            tour: Initial tour (List of bin IDs including depot 0s)
            **kwargs: Context dictionary containing distance matrix, etc.

        Returns:
            List[int]: Refined tour.
        """
        pass


# --- Post-Processor Registry ---
class PostProcessorRegistry:
    """Registry for routing post-processing strategies."""

    _strategies: Dict[str, Type[IPostProcessor]] = {}

    @classmethod
    def register(cls, name: str) -> Callable:
        """Decorator to register a post-processor."""

        def wrapper(processor_cls: Type[IPostProcessor]):
            """Wrapper for registering the processor class."""
            cls._strategies[name.lower()] = processor_cls
            return processor_cls

        return wrapper

    @classmethod
    def get(cls, name: str) -> Optional[Type[IPostProcessor]]:
        """Retrieve a post-processor by name."""
        return cls._strategies.get(name.lower())


# --- Post-Processor Factory ---
class PostProcessorFactory:
    """Factory for creating post-processing strategy instances."""

    @staticmethod
    def create(name: str) -> IPostProcessor:
        """
        Create a post-processor instance by name.
        """
        cls = PostProcessorRegistry.get(name)
        if not cls:
            # Fallback for dynamic/mapped names if needed
            if name.lower() == "fast_tsp":
                return FastTSPPostProcessor()
            elif name.lower() in ["2opt", "2opt_star", "swap", "relocate", "swap_star", "3opt"]:
                return ClassicalLocalSearchPostProcessor(operator_name=name.lower())
            elif name.lower() in ["random", "random_local_search"]:
                return RandomLocalSearchPostProcessor()

            raise ValueError(f"Unknown post-processor: {name}")
        return cls()


# --- Concrete Implementation: Fast TSP ---
@PostProcessorRegistry.register("fast_tsp")
class FastTSPPostProcessor(IPostProcessor):
    """
    Refines all sub-tours using the fast_tsp library.
    Splits long tours by depot (0), re-optimizes each segment, and reconstructs.
    """

    def process(self, tour: List[int], **kwargs: Any) -> List[int]:
        """
        Refine the tour by splitting it into trips and optimizing each with fast_tsp.

        Args:
            tour: The initial tour to refine (list of node IDs).
            **kwargs: Keyword arguments containing 'distance_matrix'.

        Returns:
            List[int]: The optimized tour with reduced total distance.
        """
        distance_matrix = kwargs.get("distance_matrix")
        if distance_matrix is None:
            return tour

        if isinstance(distance_matrix, torch.Tensor):
            distance_matrix = distance_matrix.cpu().numpy()

        # Split tour into sub-tours (trips)
        trips = []
        current_trip: List[int] = []
        for node in tour:
            if node == 0:
                if current_trip:
                    trips.append(current_trip)
                    current_trip = []
            else:
                current_trip.append(node)

        if not trips:
            return tour

        refined_tour = [0]
        for trip in trips:
            if len(trip) > 1:
                # Re-optimize with fast_tsp
                refined_trip = find_route(distance_matrix, np.array(trip))
                # strip depot 0s from the constructed route to avoid doubles
                refined_tour.extend([n for n in refined_trip if n != 0])
            else:
                refined_tour.extend(trip)
            refined_tour.append(0)

        return refined_tour


# --- Concrete Implementation: Classical Local Search ---
@PostProcessorRegistry.register("classical")
class ClassicalLocalSearchPostProcessor(IPostProcessor):
    """
    Wrapper for vectorized local search operators from
    logic/src/models/policies/classical/local_search.py
    """

    def __init__(self, operator_name: str = "2opt"):
        """
        Initialize the classical local search processor.

        Args:
            operator_name: The name of the local search operator to use
                (e.g., '2opt', 'swap', 'relocate'). Defaults to '2opt'.
        """
        self.operator_name = operator_name

    def process(self, tour: List[int], **kwargs: Any) -> List[int]:
        """
        Apply vectorized local search to the tour.

        Args:
            tour: The initial tour to refine.
            **kwargs: Context containing 'distance_matrix' and optionally 'n_iterations'.

        Returns:
            List[int]: The refined tour after applying the local search operator.
        """
        import torch
        from logic.src.models.policies.classical.local_search import (
            vectorized_relocate,
            vectorized_swap,
            vectorized_swap_star,
            vectorized_three_opt,
            vectorized_two_opt,
            vectorized_two_opt_star,
        )

        distance_matrix = kwargs.get("distance_matrix", kwargs.get("distancesC"))
        if distance_matrix is None:
            return tour

        # Parameters from kwargs (extracted from context/config in actions.py)
        # Default to 50 iterations as a safe post-processing refinement
        max_iter = kwargs.get("n_iterations", kwargs.get("post_process_iterations", 50))

        # Ensure Tensors
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        if not isinstance(distance_matrix, torch.Tensor):
            dm_tensor = torch.from_numpy(np.array(distance_matrix)).float().to(device)
        else:
            dm_tensor = distance_matrix.to(device)

        # Handle batching: operators expect [B, N]
        # We ensure tour length matches and no single-node tours
        if len(tour) < 4:
            return tour

        tour_tensor = torch.tensor(tour, device=device).unsqueeze(0)  # (1, N)

        ops = {
            "2opt": vectorized_two_opt,
            "swap": vectorized_swap,
            "relocate": vectorized_relocate,
            "2opt*": vectorized_two_opt_star,
            "swap_star": vectorized_swap_star,
            "3opt": vectorized_three_opt,
            "two_opt": vectorized_two_opt,
            "two_opt_star": vectorized_two_opt_star,
            "three_opt": vectorized_three_opt,
        }

        op_fn = ops.get(self.operator_name, vectorized_two_opt)

        try:
            refined_tensor = op_fn(tour_tensor, dm_tensor, max_iterations=max_iter)
            return refined_tensor.squeeze(0).cpu().tolist()
        except Exception:
            # Fallback to original on error
            return tour


# --- Concrete Implementation: Random Local Search ---
@PostProcessorRegistry.register("random")
class RandomLocalSearchPostProcessor(IPostProcessor):
    """
    Performs stochastic local search refinement by applying random operators.
    Mirrors the logic of RandomLocalSearchPolicy but as a post-processor.
    """

    def process(self, tour: List[int], **kwargs: Any) -> List[int]:
        """
        Apply random local search operators stochastically.

        Args:
            tour: The initial tour to refine.
            **kwargs: Context containing 'distance_matrix', 'n_iterations', and optionally 'op_probs'.

        Returns:
            List[int]: The refined tour.
        """
        import torch
        from logic.src.models.policies.classical.local_search import (
            vectorized_relocate,
            vectorized_swap,
            vectorized_swap_star,
            vectorized_three_opt,
            vectorized_two_opt,
            vectorized_two_opt_star,
        )

        distance_matrix = kwargs.get("distance_matrix", kwargs.get("distancesC"))
        if distance_matrix is None or len(tour) < 4:
            return tour

        # 1. Configuration Extracted from context
        # n_iterations is the number of random operator applications
        n_iterations = kwargs.get("n_iterations", kwargs.get("post_process_iterations", 50))
        op_probs = kwargs.get("op_probs") or {
            "two_opt": 0.25,
            "swap": 0.15,
            "relocate": 0.15,
            "two_opt_star": 0.2,
            "swap_star": 0.15,
            "three_opt": 0.1,
        }

        # 2. Setup Device and Tensors
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        if not isinstance(distance_matrix, torch.Tensor):
            dm_tensor = torch.from_numpy(np.array(distance_matrix)).float().to(device)
        else:
            dm_tensor = distance_matrix.to(device)

        current_routes = torch.tensor(tour, device=device).unsqueeze(0)  # (1, N)

        # 3. Setup Operator Map and Sampling
        op_map = {
            "two_opt": vectorized_two_opt,
            "swap": vectorized_swap,
            "relocate": vectorized_relocate,
            "two_opt_star": vectorized_two_opt_star,
            "swap_star": vectorized_swap_star,
            "three_opt": vectorized_three_opt,
        }

        ops_sorted = sorted(op_map.keys())
        probs = torch.tensor([op_probs.get(op, 0.0) for op in ops_sorted], dtype=torch.float32)
        probs = probs / (probs.sum() + 1e-10)

        # 4. Iterative stochastic refinement
        iter_count = int(n_iterations) if n_iterations is not None else 50
        try:
            # Sample operators
            op_indices = torch.multinomial(probs, iter_count, replacement=True).tolist()
            for op_idx in op_indices:
                op_name = ops_sorted[op_idx]
                op_func = op_map[op_name]
                # Apply 1 iteration of the sampled operator
                current_routes = op_func(current_routes, dm_tensor, max_iterations=1)

            return current_routes.squeeze(0).cpu().tolist()
        except Exception:
            return tour


# --- Concrete Implementation: Path Refinement ---
@PostProcessorRegistry.register("path")
class PathPostProcessor(IPostProcessor):
    """
    Refines the tour by including nodes that lie on the shortest paths between consecutive
    stops in the tour, provided they fit within the vehicle capacity.
    mirrors the logic of the deprecated LastMinuteAndPathSelection.
    """

    def process(self, tour: List[int], **kwargs: Any) -> List[int]:
        """
        Refine the tour by picking up convenient bins along the path.

        Args:
            tour: The current tour (list of bin IDs).
            **kwargs: Context containing 'bins' or 'total_fill', 'paths_between_states',
                      and 'vehicle_capacity'.

        Returns:
            List[int]: The expanded tour including opportunistic pickups.
        """

        # 1. Extract context data
        bins = kwargs.get("bins")
        paths = kwargs.get("paths_between_states")

        # Retrieve fill levels (Simulations put 'total_fill' in context)
        current_fill = kwargs.get("total_fill")
        if current_fill is None and bins is not None:
            current_fill = getattr(bins, "c", None)

        if current_fill is None or paths is None:
            return tour

        capacity = kwargs.get("max_capacity") or kwargs.get("vehicle_capacity", 100.0)

        # 2. Initialize State
        selected_nodes = set(tour)
        if 0 in selected_nodes:
            selected_nodes.remove(0)

        current_load = sum(current_fill[node - 1] for node in selected_nodes)

        new_tour = [tour[0]]

        # 3. Iterate edges and fill gaps
        for i in range(len(tour) - 1):
            u = tour[i]
            v = tour[i + 1]

            # Retrieve path segment
            # paths is List[List[List[int]]] typically
            try:
                segment = paths[u][v]
            except IndexError:
                segment = [u, v]

            if not segment:
                # Should not happen if data valid, but safe fallback
                new_tour.append(v)
                continue

            # Iterate intermediate nodes (skip u)
            for node in segment[1:]:
                if node == 0:
                    if node == v:
                        new_tour.append(node)
                    continue

                if node == v:
                    new_tour.append(node)
                    continue

                if node not in selected_nodes:
                    waste = current_fill[node - 1]
                    if current_load + waste <= capacity:
                        current_load += waste
                        selected_nodes.add(node)
                        new_tour.append(node)
                    # else: skip

        return new_tour


# --- Concrete Implementation: Iterated Local Search ---
@PostProcessorRegistry.register("ils")
class IteratedLocalSearchPostProcessor(IPostProcessor):
    """
    Iterated Local Search (ILS) post-processor.

    Combines local search with perturbation to escape local minima.
    The algorithm:
    1. Apply local search until local optimum
    2. Perturb the solution (double-bridge or segment shuffle)
    3. Apply local search again
    4. Accept new solution if improving (or based on acceptance criterion)
    5. Repeat for n_restarts
    """

    def __init__(
        self,
        ls_operator: Union[str, Dict[str, float]] = "2opt",
        perturbation_type: Union[str, Dict[str, float]] = "double_bridge",
        n_restarts: int = 5,
        ls_iterations: int = 50,
        perturbation_strength: float = 0.2,
    ):
        """
        Initialize the ILS post-processor.

        Args:
            ls_operator: Local search operator or dict of {name: prob}.
            perturbation_type: Perturbation method or dict of {mode: prob}.
            n_restarts: Number of ILS restarts (perturbation cycles).
            ls_iterations: Iterations for local search within each phase.
            perturbation_strength: Fraction of tour to perturb (for shuffle/swap).
        """
        self.ls_operator = ls_operator
        self.perturbation_type = perturbation_type
        self.n_restarts = n_restarts
        self.ls_iterations = ls_iterations
        self.perturbation_strength = perturbation_strength

        # Default operator probabilities if none provided
        self.default_op_probs = {
            "2opt": 0.25,
            "swap": 0.15,
            "relocate": 0.15,
            "two_opt_star": 0.2,
            "swap_star": 0.15,
            "3opt": 0.1,
        }

        # Default perturbation probabilities
        self.default_perturb_probs = {
            "double_bridge": 0.5,
            "shuffle": 0.3,
            "random_swap": 0.2,
        }

    def process(self, tour: List[int], **kwargs: Any) -> List[int]:
        """
        Apply ILS to refine the tour.

        Args:
            tour: The initial tour to refine.
            **kwargs: Context containing 'distance_matrix'.

        Returns:
            List[int]: The refined tour.
        """
        import random

        import torch
        from logic.src.models.policies.classical.local_search import (
            vectorized_relocate,
            vectorized_swap,
            vectorized_swap_star,
            vectorized_three_opt,
            vectorized_two_opt,
            vectorized_two_opt_star,
        )

        distance_matrix = kwargs.get("distance_matrix", kwargs.get("distancesC"))
        if distance_matrix is None or len(tour) < 4:
            return tour

        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        if not isinstance(distance_matrix, torch.Tensor):
            dm_tensor = torch.from_numpy(np.array(distance_matrix)).float().to(device)
        else:
            dm_tensor = distance_matrix.to(device)

        # Map operator names to functions
        ops = {
            "2opt": vectorized_two_opt,
            "swap": vectorized_swap,
            "relocate": vectorized_relocate,
            "3opt": vectorized_three_opt,
            "two_opt": vectorized_two_opt,
            "two_opt_star": vectorized_two_opt_star,
            "swap_star": vectorized_swap_star,
            "three_opt": vectorized_three_opt,
        }

        # Prepare sampling for LS operators
        op_probs_dict = None
        ops_sorted: List[str] = []
        op_weights: List[float] = []
        ls_func = None

        if isinstance(self.ls_operator, dict):
            op_probs_dict = self.ls_operator
        elif isinstance(self.ls_operator, str) and self.ls_operator == "random":
            op_probs_dict = self.default_op_probs

        if op_probs_dict:
            ops_sorted = sorted(op_probs_dict.keys())
            op_weights = [op_probs_dict[op] for op in ops_sorted]
        else:
            # Fixed operator
            op_name = self.ls_operator if isinstance(self.ls_operator, str) else "2opt"
            ls_func = ops.get(op_name, vectorized_two_opt)

        # Prepare sampling for perturbations
        p_probs_dict = None
        p_modes_sorted: List[str] = []
        p_weights: List[float] = []

        if isinstance(self.perturbation_type, dict):
            p_probs_dict = self.perturbation_type
        elif isinstance(self.perturbation_type, str) and self.perturbation_type == "random":
            p_probs_dict = self.default_perturb_probs

        if p_probs_dict:
            p_modes_sorted = sorted(p_probs_dict.keys())
            p_weights = [p_probs_dict[m] for m in p_modes_sorted]

        def compute_cost(t: torch.Tensor) -> float:
            """Compute tour cost."""
            if t.dim() == 1:
                t = t.unsqueeze(0)
            from_n = t[:, :-1]
            to_n = t[:, 1:]
            if dm_tensor.dim() == 3:
                # Assuming batch size 1 for post-processor
                return dm_tensor[0, from_n[0], to_n[0]].sum().item()
            return dm_tensor[from_n, to_n].sum().item()

        def perturb(t: torch.Tensor, mode: str) -> torch.Tensor:
            """Apply perturbation to escape local optimum."""
            t_list = t.squeeze(0).tolist()
            n = len(t_list)

            if mode == "double_bridge":
                # Double-bridge move: break tour into 4 segments and reconnect
                if n < 8:
                    return t
                # Find segment boundaries (avoid depot at 0 and end)
                positions = sorted(random.sample(range(1, n - 1), 3))
                p1, p2, p3 = positions
                # Segment: [0:p1], [p1:p2], [p2:p3], [p3:n]
                # Reconnect as: [0:p1] + [p2:p3] + [p1:p2] + [p3:n]
                new_list = t_list[:p1] + t_list[p2:p3] + t_list[p1:p2] + t_list[p3:]
                return torch.tensor(new_list, device=device).unsqueeze(0)

            elif mode == "shuffle":
                # Shuffle a segment of the tour
                seg_len = max(2, int(n * self.perturbation_strength))
                if n - seg_len - 1 <= 1:
                    return t
                start = random.randint(1, n - seg_len - 1)
                segment = t_list[start : start + seg_len]
                random.shuffle(segment)
                new_list = t_list[:start] + segment + t_list[start + seg_len :]
                return torch.tensor(new_list, device=device).unsqueeze(0)

            else:  # random_swap or default
                # Random swaps
                n_swaps = max(1, int(n * self.perturbation_strength))
                new_list = t_list[:]
                for _ in range(n_swaps):
                    if n < 3:  # Need at least 3 nodes (depot, node1, node2) to swap two internal nodes
                        break
                    i, j = random.sample(range(1, n - 1), 2)
                    new_list[i], new_list[j] = new_list[j], new_list[i]
                return torch.tensor(new_list, device=device).unsqueeze(0)

        # Convert tour to tensor
        current = torch.tensor(tour, device=device).unsqueeze(0)

        # Initial local search
        if op_probs_dict:
            initial_op = random.choices(ops_sorted, weights=op_weights)[0]
            current_ls_func = ops.get(initial_op, vectorized_two_opt)
        else:
            current_ls_func = ls_func if ls_func is not None else vectorized_two_opt

        current = current_ls_func(current, dm_tensor, max_iterations=self.ls_iterations)
        best = current.clone()
        best_cost = compute_cost(best)

        # ILS loop
        for _ in range(self.n_restarts):
            # Sample perturbation mode
            if p_probs_dict:
                p_mode = random.choices(p_modes_sorted, weights=p_weights)[0]
            else:
                p_mode = self.perturbation_type if isinstance(self.perturbation_type, str) else "double_bridge"

            # Perturb
            perturbed = perturb(current, p_mode)

            # Sample LS operator for this restart
            if op_probs_dict:
                iter_op = random.choices(ops_sorted, weights=op_weights)[0]
                iter_ls_func = ops.get(iter_op, vectorized_two_opt)
            else:
                iter_ls_func = ls_func if ls_func is not None else vectorized_two_opt

            # Local search on perturbed solution
            refined = iter_ls_func(perturbed, dm_tensor, max_iterations=self.ls_iterations)
            refined_cost = compute_cost(refined)

            # Acceptance criterion (accept if improving)
            if refined_cost < best_cost - 1e-6:
                best = refined.clone()
                best_cost = refined_cost

            # Always move to refined for exploration (stochastic escape)
            current = refined

        return best.squeeze(0).cpu().tolist()
