"""
Post-Processing Optimization for REINFORCE Solutions.

This module provides tools to improve solutions generated by REINFORCE models through
post-processing techniques. These methods refine the neural policy outputs without
modifying the policy itself, focusing on improving specific metrics like efficiency (kg/km).

Available Methods:
- EfficiencyOptimizer: Neural post-processor for learning solution refinements
- post_processing_optimization: Training pipeline for the post-processor

Post-processing is particularly useful when:
1. The neural policy produces good but suboptimal solutions
2. Specific metrics (e.g., efficiency) need targeted optimization
3. You want to improve solutions without retraining the main policy
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader


class EfficiencyOptimizer(nn.Module):
    """
    Neural network for learning solution refinements.

    A residual MLP that learns to adjust/refine solutions produced by the main model.
    Uses residual connections so it only learns adjustments (deltas) rather than
    reconstructing solutions from scratch.

    Architecture:
    - Input: Raw model output (e.g., logits, embeddings)
    - Residual network: Input + MLP(Input)
    - Output: Refined representation

    Args:
        input_dim: Dimension of model outputs
        hidden_dim: Hidden layer size (default: 64)
    """

    def __init__(self, input_dim, hidden_dim=64):
        """
        Initialize the EfficiencyOptimizer.

        Args:
            input_dim (int): Dimension of the input features.
            hidden_dim (int): Dimension of the hidden layer.
        """
        super(EfficiencyOptimizer, self).__init__()
        self.network = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, input_dim),
        )

    def forward(self, x):
        """
        Apply residual refinement.

        Args:
            x: Input tensor (model outputs)

        Returns:
            Refined tensor: x + Δx where Δx = network(x)
        """
        # Add residual connection so the model learns adjustments
        return x + self.network(x)


def calculate_efficiency(routes, waste, distance_matrix):
    """Calculate kg/km efficiency and overflow metrics for routes"""
    total_waste = 0
    total_distance = 0
    overflow_count = 0
    for route in routes:
        # Calculate total waste collected on this route
        route_waste = sum(waste[i] for i in route)
        total_waste += route_waste

        # Calculate distance traveled (including return to depot)
        route_distance = 0
        for i in range(len(route) - 1):
            route_distance += distance_matrix[route[i], route[i + 1]]
        route_distance += distance_matrix[route[-1], 0]  # Return to depot
        total_distance += route_distance
    efficiency = total_waste / max(1, total_distance)  # kg/km
    return efficiency, overflow_count


def post_processing_optimization(
    main_model,
    dataset,
    epochs=100,
    lr=0.001,
    efficiency_weight=0.8,
    overflow_weight=0.2,
):
    """
    Apply post-processing optimization to improve efficiency

    Args:
        main_model: Your trained main routing model
        distance_matrix: Matrix of distances between nodes
        epochs: Number of epochs for post-processing
        lr: Learning rate
        efficiency_weight: Weight for efficiency in loss function
        overflow_weight: Weight for overflow penalty
    """
    # Extract model outputs as starting point
    main_model.eval()

    # Determine input dimension based on model output
    with torch.no_grad():
        sample_output = main_model(dataset[0])
        input_dim = sample_output.size(-1)

    # Create post-processing model and train it
    post_processor = EfficiencyOptimizer(input_dim)
    optimizer = optim.Adam(post_processor.parameters(), lr=lr)
    for epoch in range(epochs):
        total_loss = 0
        batch_count = 0
        for batch in DataLoader(dataset, batch_size=32, shuffle=True):
            optimizer.zero_grad()
            with torch.no_grad():
                main_outputs = main_model(batch)

            # Perform post-processing and compute metrics
            adjusted_outputs = post_processor(main_outputs)
            routes = decode_routes(adjusted_outputs)
            efficiency, overflows = calculate_efficiency(routes, batch["waste"], batch["dist"])

            # Custom loss that prioritizes efficiency with some overflow tolerance
            loss = -(efficiency_weight * efficiency) + (overflow_weight * overflows)
            loss.backward()
            optimizer.step()

            total_loss += loss.item()
            batch_count += 1
        avg_loss = total_loss / batch_count
        print(f"Epoch {epoch + 1}/{epochs}, Loss: {avg_loss:.4f}")
    return post_processor


def decode_routes(model_outputs):
    """
    Convert model outputs to concrete routes
    This function depends on your specific routing representation
    """
    routes = []
    for output in model_outputs:
        route = output[output != 0]
        routes.append([0] + route.cpu().numpy().tolist() + [0])
    return routes


def apply_post_processing(main_model, post_processor, dataset):
    """Apply the post-processor to new instances"""
    main_model.eval()
    post_processor.eval()

    results = []
    with torch.no_grad():
        for batch in DataLoader(dataset, batch_size=32):
            main_outputs = main_model(batch)
            optimized_outputs = post_processor(main_outputs)
            results.append(optimized_outputs)
    return torch.cat(results, dim=0)
