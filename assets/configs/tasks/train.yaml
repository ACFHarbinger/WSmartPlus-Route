# @package _global_

# General Configuration
verbose: true
seed: 42
start: 0

# Environment
env:
  name: "cwcvrp"

# Training Settings
train:
  train_data_size: 128_0
  train_time: true
  eval_time_days: 7
  data_distribution: "gamma1"
  load_dataset: "time"
  n_epochs: 100
  batch_size: 128
  eval_batch_size: 128
  log_step: 10
  logs_dir: "logs/output"
  model_weights_path: "model_weights"
  persistent_workers: true
  pin_memory: true
  reload_dataloaders_every_n_epochs: 0

# Optimizer Settings
optim:
  optimizer: "rmsprop"
  lr: 0.0001
  lr_decay: 1.0
  lr_scheduler: "lambda"

# RL / Algorithm Settings
rl:
  algorithm: "adaptive_imitation"
  baseline: "exponential"
  bl_alpha: 0.05
  exp_beta: 0.8
  max_grad_norm: 1.0
  gamma: 1.0

  # Algorithm-specific configurations
  ppo:
    epochs: 7
    eps_clip: 0.2

  imitation:
    mode: "hgs"

  adaptive_imitation:
    il_weight: 1.0
    il_decay: 0.95
    patience: 5
    threshold: 0.1 # stop_thresh
    decay_step: 1
    epsilon: 1e-5

# Model Settings
model:
  name: "am"
  encoder_type: "gat"
  policy_config: "assets/configs/lookahead_hgs.yaml"

# Global flags
wandb_mode: "disabled"
