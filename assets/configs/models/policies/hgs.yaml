# @package _global_

# =============================================================================
# HGS Expert Policy Configuration for RL Training
# =============================================================================
# PURPOSE:
#   Configuration for using Hybrid Genetic Search (HGS) as expert policy
#   in Imitation Learning or Adaptive Imitation Learning.
#
# USAGE:
#   python main.py train rl.imitation.policy_config=tasks/policies/rl/hgs
# =============================================================================

_target_: logic.src.configs.rl.policies.HGSConfig

# Runtime Control
time_limit: 30.0
# Maximum wall-clock seconds for HGS solver
# Range: 10-60 (10s = fast but lower quality, 30s = balanced, 60s = high quality)
# Note: Training speed vs demonstration quality tradeoff

# Population Management
population_size: 50
# Total individuals in genetic pool
# Range: 25-100 (25 = fast, 50 = balanced, 100 = thorough)
# Higher = better solutions but slower training

elite_size: 10
# Number of elite solutions to preserve each generation
# Range: 5-25 (typically 20% of population_size)

# Genetic Operators
mutation_rate: 0.2
# Probability of mutation after crossover
# Range: 0.0-0.5 (0.1 = conservative, 0.2 = balanced, 0.4 = aggressive)

# Evolution Control
n_generations: 100
# Maximum number of generations
# Range: 50-200 (adaptive stopping typically halts earlier)

# Vehicle Constraints
max_vehicles: 0
# Maximum number of vehicles (0 = unlimited, determined by problem)
