# @package _global_

# =============================================================================
# VRPP (Vehicle Routing Problem with Profits) Exact Solver Configuration
# =============================================================================
# PURPOSE:
#   Exact optimization for VRPP using Gurobi MIP solver. Finds provably
#   optimal solutions for profit-maximization routing where visiting nodes
#   yields rewards but incurs travel costs. Guarantees optimality for small
#   instances (≤50 nodes).
#
# PROBLEM FORMULATION:
#   Maximize: Σ(profit[i] * visit[i]) - Σ(cost[i,j] * travel[i,j])
#   Subject to:
#     - Vehicle capacity constraints
#     - Route continuity (each node visited once)
#     - Depot start/end requirements
#
# ALGORITHM:
#   1. Formulate VRPP as Mixed-Integer Program (MIP)
#   2. Solve via Gurobi's branch-and-cut (exact method)
#   3. Return optimal subset of nodes to visit + routes
#
# TYPICAL USE CASES:
#   - Small VRPP instances (20-50 nodes) requiring optimal solutions
#   - Benchmark baseline for neural/metaheuristic comparison
#   - Profit-driven waste collection (collect only if profitable)
#
# PERFORMANCE EXPECTATIONS:
#   - 20 nodes: Optimal in <30 seconds
#   - 50 nodes: Optimal in 1-10 minutes (highly variable)
#   - 100+ nodes: May timeout after 10 minutes (use HGS instead)
#
# NOTE:
#   Requires valid Gurobi license. Free academic licenses available at
#   https://www.gurobi.com/academia/academic-program-and-licenses/
# =============================================================================

vrpp:
  gurobi:
    # ---------------------------------------------------------------------
    # Objective Function Weights
    # ---------------------------------------------------------------------
    - Omega: 0.1
      # Penalty weight for overtime (exceeding max route duration)
      # Range: 0.0-1.0 (0 = no penalty, 1 = strong penalty)
      # Higher Omega → tighter adherence to time windows/route length limits
      # Recommendation: 0.1 for soft constraints, 0.5 for strict enforcement

    - delta: 0
      # Bonus reward for visiting mandatory nodes
      # Range: 0-100 (0 = no bonus, 100 = strong incentive)
      # delta=0 → all nodes treated equally (standard VRPP)
      # delta>0 → must_go nodes receive extra profit delta
      # Use case: Prioritize high-fill bins in waste collection

    - psi: 1
      # Travel cost scaling factor
      # Range: 0.1-10.0 (0.1 = cheap travel, 10.0 = expensive travel)
      # psi=1 → standard cost (distance × fuel_rate)
      # psi=2 → double travel cost (favor fewer, longer routes)
      # Trade-off: Higher psi → visit fewer nodes but higher profit/node

    # Objective = Σ profit - psi * Σ cost - Omega * Σ overtime + delta * Σ must_go
    # Gurobi maximizes this combined objective
    # ---------------------------------------------------------------------
    # Solver Backend
    # ---------------------------------------------------------------------
    - engine: "gurobi"
      # Execution backend: logic/src/policies/gurobi_vrpp.py
      # Requires: gurobipy Python package + valid Gurobi license

    # ---------------------------------------------------------------------
    # Node Selection Strategy
    # ---------------------------------------------------------------------
    - must_go: ["other/mg_lookahead.yaml", "other/mg_service_level0.84.yaml"]
      # Multiple selection strategies (union of both):
      #   1. mg_lookahead.yaml: Bins predicted to overflow soon
      #   2. mg_service_level0.84.xml: Statistical service level ≥84%
      #
      # Must-go nodes receive bonus profit (delta) and stricter constraints
      # See: docs/MUST_GO_STRATEGIES.md for detailed comparison

    # ---------------------------------------------------------------------
    # Runtime Control
    # ---------------------------------------------------------------------
    - time_limit: 600
      # Maximum wall-clock seconds before termination
      # Range: 60-3600 (60s = quick, 600s = thorough, 3600s = deep search)
      # Gurobi returns best solution found if time limit reached
      # Note: 600s (10 min) allows solving most 50-node instances to optimality

    # ---------------------------------------------------------------------
    # Post-Processing
    # ---------------------------------------------------------------------
    - post_processing: []
      # No post-processing needed for exact solutions
      # Empty = use Gurobi output directly (already optimal)

    # ---------------------------------------------------------------------
    # Gurobi Solver Parameters (Implicit)
    # ---------------------------------------------------------------------
    # Advanced Gurobi settings configured in:
    #   logic/src/policies/gurobi_vrpp.py
    #
    # Key implicit settings:
    #   - MIPGap: 0.01 (stop if within 1% of optimal)
    #   - MIPFocus: 1 (prioritize finding feasible solutions quickly)
    #   - Presolve: Aggressive (reduce problem size before solving)
    #   - Cuts: Automatic (let Gurobi decide cutting plane strategy)
    #   - Threads: -1 (use all available CPU cores)
    #   - LogToConsole: 0 (suppress Gurobi output)
    #
    # To override: Modify logic/src/policies/gurobi_vrpp.py

    # ---------------------------------------------------------------------
    # MIP Formulation Details
    # ---------------------------------------------------------------------
    # Decision Variables:
    #   - x[i,j] ∈ {0,1}: Binary, 1 if edge (i,j) is traversed
    #   - y[i] ∈ {0,1}: Binary, 1 if node i is visited
    #   - u[i] ∈ ℝ+: Continuous, subtour elimination (MTZ formulation)
    #
    # Constraints:
    #   - Flow conservation: Σ x[i,j] = Σ x[j,i] for all j
    #   - Visit once: Σ x[i,j] ≤ 1 for all i (if y[i]=1)
    #   - Capacity: Σ demand[i] * y[i] ≤ vehicle_capacity
    #   - Subtour elimination: u[i] - u[j] + n*x[i,j] ≤ n-1
    #   - Must-go: y[i] = 1 for all i in must_go set
    #
    # Objective:
    #   Maximize: Σ profit[i]*y[i] - psi*Σ cost[i,j]*x[i,j] - Omega*overtime + delta*Σ y[must_go]
# =============================================================================
